{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 04:05:23.406903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 04:05:25.235665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/home2/shivam.sood/.mujoco/mujoco210/bin:/home2/shivam.sood/.mujoco/mujoco210/bin:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-05-04 04:05:25.235835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/home2/shivam.sood/.mujoco/mujoco210/bin:/home2/shivam.sood/.mujoco/mujoco210/bin:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-05-04 04:05:25.235853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Create a transformer model to predict next element of a stream cipher based on the previous elements\n",
    "# Create a LSTM model to predict the next bit of a LFSR\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_data(\n",
    "    num_samples=10000, initial_key1=None, initial_key2=None, ln=5, output_ln=5\n",
    "):\n",
    "    if initial_key1 is None:\n",
    "        initial_key1 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 1: \", initial_key1)\n",
    "    if initial_key2 is None:\n",
    "        initial_key2 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 2: \", initial_key2)\n",
    "\n",
    "    # data = initial_key\n",
    "    key1 = initial_key1\n",
    "    key2 = initial_key2\n",
    "    x = []\n",
    "    y = []\n",
    "    # st = set()\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        nxt1 = key1[0] ^ key1[1]\n",
    "        nxt2 = key2[0] ^ key2[2]\n",
    "        data.append(nxt1 ^ nxt2)\n",
    "        if len(data) >= ln + output_ln:\n",
    "            x.append([2] + data[-(ln + output_ln) : -output_ln] + [3])\n",
    "            # st.add(tuple(data[-10 * ln : -9 * ln]))\n",
    "            y.append([2] + data[-output_ln:] + [3])\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key1[-1] = nxt1\n",
    "        key2[-1] = nxt2\n",
    "    # print(\"Unique samples: \", len(st))\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 12) (390, 102) (9501, 12) (9501, 102)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_data(num_samples=10000, ln=10, output_ln=100, initial_key1=np.array([1, 0, 1, 0, 1]),\n",
    "        initial_key2=np.array([0, 0, 1, 1, 1]),)\n",
    "X_train, Y_train = X[:500 - 110], Y[:500 - 110]\n",
    "X_test, Y_test = X[500 - 110:], Y[500 - 110:]\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_embedding(length, depth):\n",
    "    depth = depth // 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    # print(angle_rads.shape, np.sin(angle_rads).shape, np.cos(angle_rads).shape)\n",
    "    positional_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)], axis=-1\n",
    "    )\n",
    "\n",
    "    return tf.cast(positional_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = positional_embedding(max_len, d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        # print(length)\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.positional_encoding[tf.newaxis, :length, :]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, y):\n",
    "        attn_output = self.mha(x, y, y)\n",
    "        x = self.add([attn_output, x])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(x, x, x)\n",
    "        x = self.add([attn_output, x])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "\n",
    "        attn_output = self.mha(x, x, x, use_causal_mask=True)\n",
    "        x = self.add([attn_output, x])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(d_model),\n",
    "            ]\n",
    "        )\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        ff_output = self.seq(x)\n",
    "        x = self.add([ff_output, x])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff):\n",
    "        super().__init__()\n",
    "        self.self_attn = GlobalSelfAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.feed_forward = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.self_attn(x)\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_emb = PositionalEmbedding(vocab_size, d_model, 12)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff) for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.pos_emb(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff):\n",
    "        super().__init__()\n",
    "        self.self_attn = CausalSelfAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.cross_attn = CrossAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.feed_forward = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, enc_out):\n",
    "        x = self.self_attn(x)\n",
    "        x = self.cross_attn(x, enc_out)\n",
    "        x = self.feed_forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_emb = PositionalEmbedding(vocab_size, d_model, 101)\n",
    "\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model, num_heads, dff) for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, x, enc_out):\n",
    "        x = self.pos_emb(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_out)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, vocab_size)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, vocab_size)\n",
    "        self.final_layer = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        enc_out = self.encoder(x)\n",
    "        dec_out = self.decoder(y, enc_out)\n",
    "\n",
    "        return self.final_layer(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "# num_layers = 6\n",
    "# d_model = 512\n",
    "# dff = 2048\n",
    "# num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 04:05:28.844393: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 04:05:29.426939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10398 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff, 4)\n",
    "\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# transformer.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(transformer((X_train[0], Y_train[0, :-1])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 - 1s - loss: 0.0553 - sparse_categorical_accuracy: 0.9809 - 529ms/epoch - 264ms/step\n",
      "Epoch 2/1000\n",
      "2/2 - 0s - loss: 0.0419 - sparse_categorical_accuracy: 0.9848 - 495ms/epoch - 247ms/step\n",
      "Epoch 3/1000\n",
      "2/2 - 0s - loss: 0.0331 - sparse_categorical_accuracy: 0.9883 - 496ms/epoch - 248ms/step\n",
      "Epoch 4/1000\n",
      "2/2 - 0s - loss: 0.0237 - sparse_categorical_accuracy: 0.9924 - 495ms/epoch - 248ms/step\n",
      "Epoch 5/1000\n",
      "2/2 - 0s - loss: 0.0157 - sparse_categorical_accuracy: 0.9957 - 497ms/epoch - 249ms/step\n",
      "Epoch 6/1000\n",
      "2/2 - 0s - loss: 0.0122 - sparse_categorical_accuracy: 0.9965 - 495ms/epoch - 248ms/step\n",
      "Epoch 7/1000\n",
      "2/2 - 1s - loss: 0.0068 - sparse_categorical_accuracy: 0.9988 - 500ms/epoch - 250ms/step\n",
      "Epoch 8/1000\n",
      "2/2 - 0s - loss: 0.0060 - sparse_categorical_accuracy: 0.9990 - 495ms/epoch - 247ms/step\n",
      "Epoch 9/1000\n",
      "2/2 - 0s - loss: 0.0041 - sparse_categorical_accuracy: 0.9994 - 499ms/epoch - 249ms/step\n",
      "Epoch 10/1000\n",
      "2/2 - 9s - loss: 0.0026 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.4754 - val_sparse_categorical_accuracy: 0.7940 - 9s/epoch - 4s/step\n",
      "Epoch 11/1000\n",
      "2/2 - 0s - loss: 0.0020 - sparse_categorical_accuracy: 0.9999 - 500ms/epoch - 250ms/step\n",
      "Epoch 12/1000\n",
      "2/2 - 0s - loss: 0.0016 - sparse_categorical_accuracy: 0.9999 - 499ms/epoch - 249ms/step\n",
      "Epoch 13/1000\n",
      "2/2 - 0s - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 249ms/step\n",
      "Epoch 14/1000\n",
      "2/2 - 1s - loss: 9.3198e-04 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 15/1000\n",
      "2/2 - 0s - loss: 7.5811e-04 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 250ms/step\n",
      "Epoch 16/1000\n",
      "2/2 - 0s - loss: 6.0744e-04 - sparse_categorical_accuracy: 1.0000 - 495ms/epoch - 248ms/step\n",
      "Epoch 17/1000\n",
      "2/2 - 1s - loss: 4.8285e-04 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 18/1000\n",
      "2/2 - 0s - loss: 3.9307e-04 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 249ms/step\n",
      "Epoch 19/1000\n",
      "2/2 - 1s - loss: 3.3110e-04 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 20/1000\n",
      "2/2 - 9s - loss: 2.8639e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.8148 - val_sparse_categorical_accuracy: 0.7956 - 9s/epoch - 4s/step\n",
      "Epoch 21/1000\n",
      "2/2 - 1s - loss: 2.4932e-04 - sparse_categorical_accuracy: 1.0000 - 504ms/epoch - 252ms/step\n",
      "Epoch 22/1000\n",
      "2/2 - 1s - loss: 2.1866e-04 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 23/1000\n",
      "2/2 - 1s - loss: 1.9343e-04 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 24/1000\n",
      "2/2 - 0s - loss: 1.7182e-04 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 25/1000\n",
      "2/2 - 1s - loss: 1.5401e-04 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 26/1000\n",
      "2/2 - 1s - loss: 1.3862e-04 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 27/1000\n",
      "2/2 - 0s - loss: 1.2490e-04 - sparse_categorical_accuracy: 1.0000 - 498ms/epoch - 249ms/step\n",
      "Epoch 28/1000\n",
      "2/2 - 1s - loss: 1.1355e-04 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 29/1000\n",
      "2/2 - 1s - loss: 1.0418e-04 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 30/1000\n",
      "2/2 - 9s - loss: 9.6601e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9362 - val_sparse_categorical_accuracy: 0.7951 - 9s/epoch - 4s/step\n",
      "Epoch 31/1000\n",
      "2/2 - 1s - loss: 9.0204e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 252ms/step\n",
      "Epoch 32/1000\n",
      "2/2 - 1s - loss: 8.4989e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 33/1000\n",
      "2/2 - 1s - loss: 8.0258e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 252ms/step\n",
      "Epoch 34/1000\n",
      "2/2 - 1s - loss: 7.6176e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 35/1000\n",
      "2/2 - 1s - loss: 7.2311e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 36/1000\n",
      "2/2 - 0s - loss: 6.8826e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 37/1000\n",
      "2/2 - 0s - loss: 6.5640e-05 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 250ms/step\n",
      "Epoch 38/1000\n",
      "2/2 - 0s - loss: 6.2832e-05 - sparse_categorical_accuracy: 1.0000 - 498ms/epoch - 249ms/step\n",
      "Epoch 39/1000\n",
      "2/2 - 0s - loss: 6.0180e-05 - sparse_categorical_accuracy: 1.0000 - 498ms/epoch - 249ms/step\n",
      "Epoch 40/1000\n",
      "2/2 - 9s - loss: 5.7821e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9896 - val_sparse_categorical_accuracy: 0.7946 - 9s/epoch - 4s/step\n",
      "Epoch 41/1000\n",
      "2/2 - 0s - loss: 5.5653e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 42/1000\n",
      "2/2 - 0s - loss: 5.3672e-05 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 249ms/step\n",
      "Epoch 43/1000\n",
      "2/2 - 1s - loss: 5.1804e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 44/1000\n",
      "2/2 - 1s - loss: 5.0064e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 45/1000\n",
      "2/2 - 1s - loss: 4.8448e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 46/1000\n",
      "2/2 - 1s - loss: 4.6883e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 252ms/step\n",
      "Epoch 47/1000\n",
      "2/2 - 1s - loss: 4.5400e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 252ms/step\n",
      "Epoch 48/1000\n",
      "2/2 - 1s - loss: 4.4069e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 49/1000\n",
      "2/2 - 0s - loss: 4.2747e-05 - sparse_categorical_accuracy: 1.0000 - 498ms/epoch - 249ms/step\n",
      "Epoch 50/1000\n",
      "2/2 - 9s - loss: 4.1525e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0250 - val_sparse_categorical_accuracy: 0.7947 - 9s/epoch - 4s/step\n",
      "Epoch 51/1000\n",
      "2/2 - 1s - loss: 4.0362e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 52/1000\n",
      "2/2 - 1s - loss: 3.9233e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 53/1000\n",
      "2/2 - 1s - loss: 3.8130e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 54/1000\n",
      "2/2 - 1s - loss: 3.7101e-05 - sparse_categorical_accuracy: 1.0000 - 504ms/epoch - 252ms/step\n",
      "Epoch 55/1000\n",
      "2/2 - 1s - loss: 3.6118e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 56/1000\n",
      "2/2 - 0s - loss: 3.5161e-05 - sparse_categorical_accuracy: 1.0000 - 497ms/epoch - 248ms/step\n",
      "Epoch 57/1000\n",
      "2/2 - 1s - loss: 3.4233e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 58/1000\n",
      "2/2 - 1s - loss: 3.3358e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 59/1000\n",
      "2/2 - 0s - loss: 3.2496e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 60/1000\n",
      "2/2 - 9s - loss: 3.1664e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0566 - val_sparse_categorical_accuracy: 0.7947 - 9s/epoch - 4s/step\n",
      "Epoch 61/1000\n",
      "2/2 - 1s - loss: 3.0857e-05 - sparse_categorical_accuracy: 1.0000 - 506ms/epoch - 253ms/step\n",
      "Epoch 62/1000\n",
      "2/2 - 1s - loss: 3.0088e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 63/1000\n",
      "2/2 - 1s - loss: 2.9320e-05 - sparse_categorical_accuracy: 1.0000 - 504ms/epoch - 252ms/step\n",
      "Epoch 64/1000\n",
      "2/2 - 1s - loss: 2.8595e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 65/1000\n",
      "2/2 - 1s - loss: 2.7894e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 66/1000\n",
      "2/2 - 0s - loss: 2.7223e-05 - sparse_categorical_accuracy: 1.0000 - 497ms/epoch - 249ms/step\n",
      "Epoch 67/1000\n",
      "2/2 - 1s - loss: 2.6552e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 68/1000\n",
      "2/2 - 1s - loss: 2.5904e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 69/1000\n",
      "2/2 - 1s - loss: 2.5292e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 70/1000\n",
      "2/2 - 9s - loss: 2.4665e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0860 - val_sparse_categorical_accuracy: 0.7947 - 9s/epoch - 4s/step\n",
      "Epoch 71/1000\n",
      "2/2 - 1s - loss: 2.4079e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 72/1000\n",
      "2/2 - 1s - loss: 2.3522e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 73/1000\n",
      "2/2 - 1s - loss: 2.2956e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 74/1000\n",
      "2/2 - 1s - loss: 2.2410e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 75/1000\n",
      "2/2 - 0s - loss: 2.1891e-05 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 249ms/step\n",
      "Epoch 76/1000\n",
      "2/2 - 0s - loss: 2.1375e-05 - sparse_categorical_accuracy: 1.0000 - 499ms/epoch - 250ms/step\n",
      "Epoch 77/1000\n",
      "2/2 - 1s - loss: 2.0870e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 78/1000\n",
      "2/2 - 1s - loss: 2.0381e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 79/1000\n",
      "2/2 - 1s - loss: 1.9913e-05 - sparse_categorical_accuracy: 1.0000 - 506ms/epoch - 253ms/step\n",
      "Epoch 80/1000\n",
      "2/2 - 9s - loss: 1.9445e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1146 - val_sparse_categorical_accuracy: 0.7948 - 9s/epoch - 4s/step\n",
      "Epoch 81/1000\n",
      "2/2 - 1s - loss: 1.9002e-05 - sparse_categorical_accuracy: 1.0000 - 505ms/epoch - 252ms/step\n",
      "Epoch 82/1000\n",
      "2/2 - 1s - loss: 1.8558e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 83/1000\n",
      "2/2 - 1s - loss: 1.8129e-05 - sparse_categorical_accuracy: 1.0000 - 506ms/epoch - 253ms/step\n",
      "Epoch 84/1000\n",
      "2/2 - 1s - loss: 1.7710e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 85/1000\n",
      "2/2 - 1s - loss: 1.7305e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 86/1000\n",
      "2/2 - 0s - loss: 1.6908e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 87/1000\n",
      "2/2 - 1s - loss: 1.6517e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 88/1000\n",
      "2/2 - 1s - loss: 1.6141e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 89/1000\n",
      "2/2 - 1s - loss: 1.5773e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 90/1000\n",
      "2/2 - 9s - loss: 1.5413e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1432 - val_sparse_categorical_accuracy: 0.7948 - 9s/epoch - 4s/step\n",
      "Epoch 91/1000\n",
      "2/2 - 1s - loss: 1.5059e-05 - sparse_categorical_accuracy: 1.0000 - 505ms/epoch - 252ms/step\n",
      "Epoch 92/1000\n",
      "2/2 - 1s - loss: 1.4719e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 251ms/step\n",
      "Epoch 93/1000\n",
      "2/2 - 1s - loss: 1.4385e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 94/1000\n",
      "2/2 - 1s - loss: 1.4056e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 251ms/step\n",
      "Epoch 95/1000\n",
      "2/2 - 1s - loss: 1.3740e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 96/1000\n",
      "2/2 - 1s - loss: 1.3434e-05 - sparse_categorical_accuracy: 1.0000 - 500ms/epoch - 250ms/step\n",
      "Epoch 97/1000\n",
      "2/2 - 1s - loss: 1.3128e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 98/1000\n",
      "2/2 - 1s - loss: 1.2832e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 99/1000\n",
      "2/2 - 1s - loss: 1.2545e-05 - sparse_categorical_accuracy: 1.0000 - 501ms/epoch - 250ms/step\n",
      "Epoch 100/1000\n",
      "2/2 - 9s - loss: 1.2263e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1718 - val_sparse_categorical_accuracy: 0.7949 - 9s/epoch - 4s/step\n",
      "Epoch 101/1000\n",
      "2/2 - 1s - loss: 1.1986e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 102/1000\n",
      "2/2 - 1s - loss: 1.1720e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 103/1000\n",
      "2/2 - 1s - loss: 1.1452e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 104/1000\n",
      "2/2 - 1s - loss: 1.1199e-05 - sparse_categorical_accuracy: 1.0000 - 503ms/epoch - 252ms/step\n",
      "Epoch 105/1000\n",
      "2/2 - 1s - loss: 1.0945e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 106/1000\n",
      "2/2 - 1s - loss: 1.0698e-05 - sparse_categorical_accuracy: 1.0000 - 502ms/epoch - 251ms/step\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.fit((X_train, Y_train[:, :-1]), Y_train[:, 1:], epochs=1000, batch_size=256, validation_data=((X_test, Y_test[:, :-1]), Y_test[:, 1:]), validation_freq=10, verbose=2, validation_steps=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_5 (Encoder)         multiple                  2639360   \n",
      "                                                                 \n",
      " decoder_5 (Decoder)         multiple                  4750336   \n",
      "                                                                 \n",
      " dense_109 (Dense)           multiple                  516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,390,212\n",
      "Trainable params: 7,390,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 9s 31ms/step - loss: 2.1919 - sparse_categorical_accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1919262409210205, 0.7949616312980652]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.evaluate((X_test, Y_test[:, :-1]), Y_test[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 1 1 1]\n",
      "[0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1\n",
      " 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0][1:-1])\n",
    "print(Y_test[0][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "seq = np.array([2.0])\n",
    "for i in range(101):\n",
    "    nxt = transformer((X_test[0].reshape(1, -1), seq.reshape(1, -1)))\n",
    "    # print(np.argmax(nxt[0, -1]))\n",
    "    seq = np.concatenate([seq, [np.argmax(nxt[0, -1])]])\n",
    "\n",
    "print(seq[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(np.rint(seq) == Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4989, 10) (4989, 1) (5001, 10) (5001, 1)\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "# num_layers = 6\n",
    "# d_model = 512\n",
    "# dff = 2048\n",
    "# num_heads = 8\n",
    "\n",
    "\n",
    "def create_data(\n",
    "    num_samples=10000, initial_key1=None, initial_key2=None, ln=5, output_ln=5\n",
    "):\n",
    "    if initial_key1 is None:\n",
    "        initial_key1 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 1: \", initial_key1)\n",
    "    if initial_key2 is None:\n",
    "        initial_key2 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 2: \", initial_key2)\n",
    "\n",
    "    # data = initial_key\n",
    "    key1 = initial_key1\n",
    "    key2 = initial_key2\n",
    "    x = []\n",
    "    y = []\n",
    "    # st = set()\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        nxt1 = key1[0] ^ key1[1]\n",
    "        nxt2 = key2[0] ^ key2[2]\n",
    "        data.append(nxt1 ^ nxt2)\n",
    "        if len(data) >= ln + output_ln:\n",
    "            x.append(data[-(ln + output_ln) : -output_ln])\n",
    "            # st.add(tuple(data[-10 * ln : -9 * ln]))\n",
    "            y.append(data[-output_ln:] )\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key1[-1] = nxt1\n",
    "        key2[-1] = nxt2\n",
    "    # print(\"Unique samples: \", len(st))\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "X, Y = create_data(num_samples=10000, ln=10, output_ln=1, initial_key1=np.array([1, 0, 1, 0, 1]),\n",
    "        initial_key2=np.array([0, 0, 1, 1, 1]),)\n",
    "X_train, Y_train = X[:5000 - 11], Y[:5000 - 11]\n",
    "X_test, Y_test = X[5000 - 11:], Y[5000 - 11:]\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_emb = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, dff) for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.pos_emb(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalEncoder(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, 2)\n",
    "        self.dense = tf.keras.layers.Dense(1000)\n",
    "        self.dense2 = tf.keras.layers.Dense(1)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, x):\n",
    "        tmp = self.dense(self.flatten(self.encoder(x)))\n",
    "        # print(tmp.shape)\n",
    "        return self.dense2(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = FinalEncoder(num_layers, d_model, num_heads, dff)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "enc.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=True), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "156/156 - 13s - loss: 0.7361 - accuracy: 0.5077 - 13s/epoch - 85ms/step\n",
      "Epoch 2/1000\n",
      "156/156 - 3s - loss: 0.7514 - accuracy: 0.5097 - 3s/epoch - 21ms/step\n",
      "Epoch 3/1000\n",
      "156/156 - 3s - loss: 0.7422 - accuracy: 0.5039 - 3s/epoch - 21ms/step\n",
      "Epoch 4/1000\n",
      "156/156 - 3s - loss: 0.7284 - accuracy: 0.5077 - 3s/epoch - 21ms/step\n",
      "Epoch 5/1000\n",
      "156/156 - 3s - loss: 0.7310 - accuracy: 0.4955 - 3s/epoch - 21ms/step\n",
      "Epoch 6/1000\n",
      "156/156 - 3s - loss: 0.7245 - accuracy: 0.4997 - 3s/epoch - 21ms/step\n",
      "Epoch 7/1000\n",
      "156/156 - 3s - loss: 0.7261 - accuracy: 0.4937 - 3s/epoch - 21ms/step\n",
      "Epoch 8/1000\n",
      "156/156 - 3s - loss: 0.7263 - accuracy: 0.5003 - 3s/epoch - 21ms/step\n",
      "Epoch 9/1000\n",
      "156/156 - 3s - loss: 0.7383 - accuracy: 0.5031 - 3s/epoch - 21ms/step\n",
      "Epoch 10/1000\n",
      "156/156 - 5s - loss: 0.7182 - accuracy: 0.4935 - val_loss: 0.7045 - val_accuracy: 0.4978 - 5s/epoch - 30ms/step\n",
      "Epoch 11/1000\n",
      "156/156 - 3s - loss: 0.7087 - accuracy: 0.4953 - 3s/epoch - 20ms/step\n",
      "Epoch 12/1000\n",
      "156/156 - 3s - loss: 0.7218 - accuracy: 0.4997 - 3s/epoch - 21ms/step\n",
      "Epoch 13/1000\n",
      "156/156 - 3s - loss: 0.7296 - accuracy: 0.5021 - 3s/epoch - 21ms/step\n",
      "Epoch 14/1000\n",
      "156/156 - 3s - loss: 0.7072 - accuracy: 0.4961 - 3s/epoch - 21ms/step\n",
      "Epoch 15/1000\n",
      "156/156 - 3s - loss: 0.7163 - accuracy: 0.5021 - 3s/epoch - 22ms/step\n",
      "Epoch 16/1000\n",
      "156/156 - 3s - loss: 0.7048 - accuracy: 0.4961 - 3s/epoch - 21ms/step\n",
      "Epoch 17/1000\n",
      "156/156 - 3s - loss: 0.7045 - accuracy: 0.5005 - 3s/epoch - 21ms/step\n",
      "Epoch 18/1000\n",
      "156/156 - 3s - loss: 0.7054 - accuracy: 0.5001 - 3s/epoch - 20ms/step\n",
      "Epoch 19/1000\n",
      "156/156 - 3s - loss: 0.6999 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 20/1000\n",
      "156/156 - 4s - loss: 0.6971 - accuracy: 0.4977 - val_loss: 0.6937 - val_accuracy: 0.4978 - 4s/epoch - 26ms/step\n",
      "Epoch 21/1000\n",
      "156/156 - 3s - loss: 0.6970 - accuracy: 0.4961 - 3s/epoch - 21ms/step\n",
      "Epoch 22/1000\n",
      "156/156 - 3s - loss: 0.6947 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 23/1000\n",
      "156/156 - 3s - loss: 0.6961 - accuracy: 0.4981 - 3s/epoch - 21ms/step\n",
      "Epoch 24/1000\n",
      "156/156 - 3s - loss: 0.6952 - accuracy: 0.4993 - 3s/epoch - 21ms/step\n",
      "Epoch 25/1000\n",
      "156/156 - 3s - loss: 0.6948 - accuracy: 0.4981 - 3s/epoch - 21ms/step\n",
      "Epoch 26/1000\n",
      "156/156 - 3s - loss: 0.6954 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 27/1000\n",
      "156/156 - 3s - loss: 0.6952 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 28/1000\n",
      "156/156 - 3s - loss: 0.6951 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 29/1000\n",
      "156/156 - 3s - loss: 0.6947 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 30/1000\n",
      "156/156 - 4s - loss: 0.6941 - accuracy: 0.4977 - val_loss: 0.6932 - val_accuracy: 0.4978 - 4s/epoch - 27ms/step\n",
      "Epoch 31/1000\n",
      "156/156 - 3s - loss: 0.6951 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 32/1000\n",
      "156/156 - 3s - loss: 0.6932 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 33/1000\n",
      "156/156 - 3s - loss: 0.6935 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 34/1000\n",
      "156/156 - 3s - loss: 0.6931 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 35/1000\n",
      "156/156 - 3s - loss: 0.6936 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 36/1000\n",
      "156/156 - 3s - loss: 0.6940 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 37/1000\n",
      "156/156 - 3s - loss: 0.6942 - accuracy: 0.4977 - 3s/epoch - 21ms/step\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x14e4fd7f7760>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/apps/python-3.10.2/lib/python3.10/weakref.py\", line 370, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/shivam_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc.fit(X_train, Y_train, epochs=1000, batch_size=32, validation_data=(X_test, Y_test), validation_freq=10, verbose=2, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"final_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  10504192  \n",
      "                                                                 \n",
      " dense_19 (Dense)            multiple                  513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,504,705\n",
      "Trainable params: 10,504,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 08:45:42.045044: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 08:45:42.192698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:45:42.192739: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-05 08:45:44.345830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:45:44.345947: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:45:44.345959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Create a LSTM model to predict the next bit of a LFSR\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def create_data(num_samples=10000, initial_key1=None, initial_key2=None, ln=5):\n",
    "    if initial_key1 is None:\n",
    "        initial_key1 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 1: \", initial_key1)\n",
    "    if initial_key2 is None:\n",
    "        initial_key2 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 2: \", initial_key2)\n",
    "\n",
    "    # data = initial_key\n",
    "    key1 = initial_key1\n",
    "    key2 = initial_key2\n",
    "    x = []\n",
    "    y = []\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        nxt1 = key1[0] ^ key1[1]\n",
    "        nxt2 = key2[0] ^ key2[2]\n",
    "        data.append(nxt1 ^ nxt2)\n",
    "        if len(data) >= ln + 1:\n",
    "            x.append(data[-(ln + 1) : -1])\n",
    "            y.append(data[-1])\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key1[-1] = nxt1\n",
    "        key2[-1] = nxt2\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990, 10)\n"
     ]
    }
   ],
   "source": [
    "ln = 10\n",
    "X, Y = create_data(\n",
    "    10000,\n",
    "    ln=ln,\n",
    "    initial_key1=np.array([1, 0, 1, 1, 1]),\n",
    "    initial_key2=np.array([1, 1, 1, 0, 1]),\n",
    ")\n",
    "X_train, Y_train = X[: 500 - ln], Y[: 500 - ln]\n",
    "X_test, Y_test = X[500 - ln :], Y[500 - ln :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 200)               40400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,601\n",
      "Trainable params: 40,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 08:46:14.252547: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:46:14.252758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:46:14.252901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:46:14.253034: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:46:14.303934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 08:46:14.304142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-04-05 08:46:14.304731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # tf.keras.layers.GRU(300, input_shape=(ln, 1)),\n",
    "        tf.keras.layers.SimpleRNN(200, input_shape=(ln, 1), activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "        # tf.keras.layers.Embedding(2, 5, input_length=5),\n",
    "        # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, input_shape=(ln, 1))),\n",
    "        # tf.keras.layers.LSTM(100, input_shape=(ln, 1), activation=\"sigmoid\", recurrent_activation=\"sigmoid\"),\n",
    "        # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        # tf.keras.layers.Conv1D(100, 3, 1, input_shape=(ln, 1), activation=\"relu\"),\n",
    "        # tf.keras.layers.Conv1D(200, 3, 1, activation=\"relu\"),\n",
    "        # tf.keras.layers.Conv1D(400, 3, 1, activation=\"relu\"),\n",
    "        # tf.keras.layers.MaxPooling1D(3),\n",
    "        # tf.keras.layers.Flatten(),\n",
    "        # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 2s - loss: 0.6981 - accuracy: 0.4776 - val_loss: 0.6940 - val_accuracy: 0.5088 - 2s/epoch - 136ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 1s - loss: 0.6941 - accuracy: 0.4918 - val_loss: 0.6926 - val_accuracy: 0.5175 - 827ms/epoch - 52ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 1s - loss: 0.6921 - accuracy: 0.5204 - val_loss: 0.6927 - val_accuracy: 0.5208 - 845ms/epoch - 53ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 1s - loss: 0.6934 - accuracy: 0.5102 - val_loss: 0.6925 - val_accuracy: 0.5217 - 850ms/epoch - 53ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 1s - loss: 0.6921 - accuracy: 0.5041 - val_loss: 0.6919 - val_accuracy: 0.5151 - 845ms/epoch - 53ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 1s - loss: 0.6911 - accuracy: 0.5265 - val_loss: 0.6916 - val_accuracy: 0.5125 - 854ms/epoch - 53ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 1s - loss: 0.6893 - accuracy: 0.5469 - val_loss: 0.6904 - val_accuracy: 0.5345 - 843ms/epoch - 53ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 1s - loss: 0.6862 - accuracy: 0.5612 - val_loss: 0.6898 - val_accuracy: 0.5253 - 842ms/epoch - 53ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 1s - loss: 0.6848 - accuracy: 0.5735 - val_loss: 0.6879 - val_accuracy: 0.5469 - 853ms/epoch - 53ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 1s - loss: 0.6819 - accuracy: 0.5714 - val_loss: 0.6856 - val_accuracy: 0.5364 - 855ms/epoch - 53ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 1s - loss: 0.6778 - accuracy: 0.5959 - val_loss: 0.6824 - val_accuracy: 0.5555 - 862ms/epoch - 54ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 1s - loss: 0.6698 - accuracy: 0.5918 - val_loss: 0.6764 - val_accuracy: 0.5764 - 849ms/epoch - 53ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 1s - loss: 0.6571 - accuracy: 0.6347 - val_loss: 0.6685 - val_accuracy: 0.6075 - 857ms/epoch - 54ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 1s - loss: 0.6433 - accuracy: 0.6592 - val_loss: 0.6541 - val_accuracy: 0.6348 - 848ms/epoch - 53ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 1s - loss: 0.6188 - accuracy: 0.6878 - val_loss: 0.6492 - val_accuracy: 0.6506 - 872ms/epoch - 54ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 1s - loss: 0.5915 - accuracy: 0.7388 - val_loss: 0.6048 - val_accuracy: 0.7261 - 834ms/epoch - 52ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 1s - loss: 0.5363 - accuracy: 0.7857 - val_loss: 0.5514 - val_accuracy: 0.7794 - 872ms/epoch - 54ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 1s - loss: 0.4678 - accuracy: 0.8224 - val_loss: 0.4765 - val_accuracy: 0.8165 - 871ms/epoch - 54ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 1s - loss: 0.3998 - accuracy: 0.8592 - val_loss: 0.3624 - val_accuracy: 0.8925 - 855ms/epoch - 53ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 1s - loss: 0.2954 - accuracy: 0.9286 - val_loss: 0.2627 - val_accuracy: 0.9187 - 840ms/epoch - 53ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 1s - loss: 0.1942 - accuracy: 0.9571 - val_loss: 0.1644 - val_accuracy: 0.9626 - 850ms/epoch - 53ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 1s - loss: 0.1123 - accuracy: 0.9796 - val_loss: 0.1199 - val_accuracy: 0.9780 - 836ms/epoch - 52ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 1s - loss: 0.0742 - accuracy: 0.9898 - val_loss: 0.0776 - val_accuracy: 0.9843 - 852ms/epoch - 53ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 1s - loss: 0.0405 - accuracy: 0.9980 - val_loss: 0.0615 - val_accuracy: 0.9891 - 858ms/epoch - 54ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9953 - 848ms/epoch - 53ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9953 - 829ms/epoch - 52ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9953 - 835ms/epoch - 52ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9953 - 841ms/epoch - 53ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9953 - 845ms/epoch - 53ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9953 - 861ms/epoch - 54ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9953 - 843ms/epoch - 53ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9953 - 844ms/epoch - 53ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 1s - loss: 9.6220e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9953 - 838ms/epoch - 52ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 1s - loss: 8.7211e-04 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9953 - 869ms/epoch - 54ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 1s - loss: 7.9111e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9953 - 851ms/epoch - 53ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 1s - loss: 7.3133e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9953 - 854ms/epoch - 53ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 1s - loss: 6.7274e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9953 - 826ms/epoch - 52ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 1s - loss: 6.2356e-04 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9953 - 851ms/epoch - 53ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 1s - loss: 5.8051e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9953 - 849ms/epoch - 53ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 1s - loss: 5.4503e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9953 - 855ms/epoch - 53ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 1s - loss: 5.0610e-04 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9953 - 846ms/epoch - 53ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 1s - loss: 4.7671e-04 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9953 - 832ms/epoch - 52ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 1s - loss: 4.4611e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9953 - 846ms/epoch - 53ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 1s - loss: 4.2205e-04 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9953 - 841ms/epoch - 53ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 1s - loss: 3.9770e-04 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9953 - 848ms/epoch - 53ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 1s - loss: 3.7679e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9953 - 852ms/epoch - 53ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 1s - loss: 3.5741e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9953 - 850ms/epoch - 53ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 1s - loss: 3.3916e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9953 - 855ms/epoch - 53ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 1s - loss: 3.2350e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9953 - 857ms/epoch - 54ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 1s - loss: 3.0713e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9953 - 837ms/epoch - 52ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 1s - loss: 2.9406e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9953 - 863ms/epoch - 54ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 1s - loss: 2.8074e-04 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9953 - 835ms/epoch - 52ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 1s - loss: 2.6855e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9953 - 844ms/epoch - 53ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 1s - loss: 2.5828e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9953 - 825ms/epoch - 52ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 1s - loss: 2.4619e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9953 - 854ms/epoch - 53ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 1s - loss: 2.3568e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9953 - 851ms/epoch - 53ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 1s - loss: 2.2657e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9953 - 850ms/epoch - 53ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 1s - loss: 2.1829e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9953 - 867ms/epoch - 54ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 1s - loss: 2.0881e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9953 - 838ms/epoch - 52ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 1s - loss: 2.0119e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9953 - 847ms/epoch - 53ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 1s - loss: 1.9434e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9953 - 830ms/epoch - 52ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 1s - loss: 1.8540e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9953 - 860ms/epoch - 54ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 1s - loss: 1.7984e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9953 - 839ms/epoch - 52ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 1s - loss: 1.7359e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9953 - 864ms/epoch - 54ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 1s - loss: 1.6721e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9953 - 853ms/epoch - 53ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 1s - loss: 1.6122e-04 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9953 - 820ms/epoch - 51ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 1s - loss: 1.5602e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9953 - 842ms/epoch - 53ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 1s - loss: 1.5135e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9953 - 836ms/epoch - 52ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 1s - loss: 1.4632e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9953 - 843ms/epoch - 53ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 1s - loss: 1.4254e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 850ms/epoch - 53ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 1s - loss: 1.3879e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9953 - 841ms/epoch - 53ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 1s - loss: 1.3317e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9953 - 856ms/epoch - 53ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 1s - loss: 1.2935e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9953 - 870ms/epoch - 54ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 1s - loss: 1.2519e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 1s/epoch - 86ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 1s - loss: 1.2178e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9953 - 851ms/epoch - 53ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 1s - loss: 1.1836e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9953 - 869ms/epoch - 54ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 1s - loss: 1.1439e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 857ms/epoch - 54ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 1s - loss: 1.1142e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 850ms/epoch - 53ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 1s - loss: 1.0834e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 858ms/epoch - 54ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 1s - loss: 1.0518e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 856ms/epoch - 54ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 1s - loss: 1.0224e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 860ms/epoch - 54ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 1s - loss: 9.9633e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 824ms/epoch - 52ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 1s - loss: 9.7038e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 853ms/epoch - 53ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 1s - loss: 9.4679e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 866ms/epoch - 54ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 1s - loss: 9.2338e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9953 - 843ms/epoch - 53ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 1s - loss: 8.9630e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 857ms/epoch - 54ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 1s - loss: 8.7564e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 855ms/epoch - 53ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 1s - loss: 8.5429e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9953 - 833ms/epoch - 52ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 1s - loss: 8.3176e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9953 - 847ms/epoch - 53ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 1s - loss: 8.1427e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9953 - 845ms/epoch - 53ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 1s - loss: 7.9247e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9953 - 838ms/epoch - 52ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 1s - loss: 7.7480e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9953 - 847ms/epoch - 53ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 1s - loss: 7.5391e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9953 - 857ms/epoch - 54ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 1s - loss: 7.3811e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9953 - 844ms/epoch - 53ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 1s - loss: 7.1861e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9953 - 842ms/epoch - 53ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 1s - loss: 7.0471e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9953 - 842ms/epoch - 53ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 1s - loss: 6.8677e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9953 - 852ms/epoch - 53ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 1s - loss: 6.7162e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9953 - 850ms/epoch - 53ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 1s - loss: 6.5604e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9953 - 841ms/epoch - 53ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 1s - loss: 6.4214e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9953 - 859ms/epoch - 54ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1469cceee050>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.7024 - accuracy: 0.4579 - val_loss: 0.6944 - val_accuracy: 0.4989 - 2s/epoch - 80ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6938 - accuracy: 0.4830 - val_loss: 0.6933 - val_accuracy: 0.5045 - 674ms/epoch - 27ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6935 - accuracy: 0.4981 - val_loss: 0.6934 - val_accuracy: 0.5028 - 660ms/epoch - 26ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6932 - accuracy: 0.5057 - val_loss: 0.6934 - val_accuracy: 0.5063 - 668ms/epoch - 27ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6933 - accuracy: 0.5094 - val_loss: 0.6932 - val_accuracy: 0.5062 - 650ms/epoch - 26ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5233 - val_loss: 0.6936 - val_accuracy: 0.5030 - 668ms/epoch - 27ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5208 - val_loss: 0.6933 - val_accuracy: 0.5079 - 694ms/epoch - 28ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5182 - val_loss: 0.6933 - val_accuracy: 0.5063 - 656ms/epoch - 26ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5220 - val_loss: 0.6933 - val_accuracy: 0.5095 - 715ms/epoch - 29ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5182 - val_loss: 0.6933 - val_accuracy: 0.5063 - 656ms/epoch - 26ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5245 - val_loss: 0.6934 - val_accuracy: 0.5110 - 682ms/epoch - 27ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6928 - accuracy: 0.5094 - val_loss: 0.6934 - val_accuracy: 0.5080 - 651ms/epoch - 26ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5195 - val_loss: 0.6929 - val_accuracy: 0.5140 - 677ms/epoch - 27ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5296 - val_loss: 0.6932 - val_accuracy: 0.5129 - 658ms/epoch - 26ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5270 - val_loss: 0.6930 - val_accuracy: 0.5110 - 662ms/epoch - 26ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5283 - val_loss: 0.6932 - val_accuracy: 0.5111 - 649ms/epoch - 26ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5233 - val_loss: 0.6931 - val_accuracy: 0.5126 - 659ms/epoch - 26ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5296 - val_loss: 0.6931 - val_accuracy: 0.5142 - 683ms/epoch - 27ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5132 - val_loss: 0.6928 - val_accuracy: 0.5126 - 675ms/epoch - 27ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5195 - val_loss: 0.6927 - val_accuracy: 0.5114 - 674ms/epoch - 27ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5296 - val_loss: 0.6928 - val_accuracy: 0.5128 - 670ms/epoch - 27ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5245 - val_loss: 0.6929 - val_accuracy: 0.5145 - 697ms/epoch - 28ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5208 - val_loss: 0.6931 - val_accuracy: 0.5110 - 659ms/epoch - 26ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5245 - val_loss: 0.6927 - val_accuracy: 0.5145 - 666ms/epoch - 27ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5346 - val_loss: 0.6928 - val_accuracy: 0.5128 - 672ms/epoch - 27ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5233 - val_loss: 0.6928 - val_accuracy: 0.5128 - 652ms/epoch - 26ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5321 - val_loss: 0.6931 - val_accuracy: 0.5146 - 692ms/epoch - 28ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5346 - val_loss: 0.6930 - val_accuracy: 0.5128 - 661ms/epoch - 26ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5296 - val_loss: 0.6928 - val_accuracy: 0.5128 - 664ms/epoch - 27ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5346 - val_loss: 0.6929 - val_accuracy: 0.5128 - 659ms/epoch - 26ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5321 - val_loss: 0.6931 - val_accuracy: 0.5145 - 666ms/epoch - 27ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5283 - val_loss: 0.6930 - val_accuracy: 0.5128 - 659ms/epoch - 26ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5333 - val_loss: 0.6928 - val_accuracy: 0.5129 - 656ms/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6927 - val_accuracy: 0.5145 - 670ms/epoch - 27ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6924 - accuracy: 0.5296 - val_loss: 0.6931 - val_accuracy: 0.5146 - 643ms/epoch - 26ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5296 - val_loss: 0.6928 - val_accuracy: 0.5160 - 675ms/epoch - 27ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5333 - val_loss: 0.6926 - val_accuracy: 0.5128 - 670ms/epoch - 27ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5270 - val_loss: 0.6930 - val_accuracy: 0.5128 - 675ms/epoch - 27ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5296 - val_loss: 0.6929 - val_accuracy: 0.5145 - 681ms/epoch - 27ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5245 - val_loss: 0.6928 - val_accuracy: 0.5145 - 675ms/epoch - 27ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5308 - val_loss: 0.6930 - val_accuracy: 0.5128 - 675ms/epoch - 27ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5308 - val_loss: 0.6929 - val_accuracy: 0.5128 - 657ms/epoch - 26ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5270 - val_loss: 0.6929 - val_accuracy: 0.5145 - 666ms/epoch - 27ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5270 - val_loss: 0.6929 - val_accuracy: 0.5145 - 662ms/epoch - 26ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5258 - val_loss: 0.6933 - val_accuracy: 0.5129 - 662ms/epoch - 26ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5128 - 653ms/epoch - 26ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5296 - val_loss: 0.6929 - val_accuracy: 0.5128 - 659ms/epoch - 26ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5233 - val_loss: 0.6928 - val_accuracy: 0.5176 - 701ms/epoch - 28ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5346 - val_loss: 0.6930 - val_accuracy: 0.5129 - 640ms/epoch - 26ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5333 - val_loss: 0.6929 - val_accuracy: 0.5146 - 644ms/epoch - 26ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6931 - val_accuracy: 0.5143 - 677ms/epoch - 27ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5270 - val_loss: 0.6929 - val_accuracy: 0.5146 - 682ms/epoch - 27ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5270 - val_loss: 0.6928 - val_accuracy: 0.5161 - 692ms/epoch - 28ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5258 - val_loss: 0.6928 - val_accuracy: 0.5175 - 671ms/epoch - 27ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5358 - val_loss: 0.6928 - val_accuracy: 0.5175 - 672ms/epoch - 27ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5129 - 674ms/epoch - 27ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5358 - val_loss: 0.6930 - val_accuracy: 0.5146 - 657ms/epoch - 26ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5145 - val_loss: 0.6931 - val_accuracy: 0.5145 - 667ms/epoch - 27ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5146 - 667ms/epoch - 27ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5296 - val_loss: 0.6931 - val_accuracy: 0.5146 - 659ms/epoch - 26ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6930 - val_accuracy: 0.5145 - 651ms/epoch - 26ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5296 - val_loss: 0.6928 - val_accuracy: 0.5146 - 670ms/epoch - 27ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5346 - val_loss: 0.6929 - val_accuracy: 0.5146 - 660ms/epoch - 26ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5283 - val_loss: 0.6930 - val_accuracy: 0.5128 - 663ms/epoch - 27ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5245 - val_loss: 0.6929 - val_accuracy: 0.5145 - 667ms/epoch - 27ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5296 - val_loss: 0.6931 - val_accuracy: 0.5146 - 653ms/epoch - 26ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5270 - val_loss: 0.6929 - val_accuracy: 0.5129 - 669ms/epoch - 27ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5258 - val_loss: 0.6929 - val_accuracy: 0.5176 - 659ms/epoch - 26ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5146 - 681ms/epoch - 27ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5321 - val_loss: 0.6929 - val_accuracy: 0.5146 - 677ms/epoch - 27ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5283 - val_loss: 0.6931 - val_accuracy: 0.5145 - 653ms/epoch - 26ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5396 - val_loss: 0.6930 - val_accuracy: 0.5146 - 668ms/epoch - 27ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5371 - val_loss: 0.6931 - val_accuracy: 0.5146 - 660ms/epoch - 26ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5384 - val_loss: 0.6931 - val_accuracy: 0.5146 - 665ms/epoch - 27ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5283 - val_loss: 0.6931 - val_accuracy: 0.5191 - 697ms/epoch - 28ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5146 - 661ms/epoch - 26ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5283 - val_loss: 0.6929 - val_accuracy: 0.5146 - 668ms/epoch - 27ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5371 - val_loss: 0.6930 - val_accuracy: 0.5146 - 667ms/epoch - 27ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5346 - val_loss: 0.6931 - val_accuracy: 0.5129 - 682ms/epoch - 27ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5245 - val_loss: 0.6929 - val_accuracy: 0.5129 - 646ms/epoch - 26ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5333 - val_loss: 0.6929 - val_accuracy: 0.5146 - 657ms/epoch - 26ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5371 - val_loss: 0.6929 - val_accuracy: 0.5129 - 662ms/epoch - 26ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5371 - val_loss: 0.6931 - val_accuracy: 0.5129 - 660ms/epoch - 26ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5333 - val_loss: 0.6931 - val_accuracy: 0.5145 - 668ms/epoch - 27ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5270 - val_loss: 0.6932 - val_accuracy: 0.5160 - 681ms/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5145 - 660ms/epoch - 26ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5308 - val_loss: 0.6930 - val_accuracy: 0.5145 - 664ms/epoch - 27ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5333 - val_loss: 0.6932 - val_accuracy: 0.5129 - 672ms/epoch - 27ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5270 - val_loss: 0.6930 - val_accuracy: 0.5146 - 676ms/epoch - 27ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5371 - val_loss: 0.6930 - val_accuracy: 0.5129 - 677ms/epoch - 27ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5358 - val_loss: 0.6931 - val_accuracy: 0.5146 - 649ms/epoch - 26ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5321 - val_loss: 0.6928 - val_accuracy: 0.5146 - 691ms/epoch - 28ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5358 - val_loss: 0.6929 - val_accuracy: 0.5145 - 674ms/epoch - 27ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5296 - val_loss: 0.6931 - val_accuracy: 0.5160 - 665ms/epoch - 27ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5296 - val_loss: 0.6932 - val_accuracy: 0.5176 - 671ms/epoch - 27ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5358 - val_loss: 0.6930 - val_accuracy: 0.5176 - 663ms/epoch - 27ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5308 - val_loss: 0.6930 - val_accuracy: 0.5175 - 664ms/epoch - 27ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5358 - val_loss: 0.6931 - val_accuracy: 0.5175 - 673ms/epoch - 27ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5358 - val_loss: 0.6931 - val_accuracy: 0.5176 - 639ms/epoch - 26ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5283 - val_loss: 0.6930 - val_accuracy: 0.5129 - 668ms/epoch - 27ms/step\n",
      "288/288 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5191\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6966 - accuracy: 0.4610 - val_loss: 0.6935 - val_accuracy: 0.5008 - 2s/epoch - 78ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6947 - accuracy: 0.5113 - val_loss: 0.6942 - val_accuracy: 0.5015 - 726ms/epoch - 29ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5017 - 724ms/epoch - 29ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6934 - accuracy: 0.5164 - val_loss: 0.6936 - val_accuracy: 0.5012 - 721ms/epoch - 29ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6939 - accuracy: 0.4924 - val_loss: 0.6939 - val_accuracy: 0.5047 - 736ms/epoch - 29ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5176 - val_loss: 0.6937 - val_accuracy: 0.4996 - 700ms/epoch - 28ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5189 - val_loss: 0.6936 - val_accuracy: 0.5062 - 734ms/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6933 - accuracy: 0.4962 - val_loss: 0.6933 - val_accuracy: 0.5062 - 679ms/epoch - 27ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6928 - accuracy: 0.5025 - val_loss: 0.6935 - val_accuracy: 0.5064 - 709ms/epoch - 28ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5101 - val_loss: 0.6934 - val_accuracy: 0.5091 - 735ms/epoch - 29ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5264 - val_loss: 0.6933 - val_accuracy: 0.5075 - 693ms/epoch - 28ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5252 - val_loss: 0.6931 - val_accuracy: 0.5105 - 717ms/epoch - 29ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5091 - 698ms/epoch - 28ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6934 - val_accuracy: 0.5167 - 742ms/epoch - 30ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5353 - val_loss: 0.6934 - val_accuracy: 0.5107 - 731ms/epoch - 29ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5353 - val_loss: 0.6930 - val_accuracy: 0.5137 - 705ms/epoch - 28ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5327 - val_loss: 0.6931 - val_accuracy: 0.5136 - 712ms/epoch - 28ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5227 - val_loss: 0.6932 - val_accuracy: 0.5149 - 719ms/epoch - 29ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5390 - val_loss: 0.6929 - val_accuracy: 0.5168 - 738ms/epoch - 30ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5302 - val_loss: 0.6931 - val_accuracy: 0.5168 - 708ms/epoch - 28ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5378 - val_loss: 0.6931 - val_accuracy: 0.5166 - 722ms/epoch - 29ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5353 - val_loss: 0.6926 - val_accuracy: 0.5166 - 725ms/epoch - 29ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5365 - val_loss: 0.6931 - val_accuracy: 0.5168 - 697ms/epoch - 28ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6929 - val_accuracy: 0.5180 - 736ms/epoch - 29ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5353 - val_loss: 0.6927 - val_accuracy: 0.5183 - 760ms/epoch - 30ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5365 - val_loss: 0.6928 - val_accuracy: 0.5180 - 699ms/epoch - 28ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5182 - 682ms/epoch - 27ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5327 - val_loss: 0.6927 - val_accuracy: 0.5173 - 713ms/epoch - 29ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5491 - val_loss: 0.6925 - val_accuracy: 0.5172 - 695ms/epoch - 28ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5302 - val_loss: 0.6926 - val_accuracy: 0.5203 - 720ms/epoch - 29ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6899 - accuracy: 0.5403 - val_loss: 0.6924 - val_accuracy: 0.5183 - 713ms/epoch - 29ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5428 - val_loss: 0.6931 - val_accuracy: 0.5201 - 713ms/epoch - 29ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6897 - accuracy: 0.5378 - val_loss: 0.6921 - val_accuracy: 0.5217 - 732ms/epoch - 29ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5479 - val_loss: 0.6926 - val_accuracy: 0.5200 - 717ms/epoch - 29ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5441 - val_loss: 0.6928 - val_accuracy: 0.5166 - 696ms/epoch - 28ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5390 - val_loss: 0.6923 - val_accuracy: 0.5216 - 690ms/epoch - 28ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6889 - accuracy: 0.5441 - val_loss: 0.6925 - val_accuracy: 0.5217 - 702ms/epoch - 28ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5479 - val_loss: 0.6924 - val_accuracy: 0.5217 - 690ms/epoch - 28ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5441 - val_loss: 0.6922 - val_accuracy: 0.5217 - 710ms/epoch - 28ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6896 - accuracy: 0.5403 - val_loss: 0.6924 - val_accuracy: 0.5200 - 703ms/epoch - 28ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5403 - val_loss: 0.6926 - val_accuracy: 0.5218 - 727ms/epoch - 29ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6900 - accuracy: 0.5504 - val_loss: 0.6926 - val_accuracy: 0.5200 - 691ms/epoch - 28ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5479 - val_loss: 0.6926 - val_accuracy: 0.5216 - 692ms/epoch - 28ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6887 - accuracy: 0.5416 - val_loss: 0.6924 - val_accuracy: 0.5200 - 697ms/epoch - 28ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5416 - val_loss: 0.6922 - val_accuracy: 0.5201 - 708ms/epoch - 28ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6892 - accuracy: 0.5491 - val_loss: 0.6926 - val_accuracy: 0.5202 - 704ms/epoch - 28ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5479 - val_loss: 0.6921 - val_accuracy: 0.5218 - 705ms/epoch - 28ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5504 - val_loss: 0.6924 - val_accuracy: 0.5217 - 687ms/epoch - 27ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5491 - val_loss: 0.6925 - val_accuracy: 0.5201 - 700ms/epoch - 28ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6897 - accuracy: 0.5516 - val_loss: 0.6930 - val_accuracy: 0.5218 - 699ms/epoch - 28ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5529 - val_loss: 0.6919 - val_accuracy: 0.5217 - 705ms/epoch - 28ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6888 - accuracy: 0.5416 - val_loss: 0.6925 - val_accuracy: 0.5201 - 689ms/epoch - 28ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6892 - accuracy: 0.5453 - val_loss: 0.6930 - val_accuracy: 0.5218 - 692ms/epoch - 28ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6886 - accuracy: 0.5504 - val_loss: 0.6921 - val_accuracy: 0.5217 - 714ms/epoch - 29ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5504 - val_loss: 0.6923 - val_accuracy: 0.5218 - 714ms/epoch - 29ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6889 - accuracy: 0.5529 - val_loss: 0.6921 - val_accuracy: 0.5201 - 709ms/epoch - 28ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6888 - accuracy: 0.5542 - val_loss: 0.6928 - val_accuracy: 0.5218 - 718ms/epoch - 29ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5529 - val_loss: 0.6922 - val_accuracy: 0.5264 - 748ms/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6882 - accuracy: 0.5554 - val_loss: 0.6924 - val_accuracy: 0.5235 - 706ms/epoch - 28ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6879 - accuracy: 0.5567 - val_loss: 0.6925 - val_accuracy: 0.5218 - 710ms/epoch - 28ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5403 - val_loss: 0.6923 - val_accuracy: 0.5218 - 713ms/epoch - 29ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6879 - accuracy: 0.5542 - val_loss: 0.6929 - val_accuracy: 0.5218 - 701ms/epoch - 28ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6885 - accuracy: 0.5428 - val_loss: 0.6922 - val_accuracy: 0.5250 - 702ms/epoch - 28ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6882 - accuracy: 0.5504 - val_loss: 0.6928 - val_accuracy: 0.5218 - 698ms/epoch - 28ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6878 - accuracy: 0.5453 - val_loss: 0.6921 - val_accuracy: 0.5250 - 702ms/epoch - 28ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6876 - accuracy: 0.5491 - val_loss: 0.6925 - val_accuracy: 0.5218 - 689ms/epoch - 28ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6877 - accuracy: 0.5542 - val_loss: 0.6924 - val_accuracy: 0.5218 - 725ms/epoch - 29ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6880 - accuracy: 0.5504 - val_loss: 0.6927 - val_accuracy: 0.5218 - 710ms/epoch - 28ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6880 - accuracy: 0.5479 - val_loss: 0.6925 - val_accuracy: 0.5218 - 724ms/epoch - 29ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6886 - accuracy: 0.5491 - val_loss: 0.6925 - val_accuracy: 0.5235 - 728ms/epoch - 29ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6875 - accuracy: 0.5542 - val_loss: 0.6924 - val_accuracy: 0.5218 - 708ms/epoch - 28ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6880 - accuracy: 0.5542 - val_loss: 0.6926 - val_accuracy: 0.5218 - 699ms/epoch - 28ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6873 - accuracy: 0.5542 - val_loss: 0.6925 - val_accuracy: 0.5250 - 701ms/epoch - 28ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6876 - accuracy: 0.5554 - val_loss: 0.6927 - val_accuracy: 0.5218 - 724ms/epoch - 29ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5504 - val_loss: 0.6928 - val_accuracy: 0.5218 - 696ms/epoch - 28ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5554 - val_loss: 0.6924 - val_accuracy: 0.5234 - 721ms/epoch - 29ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6876 - accuracy: 0.5491 - val_loss: 0.6924 - val_accuracy: 0.5233 - 702ms/epoch - 28ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5516 - val_loss: 0.6929 - val_accuracy: 0.5218 - 694ms/epoch - 28ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6879 - accuracy: 0.5542 - val_loss: 0.6934 - val_accuracy: 0.5218 - 709ms/epoch - 28ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5516 - val_loss: 0.6930 - val_accuracy: 0.5233 - 706ms/epoch - 28ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6882 - accuracy: 0.5479 - val_loss: 0.6925 - val_accuracy: 0.5218 - 682ms/epoch - 27ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6877 - accuracy: 0.5479 - val_loss: 0.6924 - val_accuracy: 0.5282 - 727ms/epoch - 29ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5504 - val_loss: 0.6926 - val_accuracy: 0.5234 - 710ms/epoch - 28ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5504 - val_loss: 0.6927 - val_accuracy: 0.5250 - 709ms/epoch - 28ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5516 - val_loss: 0.6926 - val_accuracy: 0.5234 - 716ms/epoch - 29ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6878 - accuracy: 0.5479 - val_loss: 0.6930 - val_accuracy: 0.5250 - 692ms/epoch - 28ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6876 - accuracy: 0.5529 - val_loss: 0.6923 - val_accuracy: 0.5250 - 697ms/epoch - 28ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6880 - accuracy: 0.5504 - val_loss: 0.6928 - val_accuracy: 0.5233 - 705ms/epoch - 28ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5504 - val_loss: 0.6925 - val_accuracy: 0.5218 - 704ms/epoch - 28ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6870 - accuracy: 0.5479 - val_loss: 0.6924 - val_accuracy: 0.5234 - 695ms/epoch - 28ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6877 - accuracy: 0.5516 - val_loss: 0.6931 - val_accuracy: 0.5234 - 696ms/epoch - 28ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5529 - val_loss: 0.6924 - val_accuracy: 0.5218 - 686ms/epoch - 27ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5491 - val_loss: 0.6925 - val_accuracy: 0.5250 - 699ms/epoch - 28ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6881 - accuracy: 0.5504 - val_loss: 0.6929 - val_accuracy: 0.5234 - 717ms/epoch - 29ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6880 - accuracy: 0.5453 - val_loss: 0.6922 - val_accuracy: 0.5235 - 704ms/epoch - 28ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5491 - val_loss: 0.6926 - val_accuracy: 0.5234 - 690ms/epoch - 28ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5542 - val_loss: 0.6926 - val_accuracy: 0.5250 - 704ms/epoch - 28ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6869 - accuracy: 0.5542 - val_loss: 0.6926 - val_accuracy: 0.5235 - 702ms/epoch - 28ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6875 - accuracy: 0.5529 - val_loss: 0.6928 - val_accuracy: 0.5218 - 707ms/epoch - 28ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6869 - accuracy: 0.5491 - val_loss: 0.6931 - val_accuracy: 0.5218 - 714ms/epoch - 29ms/step\n",
      "288/288 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5282\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6973 - accuracy: 0.4792 - val_loss: 0.6941 - val_accuracy: 0.5002 - 2s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6945 - accuracy: 0.4968 - val_loss: 0.6938 - val_accuracy: 0.5036 - 769ms/epoch - 31ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6936 - accuracy: 0.5069 - val_loss: 0.6942 - val_accuracy: 0.4996 - 754ms/epoch - 30ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6941 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5095 - 778ms/epoch - 31ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6932 - accuracy: 0.5132 - val_loss: 0.6938 - val_accuracy: 0.5000 - 746ms/epoch - 30ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6931 - accuracy: 0.5095 - val_loss: 0.6932 - val_accuracy: 0.5078 - 744ms/epoch - 30ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6933 - val_accuracy: 0.5047 - 727ms/epoch - 29ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5152 - 777ms/epoch - 31ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6937 - val_accuracy: 0.5107 - 727ms/epoch - 29ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5208 - val_loss: 0.6929 - val_accuracy: 0.5095 - 743ms/epoch - 30ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5271 - val_loss: 0.6934 - val_accuracy: 0.5124 - 742ms/epoch - 30ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5082 - val_loss: 0.6926 - val_accuracy: 0.5220 - 771ms/epoch - 31ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5271 - val_loss: 0.6926 - val_accuracy: 0.5142 - 750ms/epoch - 30ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6927 - val_accuracy: 0.5125 - 736ms/epoch - 29ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5170 - val_loss: 0.6927 - val_accuracy: 0.5140 - 732ms/epoch - 29ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5246 - val_loss: 0.6922 - val_accuracy: 0.5200 - 751ms/epoch - 30ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5111 - 776ms/epoch - 31ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5234 - 772ms/epoch - 31ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5309 - val_loss: 0.6922 - val_accuracy: 0.5168 - 757ms/epoch - 30ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5334 - val_loss: 0.6916 - val_accuracy: 0.5262 - 793ms/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5253 - 741ms/epoch - 30ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5322 - val_loss: 0.6917 - val_accuracy: 0.5276 - 797ms/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6895 - accuracy: 0.5448 - val_loss: 0.6920 - val_accuracy: 0.5216 - 722ms/epoch - 29ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5309 - val_loss: 0.6913 - val_accuracy: 0.5285 - 797ms/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6889 - accuracy: 0.5309 - val_loss: 0.6921 - val_accuracy: 0.5229 - 743ms/epoch - 30ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5309 - val_loss: 0.6913 - val_accuracy: 0.5268 - 748ms/epoch - 30ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6890 - accuracy: 0.5334 - val_loss: 0.6914 - val_accuracy: 0.5259 - 759ms/epoch - 30ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6876 - accuracy: 0.5397 - val_loss: 0.6912 - val_accuracy: 0.5313 - 785ms/epoch - 31ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6878 - accuracy: 0.5359 - val_loss: 0.6909 - val_accuracy: 0.5324 - 770ms/epoch - 31ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5460 - val_loss: 0.6910 - val_accuracy: 0.5282 - 766ms/epoch - 31ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6887 - accuracy: 0.5233 - val_loss: 0.6909 - val_accuracy: 0.5324 - 760ms/epoch - 30ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6860 - accuracy: 0.5485 - val_loss: 0.6904 - val_accuracy: 0.5328 - 792ms/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6871 - accuracy: 0.5448 - val_loss: 0.6902 - val_accuracy: 0.5374 - 783ms/epoch - 31ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6869 - accuracy: 0.5448 - val_loss: 0.6904 - val_accuracy: 0.5312 - 744ms/epoch - 30ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6851 - accuracy: 0.5460 - val_loss: 0.6897 - val_accuracy: 0.5314 - 744ms/epoch - 30ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6847 - accuracy: 0.5473 - val_loss: 0.6901 - val_accuracy: 0.5325 - 747ms/epoch - 30ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6861 - accuracy: 0.5435 - val_loss: 0.6900 - val_accuracy: 0.5341 - 755ms/epoch - 30ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6860 - accuracy: 0.5485 - val_loss: 0.6892 - val_accuracy: 0.5390 - 761ms/epoch - 30ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6846 - accuracy: 0.5460 - val_loss: 0.6894 - val_accuracy: 0.5390 - 745ms/epoch - 30ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6837 - accuracy: 0.5485 - val_loss: 0.6890 - val_accuracy: 0.5357 - 732ms/epoch - 29ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6853 - accuracy: 0.5485 - val_loss: 0.6892 - val_accuracy: 0.5435 - 780ms/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6838 - accuracy: 0.5485 - val_loss: 0.6886 - val_accuracy: 0.5433 - 746ms/epoch - 30ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6839 - accuracy: 0.5498 - val_loss: 0.6885 - val_accuracy: 0.5396 - 755ms/epoch - 30ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6841 - accuracy: 0.5460 - val_loss: 0.6883 - val_accuracy: 0.5408 - 764ms/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6825 - accuracy: 0.5460 - val_loss: 0.6893 - val_accuracy: 0.5374 - 752ms/epoch - 30ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6825 - accuracy: 0.5435 - val_loss: 0.6888 - val_accuracy: 0.5485 - 786ms/epoch - 31ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6820 - accuracy: 0.5586 - val_loss: 0.6879 - val_accuracy: 0.5470 - 783ms/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6814 - accuracy: 0.5599 - val_loss: 0.6880 - val_accuracy: 0.5470 - 752ms/epoch - 30ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6823 - accuracy: 0.5485 - val_loss: 0.6878 - val_accuracy: 0.5423 - 734ms/epoch - 29ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6806 - accuracy: 0.5586 - val_loss: 0.6876 - val_accuracy: 0.5453 - 740ms/epoch - 30ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6803 - accuracy: 0.5574 - val_loss: 0.6874 - val_accuracy: 0.5548 - 792ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6804 - accuracy: 0.5586 - val_loss: 0.6872 - val_accuracy: 0.5455 - 774ms/epoch - 31ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6806 - accuracy: 0.5675 - val_loss: 0.6871 - val_accuracy: 0.5500 - 771ms/epoch - 31ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6795 - accuracy: 0.5662 - val_loss: 0.6871 - val_accuracy: 0.5483 - 776ms/epoch - 31ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6815 - accuracy: 0.5549 - val_loss: 0.6873 - val_accuracy: 0.5453 - 775ms/epoch - 31ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6794 - accuracy: 0.5687 - val_loss: 0.6867 - val_accuracy: 0.5533 - 751ms/epoch - 30ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6792 - accuracy: 0.5574 - val_loss: 0.6864 - val_accuracy: 0.5528 - 748ms/epoch - 30ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6793 - accuracy: 0.5826 - val_loss: 0.6868 - val_accuracy: 0.5530 - 743ms/epoch - 30ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6785 - accuracy: 0.5612 - val_loss: 0.6861 - val_accuracy: 0.5530 - 755ms/epoch - 30ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6794 - accuracy: 0.5574 - val_loss: 0.6860 - val_accuracy: 0.5530 - 757ms/epoch - 30ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6782 - accuracy: 0.5649 - val_loss: 0.6860 - val_accuracy: 0.5564 - 798ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6778 - accuracy: 0.5687 - val_loss: 0.6863 - val_accuracy: 0.5515 - 756ms/epoch - 30ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6776 - accuracy: 0.5675 - val_loss: 0.6859 - val_accuracy: 0.5543 - 754ms/epoch - 30ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6782 - accuracy: 0.5725 - val_loss: 0.6862 - val_accuracy: 0.5548 - 749ms/epoch - 30ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6774 - accuracy: 0.5801 - val_loss: 0.6859 - val_accuracy: 0.5546 - 764ms/epoch - 31ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6770 - accuracy: 0.5738 - val_loss: 0.6858 - val_accuracy: 0.5560 - 755ms/epoch - 30ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6777 - accuracy: 0.5687 - val_loss: 0.6859 - val_accuracy: 0.5562 - 730ms/epoch - 29ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6767 - accuracy: 0.5725 - val_loss: 0.6860 - val_accuracy: 0.5545 - 744ms/epoch - 30ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6775 - accuracy: 0.5725 - val_loss: 0.6855 - val_accuracy: 0.5575 - 764ms/epoch - 31ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6767 - accuracy: 0.5700 - val_loss: 0.6852 - val_accuracy: 0.5576 - 788ms/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6772 - accuracy: 0.5700 - val_loss: 0.6856 - val_accuracy: 0.5559 - 753ms/epoch - 30ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6772 - accuracy: 0.5750 - val_loss: 0.6852 - val_accuracy: 0.5560 - 757ms/epoch - 30ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6761 - accuracy: 0.5763 - val_loss: 0.6855 - val_accuracy: 0.5543 - 748ms/epoch - 30ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6751 - accuracy: 0.5712 - val_loss: 0.6850 - val_accuracy: 0.5575 - 740ms/epoch - 30ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6767 - accuracy: 0.5725 - val_loss: 0.6856 - val_accuracy: 0.5560 - 754ms/epoch - 30ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6758 - accuracy: 0.5788 - val_loss: 0.6845 - val_accuracy: 0.5608 - 771ms/epoch - 31ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6767 - accuracy: 0.5675 - val_loss: 0.6853 - val_accuracy: 0.5546 - 752ms/epoch - 30ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6758 - accuracy: 0.5776 - val_loss: 0.6852 - val_accuracy: 0.5590 - 742ms/epoch - 30ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6757 - accuracy: 0.5813 - val_loss: 0.6845 - val_accuracy: 0.5591 - 743ms/epoch - 30ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6752 - accuracy: 0.5813 - val_loss: 0.6851 - val_accuracy: 0.5546 - 733ms/epoch - 29ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6759 - accuracy: 0.5788 - val_loss: 0.6849 - val_accuracy: 0.5591 - 766ms/epoch - 31ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6746 - accuracy: 0.5687 - val_loss: 0.6851 - val_accuracy: 0.5578 - 741ms/epoch - 30ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6757 - accuracy: 0.5599 - val_loss: 0.6849 - val_accuracy: 0.5592 - 756ms/epoch - 30ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6741 - accuracy: 0.5725 - val_loss: 0.6846 - val_accuracy: 0.5591 - 779ms/epoch - 31ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6758 - accuracy: 0.5649 - val_loss: 0.6843 - val_accuracy: 0.5591 - 760ms/epoch - 30ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6755 - accuracy: 0.5687 - val_loss: 0.6844 - val_accuracy: 0.5576 - 746ms/epoch - 30ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6744 - accuracy: 0.5687 - val_loss: 0.6852 - val_accuracy: 0.5576 - 748ms/epoch - 30ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6756 - accuracy: 0.5776 - val_loss: 0.6849 - val_accuracy: 0.5579 - 753ms/epoch - 30ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6746 - accuracy: 0.5725 - val_loss: 0.6843 - val_accuracy: 0.5592 - 750ms/epoch - 30ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6748 - accuracy: 0.5712 - val_loss: 0.6850 - val_accuracy: 0.5577 - 729ms/epoch - 29ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6753 - accuracy: 0.5725 - val_loss: 0.6844 - val_accuracy: 0.5597 - 746ms/epoch - 30ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6740 - accuracy: 0.5776 - val_loss: 0.6847 - val_accuracy: 0.5575 - 765ms/epoch - 31ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6741 - accuracy: 0.5813 - val_loss: 0.6838 - val_accuracy: 0.5575 - 770ms/epoch - 31ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6737 - accuracy: 0.5738 - val_loss: 0.6846 - val_accuracy: 0.5576 - 776ms/epoch - 31ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6757 - accuracy: 0.5776 - val_loss: 0.6846 - val_accuracy: 0.5561 - 775ms/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6746 - accuracy: 0.5637 - val_loss: 0.6834 - val_accuracy: 0.5604 - 738ms/epoch - 30ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6731 - accuracy: 0.5788 - val_loss: 0.6840 - val_accuracy: 0.5607 - 749ms/epoch - 30ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6738 - accuracy: 0.5750 - val_loss: 0.6846 - val_accuracy: 0.5560 - 740ms/epoch - 30ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6735 - accuracy: 0.5801 - val_loss: 0.6838 - val_accuracy: 0.5610 - 779ms/epoch - 31ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6738 - accuracy: 0.5776 - val_loss: 0.6843 - val_accuracy: 0.5591 - 745ms/epoch - 30ms/step\n",
      "288/288 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5610\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6975 - accuracy: 0.4848 - val_loss: 0.6939 - val_accuracy: 0.5014 - 2s/epoch - 84ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6940 - accuracy: 0.5164 - val_loss: 0.6940 - val_accuracy: 0.5046 - 821ms/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6935 - accuracy: 0.5152 - val_loss: 0.6936 - val_accuracy: 0.5109 - 850ms/epoch - 34ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6933 - accuracy: 0.5265 - val_loss: 0.6930 - val_accuracy: 0.5093 - 795ms/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6924 - accuracy: 0.5189 - val_loss: 0.6930 - val_accuracy: 0.5078 - 790ms/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6927 - accuracy: 0.5177 - val_loss: 0.6925 - val_accuracy: 0.5077 - 782ms/epoch - 31ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6919 - val_accuracy: 0.5167 - 826ms/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5051 - val_loss: 0.6915 - val_accuracy: 0.5215 - 816ms/epoch - 33ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5249 - 817ms/epoch - 33ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6884 - accuracy: 0.5404 - val_loss: 0.6883 - val_accuracy: 0.5477 - 820ms/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6871 - accuracy: 0.5467 - val_loss: 0.6873 - val_accuracy: 0.5459 - 797ms/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6849 - accuracy: 0.5568 - val_loss: 0.6824 - val_accuracy: 0.5770 - 817ms/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6791 - accuracy: 0.5896 - val_loss: 0.6778 - val_accuracy: 0.5862 - 808ms/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6800 - accuracy: 0.5833 - val_loss: 0.6770 - val_accuracy: 0.5813 - 788ms/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6750 - accuracy: 0.5896 - val_loss: 0.6747 - val_accuracy: 0.5858 - 794ms/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6715 - accuracy: 0.5985 - val_loss: 0.6683 - val_accuracy: 0.5998 - 817ms/epoch - 33ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6622 - accuracy: 0.6250 - val_loss: 0.6614 - val_accuracy: 0.6172 - 825ms/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6599 - accuracy: 0.6136 - val_loss: 0.6546 - val_accuracy: 0.6246 - 810ms/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6557 - accuracy: 0.6250 - val_loss: 0.6539 - val_accuracy: 0.6372 - 822ms/epoch - 33ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6495 - accuracy: 0.6465 - val_loss: 0.6457 - val_accuracy: 0.6325 - 799ms/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6462 - accuracy: 0.6351 - val_loss: 0.6419 - val_accuracy: 0.6466 - 822ms/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6398 - accuracy: 0.6452 - val_loss: 0.6384 - val_accuracy: 0.6572 - 820ms/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6414 - accuracy: 0.6351 - val_loss: 0.6396 - val_accuracy: 0.6450 - 773ms/epoch - 31ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6375 - accuracy: 0.6465 - val_loss: 0.6330 - val_accuracy: 0.6572 - 786ms/epoch - 31ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6324 - accuracy: 0.6591 - val_loss: 0.6287 - val_accuracy: 0.6605 - 811ms/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6328 - accuracy: 0.6503 - val_loss: 0.6386 - val_accuracy: 0.6430 - 781ms/epoch - 31ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6255 - accuracy: 0.6566 - val_loss: 0.6310 - val_accuracy: 0.6558 - 797ms/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6272 - accuracy: 0.6604 - val_loss: 0.6308 - val_accuracy: 0.6560 - 822ms/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6247 - accuracy: 0.6654 - val_loss: 0.6300 - val_accuracy: 0.6635 - 797ms/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6255 - accuracy: 0.6641 - val_loss: 0.6278 - val_accuracy: 0.6574 - 829ms/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6230 - accuracy: 0.6654 - val_loss: 0.6245 - val_accuracy: 0.6620 - 808ms/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6268 - accuracy: 0.6679 - val_loss: 0.6252 - val_accuracy: 0.6607 - 808ms/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6217 - accuracy: 0.6629 - val_loss: 0.6254 - val_accuracy: 0.6587 - 787ms/epoch - 31ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6244 - accuracy: 0.6641 - val_loss: 0.6254 - val_accuracy: 0.6589 - 809ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6195 - accuracy: 0.6667 - val_loss: 0.6231 - val_accuracy: 0.6636 - 816ms/epoch - 33ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6165 - accuracy: 0.6578 - val_loss: 0.6237 - val_accuracy: 0.6605 - 795ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6184 - accuracy: 0.6654 - val_loss: 0.6257 - val_accuracy: 0.6589 - 791ms/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6179 - accuracy: 0.6528 - val_loss: 0.6222 - val_accuracy: 0.6636 - 800ms/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6177 - accuracy: 0.6692 - val_loss: 0.6278 - val_accuracy: 0.6526 - 797ms/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6140 - accuracy: 0.6641 - val_loss: 0.6212 - val_accuracy: 0.6601 - 780ms/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6140 - accuracy: 0.6717 - val_loss: 0.6213 - val_accuracy: 0.6559 - 785ms/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6139 - accuracy: 0.6667 - val_loss: 0.6216 - val_accuracy: 0.6555 - 792ms/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6100 - accuracy: 0.6768 - val_loss: 0.6202 - val_accuracy: 0.6528 - 786ms/epoch - 31ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6119 - accuracy: 0.6604 - val_loss: 0.6204 - val_accuracy: 0.6587 - 780ms/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6080 - accuracy: 0.6679 - val_loss: 0.6205 - val_accuracy: 0.6574 - 790ms/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6111 - accuracy: 0.6604 - val_loss: 0.6188 - val_accuracy: 0.6526 - 792ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6076 - accuracy: 0.6730 - val_loss: 0.6190 - val_accuracy: 0.6587 - 783ms/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6072 - accuracy: 0.6705 - val_loss: 0.6193 - val_accuracy: 0.6573 - 779ms/epoch - 31ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6080 - accuracy: 0.6616 - val_loss: 0.6177 - val_accuracy: 0.6618 - 787ms/epoch - 31ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6087 - accuracy: 0.6755 - val_loss: 0.6175 - val_accuracy: 0.6575 - 817ms/epoch - 33ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6067 - accuracy: 0.6692 - val_loss: 0.6183 - val_accuracy: 0.6570 - 800ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6049 - accuracy: 0.6717 - val_loss: 0.6165 - val_accuracy: 0.6617 - 792ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6047 - accuracy: 0.6654 - val_loss: 0.6167 - val_accuracy: 0.6542 - 803ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6046 - accuracy: 0.6730 - val_loss: 0.6159 - val_accuracy: 0.6571 - 792ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6032 - accuracy: 0.6768 - val_loss: 0.6166 - val_accuracy: 0.6588 - 798ms/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6020 - accuracy: 0.6730 - val_loss: 0.6147 - val_accuracy: 0.6555 - 799ms/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6035 - accuracy: 0.6705 - val_loss: 0.6158 - val_accuracy: 0.6573 - 788ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6031 - accuracy: 0.6793 - val_loss: 0.6150 - val_accuracy: 0.6589 - 789ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.5998 - accuracy: 0.6755 - val_loss: 0.6151 - val_accuracy: 0.6525 - 793ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6026 - accuracy: 0.6742 - val_loss: 0.6150 - val_accuracy: 0.6558 - 803ms/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6016 - accuracy: 0.6780 - val_loss: 0.6143 - val_accuracy: 0.6558 - 790ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.5991 - accuracy: 0.6768 - val_loss: 0.6125 - val_accuracy: 0.6588 - 766ms/epoch - 31ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.5997 - accuracy: 0.6730 - val_loss: 0.6137 - val_accuracy: 0.6620 - 791ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6003 - accuracy: 0.6730 - val_loss: 0.6141 - val_accuracy: 0.6588 - 787ms/epoch - 31ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.5983 - accuracy: 0.6641 - val_loss: 0.6118 - val_accuracy: 0.6555 - 791ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.5996 - accuracy: 0.6742 - val_loss: 0.6127 - val_accuracy: 0.6571 - 792ms/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.5984 - accuracy: 0.6755 - val_loss: 0.6122 - val_accuracy: 0.6554 - 796ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.5966 - accuracy: 0.6679 - val_loss: 0.6119 - val_accuracy: 0.6555 - 806ms/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6018 - accuracy: 0.6654 - val_loss: 0.6115 - val_accuracy: 0.6557 - 794ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.5980 - accuracy: 0.6755 - val_loss: 0.6110 - val_accuracy: 0.6557 - 777ms/epoch - 31ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.5951 - accuracy: 0.6705 - val_loss: 0.6122 - val_accuracy: 0.6524 - 775ms/epoch - 31ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.5973 - accuracy: 0.6692 - val_loss: 0.6107 - val_accuracy: 0.6557 - 783ms/epoch - 31ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.5969 - accuracy: 0.6679 - val_loss: 0.6113 - val_accuracy: 0.6524 - 782ms/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.5934 - accuracy: 0.6780 - val_loss: 0.6101 - val_accuracy: 0.6540 - 785ms/epoch - 31ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.5953 - accuracy: 0.6641 - val_loss: 0.6098 - val_accuracy: 0.6617 - 782ms/epoch - 31ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.5944 - accuracy: 0.6755 - val_loss: 0.6098 - val_accuracy: 0.6510 - 783ms/epoch - 31ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.5965 - accuracy: 0.6717 - val_loss: 0.6100 - val_accuracy: 0.6618 - 792ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.5935 - accuracy: 0.6768 - val_loss: 0.6082 - val_accuracy: 0.6586 - 780ms/epoch - 31ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.5947 - accuracy: 0.6705 - val_loss: 0.6095 - val_accuracy: 0.6541 - 763ms/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.5940 - accuracy: 0.6705 - val_loss: 0.6087 - val_accuracy: 0.6540 - 792ms/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.5961 - accuracy: 0.6654 - val_loss: 0.6089 - val_accuracy: 0.6617 - 798ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.5933 - accuracy: 0.6742 - val_loss: 0.6086 - val_accuracy: 0.6557 - 798ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.5940 - accuracy: 0.6755 - val_loss: 0.6086 - val_accuracy: 0.6527 - 783ms/epoch - 31ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.5925 - accuracy: 0.6705 - val_loss: 0.6079 - val_accuracy: 0.6542 - 799ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.5962 - accuracy: 0.6679 - val_loss: 0.6078 - val_accuracy: 0.6586 - 796ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.5949 - accuracy: 0.6768 - val_loss: 0.6091 - val_accuracy: 0.6526 - 783ms/epoch - 31ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.5926 - accuracy: 0.6742 - val_loss: 0.6069 - val_accuracy: 0.6604 - 799ms/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.5917 - accuracy: 0.6679 - val_loss: 0.6076 - val_accuracy: 0.6559 - 783ms/epoch - 31ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.5932 - accuracy: 0.6692 - val_loss: 0.6063 - val_accuracy: 0.6620 - 781ms/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.5925 - accuracy: 0.6717 - val_loss: 0.6087 - val_accuracy: 0.6539 - 810ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.5911 - accuracy: 0.6705 - val_loss: 0.6058 - val_accuracy: 0.6587 - 795ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.5915 - accuracy: 0.6717 - val_loss: 0.6071 - val_accuracy: 0.6509 - 790ms/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.5897 - accuracy: 0.6780 - val_loss: 0.6069 - val_accuracy: 0.6541 - 802ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.5902 - accuracy: 0.6692 - val_loss: 0.6047 - val_accuracy: 0.6618 - 790ms/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.5926 - accuracy: 0.6566 - val_loss: 0.6066 - val_accuracy: 0.6510 - 817ms/epoch - 33ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.5902 - accuracy: 0.6717 - val_loss: 0.6070 - val_accuracy: 0.6558 - 794ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.5890 - accuracy: 0.6742 - val_loss: 0.6048 - val_accuracy: 0.6602 - 820ms/epoch - 33ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.5893 - accuracy: 0.6717 - val_loss: 0.6045 - val_accuracy: 0.6540 - 798ms/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.5889 - accuracy: 0.6705 - val_loss: 0.6049 - val_accuracy: 0.6491 - 795ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.5899 - accuracy: 0.6578 - val_loss: 0.6046 - val_accuracy: 0.6571 - 807ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 2ms/step - loss: 0.6231 - accuracy: 0.6636\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6977 - accuracy: 0.4842 - val_loss: 0.6936 - val_accuracy: 0.4968 - 2s/epoch - 84ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6941 - accuracy: 0.5044 - val_loss: 0.6943 - val_accuracy: 0.4997 - 862ms/epoch - 34ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6940 - accuracy: 0.5107 - val_loss: 0.6937 - val_accuracy: 0.5002 - 867ms/epoch - 35ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6940 - accuracy: 0.5145 - val_loss: 0.6936 - val_accuracy: 0.4997 - 866ms/epoch - 35ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6928 - accuracy: 0.5196 - val_loss: 0.6931 - val_accuracy: 0.5096 - 892ms/epoch - 36ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6924 - accuracy: 0.5070 - val_loss: 0.6929 - val_accuracy: 0.5091 - 862ms/epoch - 34ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6932 - accuracy: 0.5221 - val_loss: 0.6935 - val_accuracy: 0.5108 - 866ms/epoch - 35ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5272 - val_loss: 0.6926 - val_accuracy: 0.5090 - 814ms/epoch - 33ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5259 - val_loss: 0.6917 - val_accuracy: 0.5170 - 834ms/epoch - 33ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5259 - val_loss: 0.6918 - val_accuracy: 0.5215 - 842ms/epoch - 34ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5297 - val_loss: 0.6899 - val_accuracy: 0.5345 - 842ms/epoch - 34ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6899 - accuracy: 0.5386 - val_loss: 0.6897 - val_accuracy: 0.5326 - 834ms/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5297 - val_loss: 0.6875 - val_accuracy: 0.5480 - 866ms/epoch - 35ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6853 - accuracy: 0.5537 - val_loss: 0.6867 - val_accuracy: 0.5589 - 860ms/epoch - 34ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6842 - accuracy: 0.5474 - val_loss: 0.6843 - val_accuracy: 0.5663 - 863ms/epoch - 35ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6821 - accuracy: 0.5638 - val_loss: 0.6807 - val_accuracy: 0.5864 - 873ms/epoch - 35ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6799 - accuracy: 0.5828 - val_loss: 0.6790 - val_accuracy: 0.5733 - 808ms/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6746 - accuracy: 0.5879 - val_loss: 0.6757 - val_accuracy: 0.5880 - 856ms/epoch - 34ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6763 - accuracy: 0.5790 - val_loss: 0.6746 - val_accuracy: 0.5951 - 839ms/epoch - 34ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6717 - accuracy: 0.6068 - val_loss: 0.6681 - val_accuracy: 0.6168 - 842ms/epoch - 34ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6633 - accuracy: 0.6271 - val_loss: 0.6663 - val_accuracy: 0.6059 - 855ms/epoch - 34ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6621 - accuracy: 0.6233 - val_loss: 0.6598 - val_accuracy: 0.6337 - 863ms/epoch - 35ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6521 - accuracy: 0.6397 - val_loss: 0.6533 - val_accuracy: 0.6339 - 861ms/epoch - 34ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6471 - accuracy: 0.6448 - val_loss: 0.6433 - val_accuracy: 0.6349 - 855ms/epoch - 34ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6327 - accuracy: 0.6839 - val_loss: 0.6316 - val_accuracy: 0.6552 - 843ms/epoch - 34ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6215 - accuracy: 0.6751 - val_loss: 0.6183 - val_accuracy: 0.6783 - 866ms/epoch - 35ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6145 - accuracy: 0.6662 - val_loss: 0.6130 - val_accuracy: 0.6692 - 833ms/epoch - 33ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6041 - accuracy: 0.6726 - val_loss: 0.6162 - val_accuracy: 0.6692 - 830ms/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6052 - accuracy: 0.6802 - val_loss: 0.5879 - val_accuracy: 0.6921 - 873ms/epoch - 35ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.5818 - accuracy: 0.6915 - val_loss: 0.5884 - val_accuracy: 0.6800 - 827ms/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.5816 - accuracy: 0.6751 - val_loss: 0.5717 - val_accuracy: 0.6907 - 850ms/epoch - 34ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.5626 - accuracy: 0.6877 - val_loss: 0.5507 - val_accuracy: 0.7004 - 854ms/epoch - 34ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.5560 - accuracy: 0.7054 - val_loss: 0.5559 - val_accuracy: 0.6985 - 825ms/epoch - 33ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.5424 - accuracy: 0.6928 - val_loss: 0.5278 - val_accuracy: 0.7032 - 857ms/epoch - 34ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.5398 - accuracy: 0.7067 - val_loss: 0.5321 - val_accuracy: 0.7107 - 867ms/epoch - 35ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.5272 - accuracy: 0.6966 - val_loss: 0.5101 - val_accuracy: 0.7062 - 830ms/epoch - 33ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.5221 - accuracy: 0.6852 - val_loss: 0.5075 - val_accuracy: 0.7139 - 860ms/epoch - 34ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.5092 - accuracy: 0.7143 - val_loss: 0.4970 - val_accuracy: 0.7134 - 814ms/epoch - 33ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.5062 - accuracy: 0.7181 - val_loss: 0.5035 - val_accuracy: 0.7143 - 859ms/epoch - 34ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.5039 - accuracy: 0.7206 - val_loss: 0.4998 - val_accuracy: 0.7109 - 832ms/epoch - 33ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.5038 - accuracy: 0.7042 - val_loss: 0.4866 - val_accuracy: 0.7166 - 847ms/epoch - 34ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.4872 - accuracy: 0.7295 - val_loss: 0.4781 - val_accuracy: 0.7171 - 859ms/epoch - 34ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.4853 - accuracy: 0.7155 - val_loss: 0.4838 - val_accuracy: 0.7170 - 804ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.4780 - accuracy: 0.7257 - val_loss: 0.4765 - val_accuracy: 0.7167 - 845ms/epoch - 34ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.4773 - accuracy: 0.7231 - val_loss: 0.4756 - val_accuracy: 0.7182 - 862ms/epoch - 34ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.4743 - accuracy: 0.7155 - val_loss: 0.4711 - val_accuracy: 0.7164 - 819ms/epoch - 33ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.4744 - accuracy: 0.7118 - val_loss: 0.4676 - val_accuracy: 0.7220 - 844ms/epoch - 34ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.4718 - accuracy: 0.7257 - val_loss: 0.4604 - val_accuracy: 0.7229 - 836ms/epoch - 33ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.4716 - accuracy: 0.7193 - val_loss: 0.4737 - val_accuracy: 0.7205 - 841ms/epoch - 34ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.4702 - accuracy: 0.7092 - val_loss: 0.4598 - val_accuracy: 0.7234 - 844ms/epoch - 34ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.4647 - accuracy: 0.7307 - val_loss: 0.4575 - val_accuracy: 0.7235 - 860ms/epoch - 34ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.4631 - accuracy: 0.7307 - val_loss: 0.4536 - val_accuracy: 0.7216 - 835ms/epoch - 33ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.4585 - accuracy: 0.7181 - val_loss: 0.4514 - val_accuracy: 0.7230 - 812ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.4601 - accuracy: 0.7193 - val_loss: 0.4539 - val_accuracy: 0.7214 - 827ms/epoch - 33ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.4530 - accuracy: 0.7244 - val_loss: 0.4488 - val_accuracy: 0.7224 - 839ms/epoch - 34ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.4555 - accuracy: 0.7181 - val_loss: 0.4446 - val_accuracy: 0.7232 - 839ms/epoch - 34ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.4526 - accuracy: 0.7181 - val_loss: 0.4461 - val_accuracy: 0.7230 - 824ms/epoch - 33ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.4545 - accuracy: 0.7206 - val_loss: 0.4428 - val_accuracy: 0.7226 - 833ms/epoch - 33ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.4453 - accuracy: 0.7155 - val_loss: 0.4409 - val_accuracy: 0.7227 - 843ms/epoch - 34ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.4451 - accuracy: 0.7193 - val_loss: 0.4372 - val_accuracy: 0.7230 - 820ms/epoch - 33ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.4440 - accuracy: 0.7244 - val_loss: 0.4425 - val_accuracy: 0.7235 - 834ms/epoch - 33ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.4530 - accuracy: 0.7118 - val_loss: 0.4429 - val_accuracy: 0.7225 - 832ms/epoch - 33ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.4449 - accuracy: 0.7219 - val_loss: 0.4405 - val_accuracy: 0.7234 - 845ms/epoch - 34ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.4453 - accuracy: 0.7257 - val_loss: 0.4397 - val_accuracy: 0.7232 - 809ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.4469 - accuracy: 0.7257 - val_loss: 0.4358 - val_accuracy: 0.7226 - 847ms/epoch - 34ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.4421 - accuracy: 0.7231 - val_loss: 0.4349 - val_accuracy: 0.7232 - 840ms/epoch - 34ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.4409 - accuracy: 0.7054 - val_loss: 0.4329 - val_accuracy: 0.7226 - 818ms/epoch - 33ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.4370 - accuracy: 0.7345 - val_loss: 0.4342 - val_accuracy: 0.7233 - 828ms/epoch - 33ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.4382 - accuracy: 0.7295 - val_loss: 0.4370 - val_accuracy: 0.7235 - 835ms/epoch - 33ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.4383 - accuracy: 0.7295 - val_loss: 0.4298 - val_accuracy: 0.7228 - 837ms/epoch - 33ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.4347 - accuracy: 0.7231 - val_loss: 0.4314 - val_accuracy: 0.7236 - 867ms/epoch - 35ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.4313 - accuracy: 0.7332 - val_loss: 0.4343 - val_accuracy: 0.7225 - 849ms/epoch - 34ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.4357 - accuracy: 0.7155 - val_loss: 0.4286 - val_accuracy: 0.7229 - 830ms/epoch - 33ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.4371 - accuracy: 0.7307 - val_loss: 0.4338 - val_accuracy: 0.7227 - 835ms/epoch - 33ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.4315 - accuracy: 0.7269 - val_loss: 0.4273 - val_accuracy: 0.7235 - 853ms/epoch - 34ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.4319 - accuracy: 0.7193 - val_loss: 0.4271 - val_accuracy: 0.7228 - 861ms/epoch - 34ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.4296 - accuracy: 0.7244 - val_loss: 0.4265 - val_accuracy: 0.7235 - 849ms/epoch - 34ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.4324 - accuracy: 0.7168 - val_loss: 0.4303 - val_accuracy: 0.7225 - 860ms/epoch - 34ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.4277 - accuracy: 0.7244 - val_loss: 0.4300 - val_accuracy: 0.7233 - 838ms/epoch - 34ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.4318 - accuracy: 0.7257 - val_loss: 0.4332 - val_accuracy: 0.7227 - 830ms/epoch - 33ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.4353 - accuracy: 0.7257 - val_loss: 0.4333 - val_accuracy: 0.7234 - 822ms/epoch - 33ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.4349 - accuracy: 0.7295 - val_loss: 0.4333 - val_accuracy: 0.7229 - 832ms/epoch - 33ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.4280 - accuracy: 0.7219 - val_loss: 0.4268 - val_accuracy: 0.7239 - 859ms/epoch - 34ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.4292 - accuracy: 0.7269 - val_loss: 0.4278 - val_accuracy: 0.7225 - 823ms/epoch - 33ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.4276 - accuracy: 0.7067 - val_loss: 0.4264 - val_accuracy: 0.7232 - 842ms/epoch - 34ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.4270 - accuracy: 0.7244 - val_loss: 0.4231 - val_accuracy: 0.7230 - 819ms/epoch - 33ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.4235 - accuracy: 0.7231 - val_loss: 0.4211 - val_accuracy: 0.7232 - 820ms/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.4204 - accuracy: 0.7345 - val_loss: 0.4203 - val_accuracy: 0.7227 - 837ms/epoch - 33ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.4305 - accuracy: 0.7118 - val_loss: 0.4254 - val_accuracy: 0.7233 - 821ms/epoch - 33ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.4264 - accuracy: 0.7130 - val_loss: 0.4192 - val_accuracy: 0.7229 - 829ms/epoch - 33ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.4209 - accuracy: 0.7345 - val_loss: 0.4214 - val_accuracy: 0.7230 - 854ms/epoch - 34ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.4197 - accuracy: 0.7332 - val_loss: 0.4231 - val_accuracy: 0.7228 - 834ms/epoch - 33ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.4247 - accuracy: 0.7168 - val_loss: 0.4210 - val_accuracy: 0.7226 - 816ms/epoch - 33ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.4235 - accuracy: 0.7307 - val_loss: 0.4235 - val_accuracy: 0.7233 - 833ms/epoch - 33ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.4182 - accuracy: 0.7370 - val_loss: 0.4182 - val_accuracy: 0.7229 - 820ms/epoch - 33ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.4245 - accuracy: 0.7105 - val_loss: 0.4218 - val_accuracy: 0.7236 - 837ms/epoch - 33ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.4211 - accuracy: 0.7295 - val_loss: 0.4217 - val_accuracy: 0.7227 - 836ms/epoch - 33ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.4192 - accuracy: 0.7155 - val_loss: 0.4173 - val_accuracy: 0.7228 - 833ms/epoch - 33ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.4236 - accuracy: 0.7345 - val_loss: 0.4353 - val_accuracy: 0.7229 - 839ms/epoch - 34ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.4306 - accuracy: 0.7206 - val_loss: 0.4205 - val_accuracy: 0.7234 - 823ms/epoch - 33ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.7239\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6993 - accuracy: 0.4722 - val_loss: 0.6932 - val_accuracy: 0.5148 - 2s/epoch - 86ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6932 - accuracy: 0.5089 - val_loss: 0.6932 - val_accuracy: 0.5063 - 876ms/epoch - 35ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6932 - accuracy: 0.5076 - val_loss: 0.6935 - val_accuracy: 0.5076 - 874ms/epoch - 35ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5165 - val_loss: 0.6935 - val_accuracy: 0.4999 - 866ms/epoch - 35ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6927 - accuracy: 0.5101 - val_loss: 0.6932 - val_accuracy: 0.5107 - 862ms/epoch - 34ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5165 - val_loss: 0.6925 - val_accuracy: 0.5172 - 897ms/epoch - 36ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6928 - accuracy: 0.5101 - val_loss: 0.6919 - val_accuracy: 0.5247 - 903ms/epoch - 36ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5342 - val_loss: 0.6913 - val_accuracy: 0.5203 - 866ms/epoch - 35ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6900 - val_accuracy: 0.5265 - 920ms/epoch - 37ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5278 - val_loss: 0.6869 - val_accuracy: 0.5416 - 906ms/epoch - 36ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6834 - accuracy: 0.5646 - val_loss: 0.6737 - val_accuracy: 0.6208 - 896ms/epoch - 36ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6625 - accuracy: 0.6316 - val_loss: 0.6550 - val_accuracy: 0.6433 - 890ms/epoch - 36ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6003 - accuracy: 0.7291 - val_loss: 0.5114 - val_accuracy: 0.7684 - 882ms/epoch - 35ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.3964 - accuracy: 0.8658 - val_loss: 0.2334 - val_accuracy: 0.9786 - 905ms/epoch - 36ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.1252 - accuracy: 0.9873 - val_loss: 0.0490 - val_accuracy: 0.9909 - 897ms/epoch - 36ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.0507 - accuracy: 0.9911 - val_loss: 0.0240 - val_accuracy: 1.0000 - 885ms/epoch - 35ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - 880ms/epoch - 35ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - 885ms/epoch - 35ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 8.8539e-04 - accuracy: 1.0000 - val_loss: 7.4355e-04 - val_accuracy: 1.0000 - 876ms/epoch - 35ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 6.6056e-04 - accuracy: 1.0000 - val_loss: 5.9763e-04 - val_accuracy: 1.0000 - 871ms/epoch - 35ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 5.4324e-04 - accuracy: 1.0000 - val_loss: 5.0439e-04 - val_accuracy: 1.0000 - 876ms/epoch - 35ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 4.6287e-04 - accuracy: 1.0000 - val_loss: 4.3497e-04 - val_accuracy: 1.0000 - 885ms/epoch - 35ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 4.0490e-04 - accuracy: 1.0000 - val_loss: 3.8395e-04 - val_accuracy: 1.0000 - 876ms/epoch - 35ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 3.5747e-04 - accuracy: 1.0000 - val_loss: 3.4000e-04 - val_accuracy: 1.0000 - 878ms/epoch - 35ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 3.1739e-04 - accuracy: 1.0000 - val_loss: 3.0466e-04 - val_accuracy: 1.0000 - 871ms/epoch - 35ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 2.8472e-04 - accuracy: 1.0000 - val_loss: 2.7512e-04 - val_accuracy: 1.0000 - 857ms/epoch - 34ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 2.5826e-04 - accuracy: 1.0000 - val_loss: 2.4967e-04 - val_accuracy: 1.0000 - 859ms/epoch - 34ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 2.3471e-04 - accuracy: 1.0000 - val_loss: 2.2912e-04 - val_accuracy: 1.0000 - 866ms/epoch - 35ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 2.1639e-04 - accuracy: 1.0000 - val_loss: 2.1020e-04 - val_accuracy: 1.0000 - 875ms/epoch - 35ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 1.9845e-04 - accuracy: 1.0000 - val_loss: 1.9411e-04 - val_accuracy: 1.0000 - 856ms/epoch - 34ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 1.8381e-04 - accuracy: 1.0000 - val_loss: 1.7987e-04 - val_accuracy: 1.0000 - 867ms/epoch - 35ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 1.6966e-04 - accuracy: 1.0000 - val_loss: 1.6713e-04 - val_accuracy: 1.0000 - 882ms/epoch - 35ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 1.5795e-04 - accuracy: 1.0000 - val_loss: 1.5608e-04 - val_accuracy: 1.0000 - 863ms/epoch - 35ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 1.4852e-04 - accuracy: 1.0000 - val_loss: 1.4576e-04 - val_accuracy: 1.0000 - 877ms/epoch - 35ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 1.3854e-04 - accuracy: 1.0000 - val_loss: 1.3686e-04 - val_accuracy: 1.0000 - 881ms/epoch - 35ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 1.3016e-04 - accuracy: 1.0000 - val_loss: 1.2884e-04 - val_accuracy: 1.0000 - 866ms/epoch - 35ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 1.2220e-04 - accuracy: 1.0000 - val_loss: 1.2134e-04 - val_accuracy: 1.0000 - 877ms/epoch - 35ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 1.1552e-04 - accuracy: 1.0000 - val_loss: 1.1438e-04 - val_accuracy: 1.0000 - 872ms/epoch - 35ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 1.0909e-04 - accuracy: 1.0000 - val_loss: 1.0816e-04 - val_accuracy: 1.0000 - 859ms/epoch - 34ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 1.0309e-04 - accuracy: 1.0000 - val_loss: 1.0252e-04 - val_accuracy: 1.0000 - 903ms/epoch - 36ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 9.7837e-05 - accuracy: 1.0000 - val_loss: 9.7081e-05 - val_accuracy: 1.0000 - 900ms/epoch - 36ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 9.2815e-05 - accuracy: 1.0000 - val_loss: 9.2275e-05 - val_accuracy: 1.0000 - 880ms/epoch - 35ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 8.8219e-05 - accuracy: 1.0000 - val_loss: 8.7794e-05 - val_accuracy: 1.0000 - 875ms/epoch - 35ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 8.3755e-05 - accuracy: 1.0000 - val_loss: 8.3571e-05 - val_accuracy: 1.0000 - 879ms/epoch - 35ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 8.0252e-05 - accuracy: 1.0000 - val_loss: 7.9806e-05 - val_accuracy: 1.0000 - 870ms/epoch - 35ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 7.6348e-05 - accuracy: 1.0000 - val_loss: 7.6135e-05 - val_accuracy: 1.0000 - 881ms/epoch - 35ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 7.2830e-05 - accuracy: 1.0000 - val_loss: 7.2842e-05 - val_accuracy: 1.0000 - 868ms/epoch - 35ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 6.9756e-05 - accuracy: 1.0000 - val_loss: 6.9627e-05 - val_accuracy: 1.0000 - 894ms/epoch - 36ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 6.6852e-05 - accuracy: 1.0000 - val_loss: 6.6735e-05 - val_accuracy: 1.0000 - 877ms/epoch - 35ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 6.4118e-05 - accuracy: 1.0000 - val_loss: 6.4031e-05 - val_accuracy: 1.0000 - 872ms/epoch - 35ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 6.1300e-05 - accuracy: 1.0000 - val_loss: 6.1319e-05 - val_accuracy: 1.0000 - 882ms/epoch - 35ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 5.8769e-05 - accuracy: 1.0000 - val_loss: 5.8924e-05 - val_accuracy: 1.0000 - 906ms/epoch - 36ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 5.6605e-05 - accuracy: 1.0000 - val_loss: 5.6596e-05 - val_accuracy: 1.0000 - 880ms/epoch - 35ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 5.4372e-05 - accuracy: 1.0000 - val_loss: 5.4475e-05 - val_accuracy: 1.0000 - 860ms/epoch - 34ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 5.2179e-05 - accuracy: 1.0000 - val_loss: 5.2431e-05 - val_accuracy: 1.0000 - 894ms/epoch - 36ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 5.0306e-05 - accuracy: 1.0000 - val_loss: 5.0486e-05 - val_accuracy: 1.0000 - 883ms/epoch - 35ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 4.8627e-05 - accuracy: 1.0000 - val_loss: 4.8660e-05 - val_accuracy: 1.0000 - 875ms/epoch - 35ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 4.6670e-05 - accuracy: 1.0000 - val_loss: 4.6896e-05 - val_accuracy: 1.0000 - 861ms/epoch - 34ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 4.5090e-05 - accuracy: 1.0000 - val_loss: 4.5212e-05 - val_accuracy: 1.0000 - 889ms/epoch - 36ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 4.3443e-05 - accuracy: 1.0000 - val_loss: 4.3648e-05 - val_accuracy: 1.0000 - 890ms/epoch - 36ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 4.1862e-05 - accuracy: 1.0000 - val_loss: 4.2119e-05 - val_accuracy: 1.0000 - 898ms/epoch - 36ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 4.0373e-05 - accuracy: 1.0000 - val_loss: 4.0713e-05 - val_accuracy: 1.0000 - 873ms/epoch - 35ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 3.9066e-05 - accuracy: 1.0000 - val_loss: 3.9318e-05 - val_accuracy: 1.0000 - 888ms/epoch - 36ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 3.7785e-05 - accuracy: 1.0000 - val_loss: 3.8054e-05 - val_accuracy: 1.0000 - 880ms/epoch - 35ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 3.6527e-05 - accuracy: 1.0000 - val_loss: 3.6792e-05 - val_accuracy: 1.0000 - 877ms/epoch - 35ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 3.5377e-05 - accuracy: 1.0000 - val_loss: 3.5621e-05 - val_accuracy: 1.0000 - 882ms/epoch - 35ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 3.4180e-05 - accuracy: 1.0000 - val_loss: 3.4493e-05 - val_accuracy: 1.0000 - 868ms/epoch - 35ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 3.3082e-05 - accuracy: 1.0000 - val_loss: 3.3384e-05 - val_accuracy: 1.0000 - 871ms/epoch - 35ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 3.2104e-05 - accuracy: 1.0000 - val_loss: 3.2354e-05 - val_accuracy: 1.0000 - 870ms/epoch - 35ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 3.1066e-05 - accuracy: 1.0000 - val_loss: 3.1369e-05 - val_accuracy: 1.0000 - 867ms/epoch - 35ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 3.0128e-05 - accuracy: 1.0000 - val_loss: 3.0378e-05 - val_accuracy: 1.0000 - 865ms/epoch - 35ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 2.9173e-05 - accuracy: 1.0000 - val_loss: 2.9487e-05 - val_accuracy: 1.0000 - 879ms/epoch - 35ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 2.8327e-05 - accuracy: 1.0000 - val_loss: 2.8583e-05 - val_accuracy: 1.0000 - 860ms/epoch - 34ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 2.7479e-05 - accuracy: 1.0000 - val_loss: 2.7707e-05 - val_accuracy: 1.0000 - 874ms/epoch - 35ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 2.6613e-05 - accuracy: 1.0000 - val_loss: 2.6898e-05 - val_accuracy: 1.0000 - 883ms/epoch - 35ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 2.5875e-05 - accuracy: 1.0000 - val_loss: 2.6120e-05 - val_accuracy: 1.0000 - 858ms/epoch - 34ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 2.5081e-05 - accuracy: 1.0000 - val_loss: 2.5390e-05 - val_accuracy: 1.0000 - 893ms/epoch - 36ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 2.4364e-05 - accuracy: 1.0000 - val_loss: 2.4632e-05 - val_accuracy: 1.0000 - 867ms/epoch - 35ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 2.3669e-05 - accuracy: 1.0000 - val_loss: 2.3949e-05 - val_accuracy: 1.0000 - 894ms/epoch - 36ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 2.3012e-05 - accuracy: 1.0000 - val_loss: 2.3269e-05 - val_accuracy: 1.0000 - 871ms/epoch - 35ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 2.2395e-05 - accuracy: 1.0000 - val_loss: 2.2636e-05 - val_accuracy: 1.0000 - 910ms/epoch - 36ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 2.1763e-05 - accuracy: 1.0000 - val_loss: 2.2005e-05 - val_accuracy: 1.0000 - 875ms/epoch - 35ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 2.1183e-05 - accuracy: 1.0000 - val_loss: 2.1403e-05 - val_accuracy: 1.0000 - 880ms/epoch - 35ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 2.0565e-05 - accuracy: 1.0000 - val_loss: 2.0830e-05 - val_accuracy: 1.0000 - 898ms/epoch - 36ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 2.0029e-05 - accuracy: 1.0000 - val_loss: 2.0290e-05 - val_accuracy: 1.0000 - 889ms/epoch - 36ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 1.9505e-05 - accuracy: 1.0000 - val_loss: 1.9742e-05 - val_accuracy: 1.0000 - 852ms/epoch - 34ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 1.8975e-05 - accuracy: 1.0000 - val_loss: 1.9246e-05 - val_accuracy: 1.0000 - 884ms/epoch - 35ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 1.8465e-05 - accuracy: 1.0000 - val_loss: 1.8723e-05 - val_accuracy: 1.0000 - 891ms/epoch - 36ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 1.7977e-05 - accuracy: 1.0000 - val_loss: 1.8240e-05 - val_accuracy: 1.0000 - 888ms/epoch - 36ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 1.7543e-05 - accuracy: 1.0000 - val_loss: 1.7772e-05 - val_accuracy: 1.0000 - 885ms/epoch - 35ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 1.7075e-05 - accuracy: 1.0000 - val_loss: 1.7316e-05 - val_accuracy: 1.0000 - 876ms/epoch - 35ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 1.6663e-05 - accuracy: 1.0000 - val_loss: 1.6882e-05 - val_accuracy: 1.0000 - 879ms/epoch - 35ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 1.6217e-05 - accuracy: 1.0000 - val_loss: 1.6457e-05 - val_accuracy: 1.0000 - 876ms/epoch - 35ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 1.5810e-05 - accuracy: 1.0000 - val_loss: 1.6048e-05 - val_accuracy: 1.0000 - 887ms/epoch - 35ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 1.5460e-05 - accuracy: 1.0000 - val_loss: 1.5655e-05 - val_accuracy: 1.0000 - 862ms/epoch - 34ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 1.5042e-05 - accuracy: 1.0000 - val_loss: 1.5262e-05 - val_accuracy: 1.0000 - 897ms/epoch - 36ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 1.4667e-05 - accuracy: 1.0000 - val_loss: 1.4909e-05 - val_accuracy: 1.0000 - 889ms/epoch - 36ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 1.4320e-05 - accuracy: 1.0000 - val_loss: 1.4536e-05 - val_accuracy: 1.0000 - 871ms/epoch - 35ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 1.3990e-05 - accuracy: 1.0000 - val_loss: 1.4204e-05 - val_accuracy: 1.0000 - 867ms/epoch - 35ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 1.3645e-05 - accuracy: 1.0000 - val_loss: 1.3867e-05 - val_accuracy: 1.0000 - 884ms/epoch - 35ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "25/25 - 3s - loss: 0.7001 - accuracy: 0.4461 - val_loss: 0.6932 - val_accuracy: 0.5007 - 3s/epoch - 102ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6934 - accuracy: 0.5171 - val_loss: 0.6935 - val_accuracy: 0.5042 - 930ms/epoch - 37ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6933 - accuracy: 0.5158 - val_loss: 0.6933 - val_accuracy: 0.4997 - 944ms/epoch - 38ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6937 - accuracy: 0.5095 - val_loss: 0.6934 - val_accuracy: 0.4998 - 905ms/epoch - 36ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6933 - accuracy: 0.5108 - val_loss: 0.6931 - val_accuracy: 0.5029 - 920ms/epoch - 37ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5171 - val_loss: 0.6932 - val_accuracy: 0.5015 - 924ms/epoch - 37ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6927 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.5103 - 940ms/epoch - 38ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5260 - val_loss: 0.6924 - val_accuracy: 0.5042 - 909ms/epoch - 36ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5095 - val_loss: 0.6923 - val_accuracy: 0.5122 - 946ms/epoch - 38ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5133 - val_loss: 0.6901 - val_accuracy: 0.5234 - 946ms/epoch - 38ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6889 - accuracy: 0.5349 - val_loss: 0.6860 - val_accuracy: 0.5460 - 949ms/epoch - 38ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6828 - accuracy: 0.5526 - val_loss: 0.6775 - val_accuracy: 0.5782 - 965ms/epoch - 39ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6743 - accuracy: 0.5716 - val_loss: 0.6876 - val_accuracy: 0.5462 - 932ms/epoch - 37ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6819 - accuracy: 0.5450 - val_loss: 0.6662 - val_accuracy: 0.5897 - 949ms/epoch - 38ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6600 - accuracy: 0.6122 - val_loss: 0.6540 - val_accuracy: 0.6174 - 958ms/epoch - 38ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6523 - accuracy: 0.6388 - val_loss: 0.6306 - val_accuracy: 0.6789 - 951ms/epoch - 38ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6365 - accuracy: 0.6603 - val_loss: 0.6334 - val_accuracy: 0.6493 - 910ms/epoch - 36ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6206 - accuracy: 0.6857 - val_loss: 0.6098 - val_accuracy: 0.6897 - 952ms/epoch - 38ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6026 - accuracy: 0.6907 - val_loss: 0.5806 - val_accuracy: 0.7220 - 938ms/epoch - 38ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.5689 - accuracy: 0.7110 - val_loss: 0.5643 - val_accuracy: 0.7220 - 910ms/epoch - 36ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.5507 - accuracy: 0.7212 - val_loss: 0.5228 - val_accuracy: 0.7540 - 923ms/epoch - 37ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.4961 - accuracy: 0.7592 - val_loss: 0.5061 - val_accuracy: 0.7311 - 914ms/epoch - 37ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.4609 - accuracy: 0.7807 - val_loss: 0.4175 - val_accuracy: 0.8013 - 944ms/epoch - 38ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.3988 - accuracy: 0.8276 - val_loss: 0.3770 - val_accuracy: 0.8386 - 952ms/epoch - 38ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.3003 - accuracy: 0.8847 - val_loss: 0.2447 - val_accuracy: 0.9371 - 934ms/epoch - 37ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.2073 - accuracy: 0.9366 - val_loss: 0.1637 - val_accuracy: 0.9661 - 956ms/epoch - 38ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.1007 - accuracy: 0.9848 - val_loss: 0.0349 - val_accuracy: 1.0000 - 958ms/epoch - 38ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.0420 - accuracy: 0.9911 - val_loss: 0.0436 - val_accuracy: 0.9937 - 944ms/epoch - 38ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.0230 - accuracy: 0.9987 - val_loss: 0.0072 - val_accuracy: 1.0000 - 921ms/epoch - 37ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - 933ms/epoch - 37ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - 926ms/epoch - 37ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 9.7589e-04 - accuracy: 1.0000 - val_loss: 7.8971e-04 - val_accuracy: 1.0000 - 926ms/epoch - 37ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 7.0179e-04 - accuracy: 1.0000 - val_loss: 6.3828e-04 - val_accuracy: 1.0000 - 924ms/epoch - 37ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 5.7400e-04 - accuracy: 1.0000 - val_loss: 5.3804e-04 - val_accuracy: 1.0000 - 924ms/epoch - 37ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 4.9109e-04 - accuracy: 1.0000 - val_loss: 4.6883e-04 - val_accuracy: 1.0000 - 929ms/epoch - 37ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 4.2855e-04 - accuracy: 1.0000 - val_loss: 4.1181e-04 - val_accuracy: 1.0000 - 931ms/epoch - 37ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 3.7922e-04 - accuracy: 1.0000 - val_loss: 3.6690e-04 - val_accuracy: 1.0000 - 916ms/epoch - 37ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 3.3916e-04 - accuracy: 1.0000 - val_loss: 3.2994e-04 - val_accuracy: 1.0000 - 919ms/epoch - 37ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 3.0682e-04 - accuracy: 1.0000 - val_loss: 3.0046e-04 - val_accuracy: 1.0000 - 926ms/epoch - 37ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 2.7755e-04 - accuracy: 1.0000 - val_loss: 2.7260e-04 - val_accuracy: 1.0000 - 916ms/epoch - 37ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 2.5264e-04 - accuracy: 1.0000 - val_loss: 2.4902e-04 - val_accuracy: 1.0000 - 916ms/epoch - 37ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 2.3196e-04 - accuracy: 1.0000 - val_loss: 2.2904e-04 - val_accuracy: 1.0000 - 904ms/epoch - 36ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 2.1343e-04 - accuracy: 1.0000 - val_loss: 2.1170e-04 - val_accuracy: 1.0000 - 924ms/epoch - 37ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 1.9810e-04 - accuracy: 1.0000 - val_loss: 1.9638e-04 - val_accuracy: 1.0000 - 908ms/epoch - 36ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 1.8368e-04 - accuracy: 1.0000 - val_loss: 1.8265e-04 - val_accuracy: 1.0000 - 921ms/epoch - 37ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 1.7021e-04 - accuracy: 1.0000 - val_loss: 1.7001e-04 - val_accuracy: 1.0000 - 927ms/epoch - 37ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 1.5936e-04 - accuracy: 1.0000 - val_loss: 1.5924e-04 - val_accuracy: 1.0000 - 945ms/epoch - 38ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 1.4894e-04 - accuracy: 1.0000 - val_loss: 1.4944e-04 - val_accuracy: 1.0000 - 900ms/epoch - 36ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 1.3996e-04 - accuracy: 1.0000 - val_loss: 1.4077e-04 - val_accuracy: 1.0000 - 915ms/epoch - 37ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 1.3186e-04 - accuracy: 1.0000 - val_loss: 1.3281e-04 - val_accuracy: 1.0000 - 934ms/epoch - 37ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 1.2458e-04 - accuracy: 1.0000 - val_loss: 1.2526e-04 - val_accuracy: 1.0000 - 915ms/epoch - 37ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 1.1765e-04 - accuracy: 1.0000 - val_loss: 1.1858e-04 - val_accuracy: 1.0000 - 911ms/epoch - 36ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 1.1103e-04 - accuracy: 1.0000 - val_loss: 1.1243e-04 - val_accuracy: 1.0000 - 923ms/epoch - 37ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 1.0523e-04 - accuracy: 1.0000 - val_loss: 1.0640e-04 - val_accuracy: 1.0000 - 935ms/epoch - 37ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 1.0019e-04 - accuracy: 1.0000 - val_loss: 1.0123e-04 - val_accuracy: 1.0000 - 935ms/epoch - 37ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 9.5057e-05 - accuracy: 1.0000 - val_loss: 9.6554e-05 - val_accuracy: 1.0000 - 913ms/epoch - 37ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 9.0515e-05 - accuracy: 1.0000 - val_loss: 9.1910e-05 - val_accuracy: 1.0000 - 922ms/epoch - 37ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 8.6323e-05 - accuracy: 1.0000 - val_loss: 8.7691e-05 - val_accuracy: 1.0000 - 919ms/epoch - 37ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 8.2298e-05 - accuracy: 1.0000 - val_loss: 8.3583e-05 - val_accuracy: 1.0000 - 942ms/epoch - 38ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 7.8543e-05 - accuracy: 1.0000 - val_loss: 8.0071e-05 - val_accuracy: 1.0000 - 931ms/epoch - 37ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 7.5328e-05 - accuracy: 1.0000 - val_loss: 7.6753e-05 - val_accuracy: 1.0000 - 927ms/epoch - 37ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 7.1960e-05 - accuracy: 1.0000 - val_loss: 7.3444e-05 - val_accuracy: 1.0000 - 921ms/epoch - 37ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 6.9065e-05 - accuracy: 1.0000 - val_loss: 7.0512e-05 - val_accuracy: 1.0000 - 908ms/epoch - 36ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 6.6281e-05 - accuracy: 1.0000 - val_loss: 6.7692e-05 - val_accuracy: 1.0000 - 923ms/epoch - 37ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 6.3574e-05 - accuracy: 1.0000 - val_loss: 6.4980e-05 - val_accuracy: 1.0000 - 919ms/epoch - 37ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 6.1095e-05 - accuracy: 1.0000 - val_loss: 6.2523e-05 - val_accuracy: 1.0000 - 924ms/epoch - 37ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 5.8808e-05 - accuracy: 1.0000 - val_loss: 6.0158e-05 - val_accuracy: 1.0000 - 927ms/epoch - 37ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 5.6523e-05 - accuracy: 1.0000 - val_loss: 5.7898e-05 - val_accuracy: 1.0000 - 928ms/epoch - 37ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 5.4444e-05 - accuracy: 1.0000 - val_loss: 5.5747e-05 - val_accuracy: 1.0000 - 891ms/epoch - 36ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 5.2371e-05 - accuracy: 1.0000 - val_loss: 5.3791e-05 - val_accuracy: 1.0000 - 938ms/epoch - 38ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 5.0556e-05 - accuracy: 1.0000 - val_loss: 5.1867e-05 - val_accuracy: 1.0000 - 931ms/epoch - 37ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 4.8769e-05 - accuracy: 1.0000 - val_loss: 5.0011e-05 - val_accuracy: 1.0000 - 928ms/epoch - 37ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 4.7088e-05 - accuracy: 1.0000 - val_loss: 4.8238e-05 - val_accuracy: 1.0000 - 939ms/epoch - 38ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 4.5393e-05 - accuracy: 1.0000 - val_loss: 4.6710e-05 - val_accuracy: 1.0000 - 910ms/epoch - 36ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 4.3965e-05 - accuracy: 1.0000 - val_loss: 4.5173e-05 - val_accuracy: 1.0000 - 928ms/epoch - 37ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 4.2445e-05 - accuracy: 1.0000 - val_loss: 4.3631e-05 - val_accuracy: 1.0000 - 917ms/epoch - 37ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 4.1041e-05 - accuracy: 1.0000 - val_loss: 4.2202e-05 - val_accuracy: 1.0000 - 914ms/epoch - 37ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 3.9693e-05 - accuracy: 1.0000 - val_loss: 4.0888e-05 - val_accuracy: 1.0000 - 916ms/epoch - 37ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 3.8586e-05 - accuracy: 1.0000 - val_loss: 3.9577e-05 - val_accuracy: 1.0000 - 917ms/epoch - 37ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 3.7286e-05 - accuracy: 1.0000 - val_loss: 3.8409e-05 - val_accuracy: 1.0000 - 926ms/epoch - 37ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 3.6015e-05 - accuracy: 1.0000 - val_loss: 3.7149e-05 - val_accuracy: 1.0000 - 927ms/epoch - 37ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 3.4952e-05 - accuracy: 1.0000 - val_loss: 3.6009e-05 - val_accuracy: 1.0000 - 919ms/epoch - 37ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 3.3824e-05 - accuracy: 1.0000 - val_loss: 3.4935e-05 - val_accuracy: 1.0000 - 904ms/epoch - 36ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 3.2906e-05 - accuracy: 1.0000 - val_loss: 3.3884e-05 - val_accuracy: 1.0000 - 892ms/epoch - 36ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 3.1875e-05 - accuracy: 1.0000 - val_loss: 3.2859e-05 - val_accuracy: 1.0000 - 922ms/epoch - 37ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 3.0933e-05 - accuracy: 1.0000 - val_loss: 3.1945e-05 - val_accuracy: 1.0000 - 921ms/epoch - 37ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 2.9982e-05 - accuracy: 1.0000 - val_loss: 3.1015e-05 - val_accuracy: 1.0000 - 915ms/epoch - 37ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 2.9142e-05 - accuracy: 1.0000 - val_loss: 3.0103e-05 - val_accuracy: 1.0000 - 904ms/epoch - 36ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 2.8289e-05 - accuracy: 1.0000 - val_loss: 2.9244e-05 - val_accuracy: 1.0000 - 905ms/epoch - 36ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 2.7475e-05 - accuracy: 1.0000 - val_loss: 2.8434e-05 - val_accuracy: 1.0000 - 913ms/epoch - 37ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 2.6729e-05 - accuracy: 1.0000 - val_loss: 2.7643e-05 - val_accuracy: 1.0000 - 912ms/epoch - 36ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 2.6049e-05 - accuracy: 1.0000 - val_loss: 2.6908e-05 - val_accuracy: 1.0000 - 922ms/epoch - 37ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 2.5311e-05 - accuracy: 1.0000 - val_loss: 2.6168e-05 - val_accuracy: 1.0000 - 917ms/epoch - 37ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 2.4582e-05 - accuracy: 1.0000 - val_loss: 2.5447e-05 - val_accuracy: 1.0000 - 919ms/epoch - 37ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 2.3903e-05 - accuracy: 1.0000 - val_loss: 2.4779e-05 - val_accuracy: 1.0000 - 919ms/epoch - 37ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 2.3294e-05 - accuracy: 1.0000 - val_loss: 2.4117e-05 - val_accuracy: 1.0000 - 924ms/epoch - 37ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 2.2670e-05 - accuracy: 1.0000 - val_loss: 2.3485e-05 - val_accuracy: 1.0000 - 909ms/epoch - 36ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 2.2095e-05 - accuracy: 1.0000 - val_loss: 2.2894e-05 - val_accuracy: 1.0000 - 925ms/epoch - 37ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 2.1511e-05 - accuracy: 1.0000 - val_loss: 2.2304e-05 - val_accuracy: 1.0000 - 911ms/epoch - 36ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 2.0925e-05 - accuracy: 1.0000 - val_loss: 2.1736e-05 - val_accuracy: 1.0000 - 918ms/epoch - 37ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6981 - accuracy: 0.4645 - val_loss: 0.6934 - val_accuracy: 0.4998 - 2s/epoch - 89ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6944 - accuracy: 0.4898 - val_loss: 0.6934 - val_accuracy: 0.5110 - 983ms/epoch - 39ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5178 - val_loss: 0.6935 - val_accuracy: 0.5051 - 972ms/epoch - 39ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5127 - val_loss: 0.6936 - val_accuracy: 0.4998 - 974ms/epoch - 39ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6934 - val_accuracy: 0.5048 - 962ms/epoch - 38ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6928 - val_accuracy: 0.5123 - 1s/epoch - 41ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5140 - val_loss: 0.6930 - val_accuracy: 0.5080 - 967ms/epoch - 39ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5102 - val_loss: 0.6926 - val_accuracy: 0.5078 - 977ms/epoch - 39ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6922 - val_accuracy: 0.5140 - 1s/epoch - 40ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5089 - val_loss: 0.6915 - val_accuracy: 0.5092 - 967ms/epoch - 39ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5317 - val_loss: 0.6888 - val_accuracy: 0.5490 - 979ms/epoch - 39ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6886 - accuracy: 0.5406 - val_loss: 0.6857 - val_accuracy: 0.5766 - 1s/epoch - 40ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6863 - accuracy: 0.5520 - val_loss: 0.6830 - val_accuracy: 0.5633 - 949ms/epoch - 38ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6861 - accuracy: 0.5508 - val_loss: 0.6822 - val_accuracy: 0.5677 - 960ms/epoch - 38ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6775 - accuracy: 0.5799 - val_loss: 0.6698 - val_accuracy: 0.5953 - 993ms/epoch - 40ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6710 - accuracy: 0.5888 - val_loss: 0.6624 - val_accuracy: 0.6159 - 967ms/epoch - 39ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6550 - accuracy: 0.6244 - val_loss: 0.6563 - val_accuracy: 0.6229 - 1s/epoch - 40ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6550 - accuracy: 0.6269 - val_loss: 0.6650 - val_accuracy: 0.5938 - 946ms/epoch - 38ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6495 - accuracy: 0.6066 - val_loss: 0.6395 - val_accuracy: 0.6388 - 975ms/epoch - 39ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6213 - accuracy: 0.6815 - val_loss: 0.6251 - val_accuracy: 0.6524 - 991ms/epoch - 40ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6109 - accuracy: 0.6612 - val_loss: 0.6297 - val_accuracy: 0.6536 - 1s/epoch - 40ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.5957 - accuracy: 0.6865 - val_loss: 0.5826 - val_accuracy: 0.7140 - 1s/epoch - 40ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.5710 - accuracy: 0.7234 - val_loss: 0.5542 - val_accuracy: 0.7434 - 992ms/epoch - 40ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.5345 - accuracy: 0.7475 - val_loss: 0.5149 - val_accuracy: 0.7758 - 990ms/epoch - 40ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.5126 - accuracy: 0.7551 - val_loss: 0.4973 - val_accuracy: 0.7801 - 979ms/epoch - 39ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.4862 - accuracy: 0.7805 - val_loss: 0.4522 - val_accuracy: 0.8171 - 1s/epoch - 40ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.4377 - accuracy: 0.8071 - val_loss: 0.4477 - val_accuracy: 0.8420 - 995ms/epoch - 40ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.4154 - accuracy: 0.8401 - val_loss: 0.4049 - val_accuracy: 0.8649 - 1s/epoch - 40ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.3742 - accuracy: 0.8579 - val_loss: 0.3654 - val_accuracy: 0.8801 - 997ms/epoch - 40ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.3392 - accuracy: 0.8756 - val_loss: 0.3057 - val_accuracy: 0.9137 - 977ms/epoch - 39ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.2766 - accuracy: 0.9137 - val_loss: 0.2536 - val_accuracy: 0.9309 - 976ms/epoch - 39ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.2319 - accuracy: 0.9340 - val_loss: 0.2115 - val_accuracy: 0.9537 - 995ms/epoch - 40ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.1808 - accuracy: 0.9594 - val_loss: 0.1650 - val_accuracy: 0.9586 - 997ms/epoch - 40ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.1750 - accuracy: 0.9569 - val_loss: 0.1539 - val_accuracy: 0.9695 - 986ms/epoch - 39ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.1458 - accuracy: 0.9670 - val_loss: 0.1126 - val_accuracy: 0.9892 - 1s/epoch - 40ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.1099 - accuracy: 0.9860 - val_loss: 0.0857 - val_accuracy: 0.9924 - 988ms/epoch - 40ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.0827 - accuracy: 0.9924 - val_loss: 0.0730 - val_accuracy: 0.9939 - 1s/epoch - 41ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.0706 - accuracy: 0.9898 - val_loss: 0.0515 - val_accuracy: 0.9968 - 993ms/epoch - 40ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.0565 - accuracy: 0.9937 - val_loss: 0.0779 - val_accuracy: 0.9892 - 987ms/epoch - 39ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.0636 - accuracy: 0.9873 - val_loss: 0.0529 - val_accuracy: 0.9970 - 974ms/epoch - 39ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.0549 - accuracy: 0.9937 - val_loss: 0.0437 - val_accuracy: 0.9954 - 977ms/epoch - 39ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.0418 - accuracy: 0.9949 - val_loss: 0.0258 - val_accuracy: 0.9985 - 969ms/epoch - 39ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.0256 - accuracy: 0.9987 - val_loss: 0.0195 - val_accuracy: 1.0000 - 999ms/epoch - 40ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.0161 - accuracy: 0.9987 - val_loss: 0.0111 - val_accuracy: 1.0000 - 981ms/epoch - 39ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9970 - 943ms/epoch - 38ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.0202 - accuracy: 0.9975 - val_loss: 0.0130 - val_accuracy: 0.9985 - 960ms/epoch - 38ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.0099 - val_accuracy: 0.9984 - 969ms/epoch - 39ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.0155 - accuracy: 0.9975 - val_loss: 0.0128 - val_accuracy: 1.0000 - 977ms/epoch - 39ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.0307 - accuracy: 0.9924 - val_loss: 0.0952 - val_accuracy: 0.9734 - 984ms/epoch - 39ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.0795 - accuracy: 0.9822 - val_loss: 0.0415 - val_accuracy: 0.9939 - 951ms/epoch - 38ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.1187 - accuracy: 0.9619 - val_loss: 0.0903 - val_accuracy: 0.9816 - 977ms/epoch - 39ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.0577 - accuracy: 0.9873 - val_loss: 0.0310 - val_accuracy: 0.9985 - 966ms/epoch - 39ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.0210 - accuracy: 0.9975 - val_loss: 0.0109 - val_accuracy: 1.0000 - 978ms/epoch - 39ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000 - 968ms/epoch - 39ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000 - 971ms/epoch - 39ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000 - 984ms/epoch - 39ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - 992ms/epoch - 40ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000 - 971ms/epoch - 39ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - 990ms/epoch - 40ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - 949ms/epoch - 38ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - 968ms/epoch - 39ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000 - 988ms/epoch - 40ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - 967ms/epoch - 39ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - 962ms/epoch - 38ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - 998ms/epoch - 40ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - 965ms/epoch - 39ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - 962ms/epoch - 38ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - 962ms/epoch - 38ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - 968ms/epoch - 39ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 9.5057e-04 - accuracy: 1.0000 - val_loss: 9.9124e-04 - val_accuracy: 1.0000 - 956ms/epoch - 38ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 8.9085e-04 - accuracy: 1.0000 - val_loss: 9.3523e-04 - val_accuracy: 1.0000 - 961ms/epoch - 38ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 8.4358e-04 - accuracy: 1.0000 - val_loss: 8.8451e-04 - val_accuracy: 1.0000 - 984ms/epoch - 39ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 7.9743e-04 - accuracy: 1.0000 - val_loss: 8.3398e-04 - val_accuracy: 1.0000 - 958ms/epoch - 38ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 7.4992e-04 - accuracy: 1.0000 - val_loss: 7.9082e-04 - val_accuracy: 1.0000 - 974ms/epoch - 39ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 7.1316e-04 - accuracy: 1.0000 - val_loss: 7.4886e-04 - val_accuracy: 1.0000 - 992ms/epoch - 40ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 6.7707e-04 - accuracy: 1.0000 - val_loss: 7.1397e-04 - val_accuracy: 1.0000 - 975ms/epoch - 39ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 6.4474e-04 - accuracy: 1.0000 - val_loss: 6.7889e-04 - val_accuracy: 1.0000 - 960ms/epoch - 38ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 6.1205e-04 - accuracy: 1.0000 - val_loss: 6.4551e-04 - val_accuracy: 1.0000 - 967ms/epoch - 39ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 5.8380e-04 - accuracy: 1.0000 - val_loss: 6.1547e-04 - val_accuracy: 1.0000 - 976ms/epoch - 39ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 5.5661e-04 - accuracy: 1.0000 - val_loss: 5.8826e-04 - val_accuracy: 1.0000 - 979ms/epoch - 39ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 5.3268e-04 - accuracy: 1.0000 - val_loss: 5.6260e-04 - val_accuracy: 1.0000 - 965ms/epoch - 39ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 5.0749e-04 - accuracy: 1.0000 - val_loss: 5.3838e-04 - val_accuracy: 1.0000 - 959ms/epoch - 38ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 4.8847e-04 - accuracy: 1.0000 - val_loss: 5.1568e-04 - val_accuracy: 1.0000 - 979ms/epoch - 39ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 4.6809e-04 - accuracy: 1.0000 - val_loss: 4.9514e-04 - val_accuracy: 1.0000 - 967ms/epoch - 39ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 4.4954e-04 - accuracy: 1.0000 - val_loss: 4.7557e-04 - val_accuracy: 1.0000 - 970ms/epoch - 39ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 4.3138e-04 - accuracy: 1.0000 - val_loss: 4.5619e-04 - val_accuracy: 1.0000 - 982ms/epoch - 39ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 4.1356e-04 - accuracy: 1.0000 - val_loss: 4.3884e-04 - val_accuracy: 1.0000 - 935ms/epoch - 37ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 3.9746e-04 - accuracy: 1.0000 - val_loss: 4.2217e-04 - val_accuracy: 1.0000 - 977ms/epoch - 39ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 3.8244e-04 - accuracy: 1.0000 - val_loss: 4.0706e-04 - val_accuracy: 1.0000 - 983ms/epoch - 39ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 3.6902e-04 - accuracy: 1.0000 - val_loss: 3.9162e-04 - val_accuracy: 1.0000 - 951ms/epoch - 38ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 3.5529e-04 - accuracy: 1.0000 - val_loss: 3.7786e-04 - val_accuracy: 1.0000 - 960ms/epoch - 38ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 3.4282e-04 - accuracy: 1.0000 - val_loss: 3.6458e-04 - val_accuracy: 1.0000 - 982ms/epoch - 39ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 3.3006e-04 - accuracy: 1.0000 - val_loss: 3.5160e-04 - val_accuracy: 1.0000 - 980ms/epoch - 39ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 3.1907e-04 - accuracy: 1.0000 - val_loss: 3.3953e-04 - val_accuracy: 1.0000 - 978ms/epoch - 39ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 3.0847e-04 - accuracy: 1.0000 - val_loss: 3.2816e-04 - val_accuracy: 1.0000 - 978ms/epoch - 39ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 2.9840e-04 - accuracy: 1.0000 - val_loss: 3.1734e-04 - val_accuracy: 1.0000 - 975ms/epoch - 39ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 2.8808e-04 - accuracy: 1.0000 - val_loss: 3.0718e-04 - val_accuracy: 1.0000 - 981ms/epoch - 39ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 2.7915e-04 - accuracy: 1.0000 - val_loss: 2.9659e-04 - val_accuracy: 1.0000 - 979ms/epoch - 39ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 2.7006e-04 - accuracy: 1.0000 - val_loss: 2.8785e-04 - val_accuracy: 1.0000 - 975ms/epoch - 39ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 2.6121e-04 - accuracy: 1.0000 - val_loss: 2.7843e-04 - val_accuracy: 1.0000 - 964ms/epoch - 39ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "tf.keras.utils.enable_interactive_logging()\n",
    "for ln in range(5, 13):\n",
    "    print(f\"{ln - 5}/8\", end=\"\\r\")\n",
    "    X, Y = create_data(\n",
    "        10000,\n",
    "        ln=ln,\n",
    "        initial_key1=np.array([1, 0, 1, 1, 1]),\n",
    "        initial_key2=np.array([1, 1, 1, 0, 1]),\n",
    "    )\n",
    "    X_train, Y_train = X[: 800 - ln], Y[: 800 - ln]\n",
    "    X_test, Y_test = X[800 - ln :], Y[800 - ln :]\n",
    "    model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # tf.keras.layers.GRU(300, input_shape=(ln, 1)),\n",
    "        tf.keras.layers.SimpleRNN(200, input_shape=(ln, 1), activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "        # tf.keras.layers.Embedding(2, 5, input_length=5),\n",
    "        # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, input_shape=(ln, 1))),\n",
    "        # tf.keras.layers.LSTM(100, input_shape=(ln, 1), activation=\"sigmoid\", recurrent_activation=\"sigmoid\"),\n",
    "        # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        # tf.keras.layers.Conv1D(100, 3, 1, input_shape=(ln, 1), activation=\"relu\"),\n",
    "        # tf.keras.layers.Conv1D(200, 3, 1, activation=\"relu\"),\n",
    "        # tf.keras.layers.Conv1D(400, 3, 1, activation=\"relu\"),\n",
    "        # tf.keras.layers.MaxPooling1D(3),\n",
    "        # tf.keras.layers.Flatten(),\n",
    "        # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # model.summary()\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[callback],\n",
    "        verbose=2\n",
    "    )\n",
    "    model = tf.keras.models.load_model(\"model.h5\")\n",
    "    l, ac = model.evaluate(X_test, Y_test)\n",
    "    lengths.append(ln)\n",
    "    accuracies.append(ac)\n",
    "    losses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lengths, accuracies)\n",
    "plt.plot(lengths, losses)\n",
    "plt.grid()\n",
    "plt.legend([\"Accuracy\", \"Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# tf.keras.utils.enable_interactive_logging()\n",
    "for sq_ln in range(150, 501, 50):\n",
    "\n",
    "    ln = 10\n",
    "\n",
    "    X, Y = create_data(\n",
    "        10000,\n",
    "        ln=ln,\n",
    "        initial_key1=np.array([1, 0, 1, 1, 1]),\n",
    "        initial_key2=np.array([1, 1, 1, 0, 1]),\n",
    "    )\n",
    "    X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "    X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "            # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "            # tf.keras.layers.LSTM(5),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # model.summary()\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[callback],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model = tf.keras.models.load_model(\"model.h5\")\n",
    "    l, ac = model.evaluate(X_test, Y_test)\n",
    "    lengths.append(sq_ln)\n",
    "    accuracies.append(ac)\n",
    "    losses.append(l)\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(lengths, accuracies)\n",
    "    plt.plot(lengths, losses)\n",
    "    plt.legend([\"Accuracy\", \"Loss\"])\n",
    "    print(f\"Sequence length: {sq_ln}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lengths, accuracies)\n",
    "plt.plot(lengths, losses)\n",
    "plt.legend([\"Accuracy\", \"Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1364639699459076, 0.9952631592750549]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial key 1:  [0 0 1 1 0]\n",
      "Initial key 2:  [0 1 1 1 1]\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1361 - accuracy: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13614453375339508, 0.995195209980011]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = create_data(10000, ln=10)\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001627977762836963 1.0\n",
      "0.027096500620245934 1.0\n",
      "0.027099456638097763 1.0\n",
      "0.02709682285785675 1.0\n",
      "0.02710133045911789 1.0\n",
      "0.02709275484085083 1.0\n",
      "0.027095673605799675 1.0\n",
      "0.02709517441689968 1.0\n",
      "0.027095001190900803 1.0\n",
      "0.027100099250674248 1.0\n",
      "0.027091754600405693 1.0\n",
      "0.027095170691609383 1.0\n",
      "0.02709691971540451 1.0\n",
      "0.027092278003692627 1.0\n",
      "0.02709146775305271 1.0\n",
      "0.027095044031739235 1.0\n",
      "0.027096008881926537 1.0\n",
      "0.027098780497908592 1.0\n",
      "0.027094535529613495 1.0\n",
      "0.027093661949038506 1.0\n",
      "0.027092503383755684 1.0\n",
      "0.027091510593891144 1.0\n",
      "0.027097944170236588 1.0\n",
      "0.027090352028608322 1.0\n",
      "0.027108965441584587 1.0\n",
      "0.027095798403024673 1.0\n",
      "0.027092641219496727 1.0\n",
      "0.02709127776324749 1.0\n",
      "0.027111951261758804 1.0\n",
      "0.027092285454273224 1.0\n",
      "0.027110831812024117 1.0\n",
      "0.027099519968032837 1.0\n",
      "0.028543516993522644 1.0\n",
      "0.010601012967526913 1.0\n",
      "0.010621019639074802 1.0\n",
      "0.010682213120162487 1.0\n",
      "0.01063036173582077 1.0\n",
      "0.010549264028668404 1.0\n",
      "0.010678859427571297 1.0\n",
      "0.010609365068376064 1.0\n",
      "0.010685519315302372 1.0\n",
      "0.01061057485640049 1.0\n",
      "0.010623199865221977 1.0\n",
      "0.010583294555544853 1.0\n",
      "0.010677031241357327 1.0\n",
      "0.01066623255610466 1.0\n",
      "0.010624941438436508 1.0\n",
      "0.010638220235705376 1.0\n",
      "0.010681558400392532 1.0\n",
      "0.010678955353796482 1.0\n",
      "0.010600997135043144 1.0\n",
      "0.010614440776407719 1.0\n",
      "0.010664792731404305 1.0\n",
      "0.010575342923402786 1.0\n",
      "0.010665463283658028 1.0\n",
      "0.010652104392647743 1.0\n",
      "0.010581143200397491 1.0\n",
      "0.010675525292754173 1.0\n",
      "0.010589607059955597 1.0\n",
      "0.010596519336104393 1.0\n",
      "0.01056677382439375 1.0\n",
      "0.010614385828375816 1.0\n",
      "0.01061499584466219 1.0\n",
      "0.01062215305864811 1.0\n",
      "0.02854158543050289 1.0\n",
      "0.010681862942874432 1.0\n",
      "0.010601351037621498 1.0\n",
      "0.010677102021872997 1.0\n",
      "0.010620631277561188 1.0\n",
      "0.01059794146567583 1.0\n",
      "0.010681945830583572 1.0\n",
      "0.010604364797472954 1.0\n",
      "0.010664565488696098 1.0\n",
      "0.010628998279571533 1.0\n",
      "0.010575230233371258 1.0\n",
      "0.010549137368798256 1.0\n",
      "0.01066503208130598 1.0\n",
      "0.010676580481231213 1.0\n",
      "0.010652038268744946 1.0\n",
      "0.01060546562075615 1.0\n",
      "0.01068499218672514 1.0\n",
      "0.010580764152109623 1.0\n",
      "0.010609320364892483 1.0\n",
      "0.01067481841892004 1.0\n",
      "0.010624571703374386 1.0\n",
      "0.010588877834379673 1.0\n",
      "0.010582515969872475 1.0\n",
      "0.010597201995551586 1.0\n",
      "0.010561607778072357 1.0\n",
      "0.010676227509975433 1.0\n",
      "0.010613473132252693 1.0\n",
      "0.010661475360393524 1.0\n",
      "0.01061552856117487 1.0\n",
      "0.010625011287629604 1.0\n",
      "0.010620837099850178 1.0\n",
      "0.010637899860739708 1.0\n",
      "0.02853498049080372 1.0\n",
      "0.010578508488833904 1.0\n",
      "0.010643907822668552 1.0\n",
      "0.010619500651955605 1.0\n",
      "0.01066812314093113 1.0\n",
      "0.010604684241116047 1.0\n",
      "0.010615695267915726 1.0\n",
      "0.010588075965642929 1.0\n",
      "0.010617847554385662 1.0\n",
      "0.010689135640859604 1.0\n",
      "0.010650964453816414 1.0\n",
      "0.01062473002821207 1.0\n",
      "0.010608389973640442 1.0\n",
      "0.010553416796028614 1.0\n",
      "0.01068128738552332 1.0\n",
      "0.01067177951335907 1.0\n",
      "0.010587048716843128 1.0\n",
      "0.010637897998094559 1.0\n",
      "0.01068347878754139 1.0\n",
      "0.010554293170571327 1.0\n",
      "0.01062378566712141 1.0\n",
      "0.010605603456497192 1.0\n",
      "0.010628814809024334 1.0\n",
      "0.010675809346139431 1.0\n",
      "0.010607069358229637 1.0\n",
      "0.01059769932180643 1.0\n",
      "0.01065748929977417 1.0\n",
      "0.010580579750239849 1.0\n",
      "0.010599174536764622 1.0\n",
      "0.010675749741494656 1.0\n",
      "0.010679689235985279 1.0\n",
      "0.010679290629923344 1.0\n",
      "0.028545839712023735 1.0\n",
      "0.010686933062970638 1.0\n",
      "0.010684004984796047 1.0\n",
      "0.01058103609830141 1.0\n",
      "0.01060082670301199 1.0\n",
      "0.010609034448862076 1.0\n",
      "0.010676711797714233 1.0\n",
      "0.010677176527678967 1.0\n",
      "0.010626248084008694 1.0\n",
      "0.01062227226793766 1.0\n",
      "0.010588651522994041 1.0\n",
      "0.010598158463835716 1.0\n",
      "0.010585012845695019 1.0\n",
      "0.010682141408324242 1.0\n",
      "0.010599600151181221 1.0\n",
      "0.010604769922792912 1.0\n",
      "0.01066491287201643 1.0\n",
      "0.010560572147369385 1.0\n",
      "0.010629122145473957 1.0\n",
      "0.010676673613488674 1.0\n",
      "0.010576584376394749 1.0\n",
      "0.010614552535116673 1.0\n",
      "0.010550291277468204 1.0\n",
      "0.010660853236913681 1.0\n",
      "0.010616736486554146 1.0\n",
      "0.010667402297258377 1.0\n",
      "0.010625415481626987 1.0\n",
      "0.010677982121706009 1.0\n",
      "0.010622210800647736 1.0\n",
      "0.010652978904545307 1.0\n",
      "0.010638314299285412 1.0\n",
      "0.010606275871396065 1.0\n",
      "0.028523515909910202 1.0\n",
      "0.010612180456519127 1.0\n",
      "0.010648246854543686 1.0\n",
      "0.010681914165616035 1.0\n",
      "0.010621785186231136 1.0\n",
      "0.010578286834061146 1.0\n",
      "0.010679040104150772 1.0\n",
      "0.010632414370775223 1.0\n",
      "0.010675154626369476 1.0\n",
      "0.010621258988976479 1.0\n",
      "0.01066726166754961 1.0\n",
      "0.01065978966653347 1.0\n",
      "0.010690631344914436 1.0\n",
      "0.010601557791233063 1.0\n",
      "0.010616689920425415 1.0\n",
      "0.01062946580350399 1.0\n",
      "0.010647201910614967 1.0\n",
      "0.010671118274331093 1.0\n",
      "0.010587338358163834 1.0\n",
      "0.010603654198348522 1.0\n",
      "0.010679898783564568 1.0\n",
      "0.010579721070826054 1.0\n",
      "0.010673686861991882 1.0\n",
      "0.010635728016495705 1.0\n",
      "0.010601240210235119 1.0\n",
      "0.010680042207241058 1.0\n",
      "0.010549025610089302 1.0\n",
      "0.010612927377223969 1.0\n",
      "0.010564751923084259 1.0\n",
      "0.010619071312248707 1.0\n",
      "0.010598384775221348 1.0\n",
      "0.010606834664940834 1.0\n",
      "0.028534816578030586 1.0\n",
      "0.010588248260319233 1.0\n",
      "0.01057929266244173 1.0\n",
      "0.010637554340064526 1.0\n",
      "0.010649845004081726 1.0\n",
      "0.01068268995732069 1.0\n",
      "0.010618316009640694 1.0\n",
      "0.010555639863014221 1.0\n",
      "0.01062371488660574 1.0\n",
      "0.010668376460671425 1.0\n",
      "0.01060688216239214 1.0\n",
      "0.010604379698634148 1.0\n",
      "0.010628693737089634 1.0\n",
      "0.010615956969559193 1.0\n",
      "0.010673719458281994 1.0\n",
      "0.010587980970740318 1.0\n",
      "0.010617953725159168 1.0\n",
      "0.010608264245092869 1.0\n",
      "0.010690252296626568 1.0\n",
      "0.01059823390096426 1.0\n",
      "0.010651064105331898 1.0\n",
      "0.010656741447746754 1.0\n",
      "0.010624896734952927 1.0\n",
      "0.010580806992948055 1.0\n",
      "0.010599728673696518 1.0\n",
      "0.010608641430735588 1.0\n",
      "0.010676213540136814 1.0\n",
      "0.010552620515227318 1.0\n",
      "0.010680284351110458 1.0\n",
      "0.010680971667170525 1.0\n",
      "0.010679780505597591 1.0\n",
      "0.010672654956579208 1.0\n",
      "0.031325116753578186 1.0\n",
      "0.030318081378936768 1.0\n",
      "0.03031669370830059 1.0\n",
      "0.030318111181259155 1.0\n",
      "0.030325736850500107 1.0\n",
      "0.030315810814499855 1.0\n",
      "0.030313212424516678 1.0\n",
      "0.030325720086693764 1.0\n",
      "0.030324868857860565 1.0\n",
      "0.030321676284074783 1.0\n",
      "0.030317170545458794 1.0\n",
      "0.030323809012770653 1.0\n",
      "0.030312051996588707 1.0\n",
      "0.030324786901474 1.0\n",
      "0.030317766591906548 1.0\n",
      "0.0303114652633667 1.0\n",
      "0.030319778248667717 1.0\n",
      "0.03031962551176548 1.0\n",
      "0.030314862728118896 1.0\n",
      "0.030327782034873962 1.0\n",
      "0.03031495399773121 1.0\n",
      "0.030321024358272552 1.0\n",
      "0.030318085104227066 1.0\n",
      "0.030312424525618553 1.0\n",
      "0.030321309342980385 1.0\n",
      "0.03032025136053562 1.0\n",
      "0.03031575307250023 1.0\n",
      "0.03031989373266697 1.0\n",
      "0.030316360294818878 1.0\n",
      "0.030314847826957703 1.0\n",
      "0.030324777588248253 1.0\n",
      "0.030316874384880066 1.0\n",
      "0.028542982414364815 1.0\n",
      "0.01066543161869049 1.0\n",
      "0.01068784762173891 1.0\n",
      "0.010557161644101143 1.0\n",
      "0.010684196837246418 1.0\n",
      "0.010629105381667614 1.0\n",
      "0.010581644251942635 1.0\n",
      "0.010677838698029518 1.0\n",
      "0.01057728286832571 1.0\n",
      "0.010601907968521118 1.0\n",
      "0.01061504427343607 1.0\n",
      "0.01060937624424696 1.0\n",
      "0.010550640523433685 1.0\n",
      "0.010676193982362747 1.0\n",
      "0.010659608989953995 1.0\n",
      "0.010677752085030079 1.0\n",
      "0.010626697912812233 1.0\n",
      "0.01061681006103754 1.0\n",
      "0.010623261332511902 1.0\n",
      "0.010669487528502941 1.0\n",
      "0.010588135570287704 1.0\n",
      "0.010624808259308338 1.0\n",
      "0.010597643442451954 1.0\n",
      "0.010678142309188843 1.0\n",
      "0.01062189880758524 1.0\n",
      "0.0105863306671381 1.0\n",
      "0.010653506964445114 1.0\n",
      "0.01068160030990839 1.0\n",
      "0.01063874363899231 1.0\n",
      "0.010600975714623928 1.0\n",
      "0.010606169700622559 1.0\n",
      "0.010603375732898712 1.0\n",
      "0.03132972866296768 1.0\n",
      "0.030329274013638496 1.0\n",
      "0.030312759801745415 1.0\n",
      "0.030327556654810905 1.0\n",
      "0.03030998259782791 1.0\n",
      "0.03031427413225174 1.0\n",
      "0.03031769022345543 1.0\n",
      "0.030312027782201767 1.0\n",
      "0.030311714857816696 1.0\n",
      "0.030319498851895332 1.0\n",
      "0.030312439426779747 1.0\n",
      "0.030315658077597618 1.0\n",
      "0.030318867415189743 1.0\n",
      "0.030314791947603226 1.0\n",
      "0.030316269025206566 1.0\n",
      "0.030320661142468452 1.0\n",
      "0.030314447358250618 1.0\n",
      "0.030312106013298035 1.0\n",
      "0.030317042022943497 1.0\n",
      "0.030312715098261833 1.0\n",
      "0.03031839057803154 1.0\n",
      "0.030319545418024063 1.0\n",
      "0.03031451813876629 1.0\n",
      "0.030310936272144318 1.0\n",
      "0.030316749587655067 1.0\n",
      "0.03031238354742527 1.0\n",
      "0.030314121395349503 1.0\n",
      "0.030316269025206566 1.0\n",
      "0.030313072726130486 1.0\n",
      "0.03031734749674797 1.0\n",
      "0.030321229249238968 1.0\n",
      "0.03031057119369507 1.0\n",
      "0.028525423258543015 1.0\n",
      "0.010647373273968697 1.0\n",
      "0.010615034028887749 1.0\n",
      "0.010672048665583134 1.0\n",
      "0.010648485273122787 1.0\n",
      "0.010587906464934349 1.0\n",
      "0.010683084838092327 1.0\n",
      "0.010603677481412888 1.0\n",
      "0.010680202394723892 1.0\n",
      "0.010621106252074242 1.0\n",
      "0.010580241680145264 1.0\n",
      "0.010579343885183334 1.0\n",
      "0.010676720179617405 1.0\n",
      "0.010679425671696663 1.0\n",
      "0.010635585524141788 1.0\n",
      "0.01063814852386713 1.0\n",
      "0.010677912272512913 1.0\n",
      "0.010602538473904133 1.0\n",
      "0.010621524415910244 1.0\n",
      "0.010680533945560455 1.0\n",
      "0.010668287053704262 1.0\n",
      "0.010548993945121765 1.0\n",
      "0.01066075824201107 1.0\n",
      "0.010613941587507725 1.0\n",
      "0.01056697778403759 1.0\n",
      "0.010692885145545006 1.0\n",
      "0.010619128122925758 1.0\n",
      "0.01060166023671627 1.0\n",
      "0.010598714463412762 1.0\n",
      "0.01061695534735918 1.0\n",
      "0.010606667026877403 1.0\n",
      "0.010630798526108265 1.0\n",
      "0.028521617874503136 1.0\n",
      "0.010679208673536777 1.0\n",
      "0.01067778468132019 1.0\n",
      "0.010568538680672646 1.0\n",
      "0.010646031238138676 1.0\n",
      "0.010619796812534332 1.0\n",
      "0.010606487281620502 1.0\n",
      "0.010691743344068527 1.0\n",
      "0.010580453090369701 1.0\n",
      "0.010617143474519253 1.0\n",
      "0.010615098290145397 1.0\n",
      "0.010619458742439747 1.0\n",
      "0.010578912682831287 1.0\n",
      "0.010670777410268784 1.0\n",
      "0.010602219961583614 1.0\n",
      "0.010677418671548367 1.0\n",
      "0.010668283328413963 1.0\n",
      "0.01059654075652361 1.0\n",
      "0.010645645670592785 1.0\n",
      "0.010681835003197193 1.0\n",
      "0.010548392310738564 1.0\n",
      "0.010617466643452644 1.0\n",
      "0.010585866868495941 1.0\n",
      "0.01067870482802391 1.0\n",
      "0.010607732459902763 1.0\n",
      "0.010671408846974373 1.0\n",
      "0.010633046738803387 1.0\n",
      "0.01068317424505949 1.0\n",
      "0.010627281852066517 1.0\n",
      "0.010614645667374134 1.0\n",
      "0.01064248289912939 1.0\n",
      "0.010599316097795963 1.0\n",
      "0.028524812310934067 1.0\n",
      "0.010617815889418125 1.0\n",
      "0.010588006116449833 1.0\n",
      "0.01060790941119194 1.0\n",
      "0.010579300113022327 1.0\n",
      "0.010689881630241871 1.0\n",
      "0.010637271218001842 1.0\n",
      "0.010598516091704369 1.0\n",
      "0.01064989436417818 1.0\n",
      "0.01064981147646904 1.0\n",
      "0.010652138851583004 1.0\n",
      "0.010682303458452225 1.0\n",
      "0.0106266550719738 1.0\n",
      "0.010617565363645554 1.0\n",
      "0.010579888708889484 1.0\n",
      "0.010556875728070736 1.0\n",
      "0.010623544454574585 1.0\n",
      "0.010598951950669289 1.0\n",
      "0.010668618604540825 1.0\n",
      "0.010608257725834846 1.0\n",
      "0.01060696691274643 1.0\n",
      "0.010675718076527119 1.0\n",
      "0.010603992268443108 1.0\n",
      "0.010551366955041885 1.0\n",
      "0.010680407285690308 1.0\n",
      "0.010628731921315193 1.0\n",
      "0.010681218467652798 1.0\n",
      "0.010615464299917221 1.0\n",
      "0.010680511593818665 1.0\n",
      "0.010670099407434464 1.0\n",
      "0.010672003962099552 1.0\n",
      "0.01058803591877222 1.0\n",
      "0.024028360843658447 1.0\n",
      "0.01998225972056389 1.0\n",
      "0.01998881809413433 1.0\n",
      "0.01998332142829895 1.0\n",
      "0.020004162564873695 1.0\n",
      "0.02000425010919571 1.0\n",
      "0.019993968307971954 1.0\n",
      "0.02001013234257698 1.0\n",
      "0.01999976485967636 1.0\n",
      "0.01998540200293064 1.0\n",
      "0.01998881809413433 1.0\n",
      "0.019987456500530243 1.0\n",
      "0.020008472725749016 1.0\n",
      "0.020006908103823662 1.0\n",
      "0.020003052428364754 1.0\n",
      "0.01998784765601158 1.0\n",
      "0.02000029943883419 1.0\n",
      "0.020008785650134087 1.0\n",
      "0.01998080685734749 1.0\n",
      "0.01997644640505314 1.0\n",
      "0.01998591609299183 1.0\n",
      "0.02000540681183338 1.0\n",
      "0.019979896023869514 1.0\n",
      "0.019995585083961487 1.0\n",
      "0.01999211683869362 1.0\n",
      "0.019986353814601898 1.0\n",
      "0.019993377849459648 1.0\n",
      "0.019977673888206482 1.0\n",
      "0.019992975518107414 1.0\n",
      "0.019978754222393036 1.0\n",
      "0.020008429884910583 1.0\n",
      "0.01998528465628624 1.0\n",
      "0.03132404759526253 1.0\n",
      "0.03032069094479084 1.0\n",
      "0.03031914122402668 1.0\n",
      "0.030324013903737068 1.0\n",
      "0.030315300449728966 1.0\n",
      "0.030318448320031166 1.0\n",
      "0.030322382226586342 1.0\n",
      "0.030328825116157532 1.0\n",
      "0.030316555872559547 1.0\n",
      "0.030333107337355614 1.0\n",
      "0.030324066057801247 1.0\n",
      "0.030311107635498047 1.0\n",
      "0.030325034633278847 1.0\n",
      "0.030313674360513687 1.0\n",
      "0.03032149001955986 1.0\n",
      "0.030325211584568024 1.0\n",
      "0.03032551147043705 1.0\n",
      "0.030323423445224762 1.0\n",
      "0.03032100386917591 1.0\n",
      "0.030324768275022507 1.0\n",
      "0.030316917225718498 1.0\n",
      "0.030314505100250244 1.0\n",
      "0.030320003628730774 1.0\n",
      "0.030321048572659492 1.0\n",
      "0.030316855758428574 1.0\n",
      "0.030312418937683105 1.0\n",
      "0.030318524688482285 1.0\n",
      "0.03031875751912594 1.0\n",
      "0.030331021174788475 1.0\n",
      "0.0303170308470726 1.0\n",
      "0.03032056614756584 1.0\n",
      "0.030315877869725227 1.0\n",
      "0.028533410280942917 1.0\n",
      "0.010580452159047127 1.0\n",
      "0.010665779002010822 1.0\n",
      "0.010608842596411705 1.0\n",
      "0.010678154416382313 1.0\n",
      "0.010615551844239235 1.0\n",
      "0.010595953091979027 1.0\n",
      "0.010674863122403622 1.0\n",
      "0.010610189288854599 1.0\n",
      "0.010676288977265358 1.0\n",
      "0.010632505640387535 1.0\n",
      "0.010643730871379375 1.0\n",
      "0.010616723448038101 1.0\n",
      "0.010570892132818699 1.0\n",
      "0.01068301685154438 1.0\n",
      "0.010682064108550549 1.0\n",
      "0.010548572987318039 1.0\n",
      "0.01062630396336317 1.0\n",
      "0.010630449280142784 1.0\n",
      "0.010579895228147507 1.0\n",
      "0.01061633788049221 1.0\n",
      "0.010616663843393326 1.0\n",
      "0.010620196349918842 1.0\n",
      "0.010670402087271214 1.0\n",
      "0.010646834038197994 1.0\n",
      "0.01058454904705286 1.0\n",
      "0.010601679794490337 1.0\n",
      "0.010608607903122902 1.0\n",
      "0.010598228313028812 1.0\n",
      "0.010679767467081547 1.0\n",
      "0.010675422847270966 1.0\n",
      "0.010689022950828075 1.0\n",
      "0.028545523062348366 1.0\n",
      "0.01062006875872612 1.0\n",
      "0.010631917975842953 1.0\n",
      "0.010680392384529114 1.0\n",
      "0.01061306893825531 1.0\n",
      "0.010582290589809418 1.0\n",
      "0.010666515678167343 1.0\n",
      "0.010640030726790428 1.0\n",
      "0.010680011473596096 1.0\n",
      "0.010603810660541058 1.0\n",
      "0.010665449313819408 1.0\n",
      "0.010664824396371841 1.0\n",
      "0.010676424019038677 1.0\n",
      "0.010597984306514263 1.0\n",
      "0.010612971149384975 1.0\n",
      "0.010621897876262665 1.0\n",
      "0.01060163788497448 1.0\n",
      "0.010682268999516964 1.0\n",
      "0.010549172759056091 1.0\n",
      "0.010612227953970432 1.0\n",
      "0.010685134679079056 1.0\n",
      "0.010620903223752975 1.0\n",
      "0.010677427984774113 1.0\n",
      "0.010624054819345474 1.0\n",
      "0.010679054073989391 1.0\n",
      "0.01061446126550436 1.0\n",
      "0.010574683547019958 1.0\n",
      "0.010652423836290836 1.0\n",
      "0.010580193251371384 1.0\n",
      "0.01059031207114458 1.0\n",
      "0.01057218573987484 1.0\n",
      "0.01061395276337862 1.0\n",
      "0.028532758355140686 1.0\n",
      "0.010633422061800957 1.0\n",
      "0.01066703349351883 1.0\n",
      "0.010615099221467972 1.0\n",
      "0.010688147507607937 1.0\n",
      "0.010623953305184841 1.0\n",
      "0.010556546971201897 1.0\n",
      "0.01066973339766264 1.0\n",
      "0.010586857795715332 1.0\n",
      "0.010684123262763023 1.0\n",
      "0.010623645968735218 1.0\n",
      "0.010628816671669483 1.0\n",
      "0.010597397573292255 1.0\n",
      "0.01058046706020832 1.0\n",
      "0.010676736012101173 1.0\n",
      "0.010678773745894432 1.0\n",
      "0.01057733129709959 1.0\n",
      "0.010621374472975731 1.0\n",
      "0.010603389702737331 1.0\n",
      "0.010586624965071678 1.0\n",
      "0.010615951381623745 1.0\n",
      "0.010651561431586742 1.0\n",
      "0.010608652606606483 1.0\n",
      "0.010680558159947395 1.0\n",
      "0.010638142004609108 1.0\n",
      "0.010550842620432377 1.0\n",
      "0.010603310540318489 1.0\n",
      "0.010675697587430477 1.0\n",
      "0.010606605559587479 1.0\n",
      "0.010659288614988327 1.0\n",
      "0.010601552203297615 1.0\n",
      "0.010678276419639587 1.0\n",
      "0.02852003276348114 1.0\n",
      "0.010648504830896854 1.0\n",
      "0.010624011978507042 1.0\n",
      "0.010681064799427986 1.0\n",
      "0.010621685534715652 1.0\n",
      "0.010656546801328659 1.0\n",
      "0.0106016481295228 1.0\n",
      "0.010629531927406788 1.0\n",
      "0.010649414733052254 1.0\n",
      "0.010588572360575199 1.0\n",
      "0.01068014558404684 1.0\n",
      "0.01067240722477436 1.0\n",
      "0.010681366547942162 1.0\n",
      "0.01061057299375534 1.0\n",
      "0.010617955587804317 1.0\n",
      "0.010607698932290077 1.0\n",
      "0.01061100885272026 1.0\n",
      "0.010681450366973877 1.0\n",
      "0.010579363442957401 1.0\n",
      "0.010631599463522434 1.0\n",
      "0.010675068013370037 1.0\n",
      "0.010668788105249405 1.0\n",
      "0.010691402480006218 1.0\n",
      "0.010616595856845379 1.0\n",
      "0.010672276839613914 1.0\n",
      "0.010605095885694027 1.0\n",
      "0.01058049313724041 1.0\n",
      "0.010636573657393456 1.0\n",
      "0.010601687245070934 1.0\n",
      "0.010549517348408699 1.0\n",
      "0.010564458556473255 1.0\n",
      "0.010598341003060341 1.0\n",
      "0.031325556337833405 1.0\n",
      "0.030315149575471878 1.0\n",
      "0.03032328002154827 1.0\n",
      "0.030312759801745415 1.0\n",
      "0.030318334698677063 1.0\n",
      "0.030324267223477364 1.0\n",
      "0.0303212720900774 1.0\n",
      "0.030312610790133476 1.0\n",
      "0.030321791768074036 1.0\n",
      "0.030311670154333115 1.0\n",
      "0.030314989387989044 1.0\n",
      "0.03031545877456665 1.0\n",
      "0.030319038778543472 1.0\n",
      "0.030317161232233047 1.0\n",
      "0.03031117469072342 1.0\n",
      "0.030316082760691643 1.0\n",
      "0.030314145609736443 1.0\n",
      "0.0303153395652771 1.0\n",
      "0.0303178858011961 1.0\n",
      "0.030315153300762177 1.0\n",
      "0.03031313605606556 1.0\n",
      "0.0303131602704525 1.0\n",
      "0.03031346946954727 1.0\n",
      "0.030316263437271118 1.0\n",
      "0.030313173308968544 1.0\n",
      "0.030325116589665413 1.0\n",
      "0.030318209901452065 1.0\n",
      "0.0303106140345335 1.0\n",
      "0.0303218811750412 1.0\n",
      "0.03031538613140583 1.0\n",
      "0.03031315468251705 1.0\n",
      "0.03032318875193596 1.0\n"
     ]
    }
   ],
   "source": [
    "tl, tac = 0, 0\n",
    "for i in range(1024):\n",
    "    keys = np.binary_repr(i, width=10)\n",
    "    keys = np.array([int(k) for k in keys])\n",
    "    key1 = keys[:5]\n",
    "    key2 = keys[5:]\n",
    "    X, Y = create_data(\n",
    "        10000,\n",
    "        ln=15,\n",
    "        initial_key1=key1,\n",
    "        initial_key2=key2,\n",
    "    )\n",
    "    l, ac = model.evaluate(X, Y)\n",
    "    print(l,ac)\n",
    "    tl += l\n",
    "    tac += ac\n",
    "print(\"Total Loss and Accuracy: \", tl/1024, tac/1024)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key1:  [1 1 1 0 0]\n",
      "Key2:  [0 0 1 0 1]\n",
      "Sequence length: 250 with accuracy: 0.7001025676727295 and loss: 0.6093835234642029\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [1 0 0 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7047179341316223 and loss: 0.6492166519165039\n",
      "Key1:  [1 1 0 1 1]\n",
      "Key2:  [0 0 0 0 0]\n",
      "Sequence length: 150 with accuracy: 1.0 and loss: 0.4989528954029083\n",
      "Key1:  [0 0 1 0 1]\n",
      "Key2:  [1 0 0 0 1]\n",
      "Sequence length: 250 with accuracy: 0.7076923251152039 and loss: 0.6359493732452393\n",
      "Key1:  [1 0 1 0 0]\n",
      "Key2:  [1 0 1 1 0]\n",
      "Sequence length: 150 with accuracy: 0.7120811939239502 and loss: 0.6169815063476562\n",
      "Key1:  [1 1 0 0 0]\n",
      "Key2:  [1 1 1 0 0]\n",
      "Sequence length: 250 with accuracy: 0.7001025676727295 and loss: 0.5866572260856628\n",
      "Key1:  [0 0 1 0 0]\n",
      "Key2:  [0 0 0 0 0]\n",
      "Sequence length: 150 with accuracy: 0.7142131924629211 and loss: 0.6509259343147278\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [1 1 1 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7076923251152039 and loss: 0.5833685994148254\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [0 0 0 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7015384435653687 and loss: 0.5906823873519897\n",
      "Key1:  [1 0 0 1 1]\n",
      "Key2:  [0 1 0 0 1]\n",
      "Sequence length: 150 with accuracy: 0.703045666217804 and loss: 0.5921750664710999\n"
     ]
    }
   ],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[\"val_accuracy\"] > self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(10):\n",
    "    key1 = np.random.randint(0, 2, 5)\n",
    "    key2 = np.random.randint(0, 2, 5)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Key1: \", key1)\n",
    "    print(\"Key2: \", key2)\n",
    "    while True\n",
    "    for sq_ln in range(150, 501, 50):\n",
    "        ln = 10\n",
    "        X, Y = create_data(\n",
    "            10000,\n",
    "            ln=ln,\n",
    "            initial_key1=key1,\n",
    "            initial_key2=key2,\n",
    "        )\n",
    "        X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "        X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "                # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "                # tf.keras.layers.LSTM(5),\n",
    "                tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[ThresholdCallback(0.7)],\n",
    "            verbose=0,\n",
    "        )\n",
    "        l, ac = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        if ac > 0.7:\n",
    "            print(f\"Sequence length: {sq_ln} with accuracy: {ac} and loss: {l}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key1:  [1 1 0 0 1]\n",
      "Key2:  [1 0 1 0 1]\n",
      "Sequence length: 250 with accuracy: 0.707897424697876 and loss: 0.6060001850128174\n",
      "Key1:  [0 0 0 0 0]\n",
      "Key2:  [0 1 1 0 1]\n",
      "Sequence length: 50 with accuracy: 0.7420100569725037 and loss: 0.6757830381393433\n",
      "Key1:  [1 0 1 1 0]\n",
      "Key2:  [1 1 1 1 1]\n",
      "Sequence length: 100 with accuracy: 0.7529292702674866 and loss: 0.6520717144012451\n",
      "Key1:  [1 0 1 0 0]\n",
      "Key2:  [1 0 0 1 0]\n",
      "Sequence length: 100 with accuracy: 0.7027272582054138 and loss: 0.638469398021698\n",
      "Key1:  [1 0 0 0 0]\n",
      "Key2:  [1 0 1 1 0]\n",
      "Sequence length: 250 with accuracy: 0.7061538696289062 and loss: 0.6032127141952515\n",
      "Key1:  [1 0 1 1 0]\n",
      "Key2:  [0 1 1 1 1]\n",
      "Sequence length: 100 with accuracy: 0.7093939185142517 and loss: 0.6635072231292725\n",
      "Key1:  [1 0 0 0 1]\n",
      "Key2:  [0 0 0 0 0]\n",
      "Sequence length: 50 with accuracy: 0.7141708731651306 and loss: 0.61024409532547\n",
      "Key1:  [0 0 1 0 1]\n",
      "Key2:  [0 1 0 0 1]\n",
      "Sequence length: 250 with accuracy: 0.7030768990516663 and loss: 0.6300603747367859\n",
      "Key1:  [1 0 0 0 0]\n",
      "Key2:  [0 1 1 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7015384435653687 and loss: 0.6107650995254517\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [0 1 1 0 0]\n",
      "Sequence length: 250 with accuracy: 0.7015384435653687 and loss: 0.5968985557556152\n"
     ]
    }
   ],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[\"val_accuracy\"] > self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(10):\n",
    "    key1 = np.random.randint(0, 2, 5)\n",
    "    key2 = np.random.randint(0, 2, 5)\n",
    "    print(\"Key1: \", key1)\n",
    "    print(\"Key2: \", key2)\n",
    "    for sq_ln in range(50, 501, 50):\n",
    "        ln = 10\n",
    "        X, Y = create_data(\n",
    "            10000,\n",
    "            ln=ln,\n",
    "            initial_key1=key1,\n",
    "            initial_key2=key2,\n",
    "        )\n",
    "        X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "        X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "                # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "                # tf.keras.layers.LSTM(5),\n",
    "                tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[ThresholdCallback(0.7)],\n",
    "            verbose=0,\n",
    "        )\n",
    "        l, ac = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        if ac > 0.7:\n",
    "            print(f\"Sequence length: {sq_ln} with accuracy: {ac} and loss: {l}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Key1:  [1 1 1 1 0]\n",
      "Key2:  [0 1 0 1 1]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n",
      "Sequence length: 220 with accuracy: 0.70030677318573 and loss: 1.4538100957870483\n",
      "---------------------\n",
      "Key1:  [1 1 1 0 0]\n",
      "Key2:  [1 0 1 1 1]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n",
      "Sequence length: 220 with accuracy: 0.702658474445343 and loss: 2.3781282901763916\n",
      "---------------------\n",
      "Key1:  [1 1 1 1 0]\n",
      "Key2:  [0 1 1 1 1]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n",
      "Sequence length: 220 with accuracy: 0.701636016368866 and loss: 1.6949256658554077\n",
      "---------------------\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [1 0 1 1 1]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n",
      "Sequence length: 220 with accuracy: 0.7020449638366699 and loss: 1.8083406686782837\n",
      "---------------------\n",
      "Key1:  [1 1 1 0 1]\n",
      "Key2:  [1 0 0 0 1]\n",
      "Period of first LFSR:  7\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  217\n",
      "Sequence length: 170 with accuracy: 0.7299084663391113 and loss: 0.6430106163024902\n",
      "---------------------\n",
      "Key1:  [1 1 1 1 0]\n",
      "Key2:  [1 1 1 1 0]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n",
      "Sequence length: 270 with accuracy: 0.7041109800338745 and loss: 0.7710883021354675\n",
      "---------------------\n",
      "Key1:  [0 1 0 0 1]\n",
      "Key2:  [0 1 0 0 1]\n",
      "Period of first LFSR:  7\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  217\n",
      "Sequence length: 170 with accuracy: 0.702644944190979 and loss: 0.6717475652694702\n",
      "---------------------\n",
      "Key1:  [1 0 1 1 0]\n",
      "Key2:  [1 0 1 1 1]\n",
      "Period of first LFSR:  3\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  93\n",
      "Sequence length: 70 with accuracy: 0.7310171127319336 and loss: 0.5814135074615479\n",
      "---------------------\n",
      "Key1:  [1 0 1 0 1]\n",
      "Key2:  [1 1 1 0 1]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n",
      "Sequence length: 220 with accuracy: 0.701329231262207 and loss: 1.6091018915176392\n",
      "---------------------\n",
      "Key1:  [1 1 0 1 0]\n",
      "Key2:  [1 1 0 0 1]\n",
      "Period of first LFSR:  7\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  217\n",
      "Sequence length: 170 with accuracy: 0.7075279951095581 and loss: 0.6427282094955444\n"
     ]
    }
   ],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[\"val_accuracy\"] > self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(10):\n",
    "    key1 = np.random.randint(0, 2, 5)\n",
    "    key2 = np.random.randint(0, 2, 5)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Key1: \", key1)\n",
    "    print(\"Key2: \", key2)\n",
    "    init_key1 = key1\n",
    "    init_key2 = key2\n",
    "    i = 0\n",
    "    while True:\n",
    "        nxt = key1[0] ^ key1[1]\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key1[-1] = nxt\n",
    "        i += 1\n",
    "        if np.array_equal(key1, init_key1):\n",
    "            break\n",
    "    print(\"Period of first LFSR: \", i)\n",
    "    i=0\n",
    "    while True:\n",
    "        nxt = key2[0] ^ key2[2]\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key2[-1] = nxt\n",
    "        i += 1\n",
    "        if np.array_equal(key2, init_key2):\n",
    "            break\n",
    "    print(\"Period of second LFSR: \", i)\n",
    "    i = 0\n",
    "    while True:\n",
    "        nxt1 = key1[0] ^ key1[1]\n",
    "        nxt2 = key2[0] ^ key2[2]\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key1[-1] = nxt1\n",
    "        key2[-1] = nxt2\n",
    "        i += 1\n",
    "        if np.array_equal(key1, init_key1) and np.array_equal(key2, init_key2):\n",
    "            break\n",
    "    print(\"Period of combined: \", i)      \n",
    "    for sq_ln in range(20, 521, 50):\n",
    "        ln = 10\n",
    "        X, Y = create_data(\n",
    "            10000,\n",
    "            ln=ln,\n",
    "            initial_key1=key1,\n",
    "            initial_key2=key2,\n",
    "        )\n",
    "        X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "        X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "        model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            # tf.keras.layers.GRU(300, input_shape=(ln, 1)),\n",
    "            tf.keras.layers.SimpleRNN(200, input_shape=(ln, 1), activation=\"relu\"),\n",
    "            # tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "            # tf.keras.layers.Embedding(2, 5, input_length=5),\n",
    "            # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, input_shape=(ln, 1))),\n",
    "            # tf.keras.layers.LSTM(100, input_shape=(ln, 1), activation=\"sigmoid\", recurrent_activation=\"sigmoid\"),\n",
    "            # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "            # tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            # tf.keras.layers.Conv1D(100, 3, 1, input_shape=(ln, 1), activation=\"relu\"),\n",
    "            # tf.keras.layers.Conv1D(200, 3, 1, activation=\"relu\"),\n",
    "            # tf.keras.layers.Conv1D(400, 3, 1, activation=\"relu\"),\n",
    "            # tf.keras.layers.MaxPooling1D(3),\n",
    "            # tf.keras.layers.Flatten(),\n",
    "            # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[ThresholdCallback(0.7)],\n",
    "            verbose=0,\n",
    "        )\n",
    "        l, ac = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        if ac > 0.7:\n",
    "            print(f\"Sequence length: {sq_ln} with accuracy: {ac} and loss: {l}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

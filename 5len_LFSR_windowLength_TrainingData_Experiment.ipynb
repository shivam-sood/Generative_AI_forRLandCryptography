{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 07:50:59.830864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 07:50:59.984354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:50:59.984396: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-05 07:51:02.035108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:02.035663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:02.035692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Create a LSTM model to predict the next bit of a LFSR\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def create_data(num_samples=10000, initial_key1=None, initial_key2=None, ln=5):\n",
    "    if initial_key1 is None:\n",
    "        initial_key1 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 1: \", initial_key1)\n",
    "    if initial_key2 is None:\n",
    "        initial_key2 = np.random.randint(0, 2, 5)\n",
    "        print(\"Initial key 2: \", initial_key2)\n",
    "\n",
    "    # data = initial_key\n",
    "    key1 = initial_key1\n",
    "    key2 = initial_key2\n",
    "    x = []\n",
    "    y = []\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        nxt1 = key1[0] ^ key1[1]\n",
    "        nxt2 = key2[0] ^ key2[2]\n",
    "        data.append(nxt1 ^ nxt2)\n",
    "        if len(data) >= ln + 1:\n",
    "            x.append(data[-(ln + 1) : -1])\n",
    "            y.append(data[-1])\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key1[-1] = nxt1\n",
    "        key2[-1] = nxt2\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9990, 10)\n"
     ]
    }
   ],
   "source": [
    "ln = 10\n",
    "X, Y = create_data(\n",
    "    10000,\n",
    "    ln=ln,\n",
    "    initial_key1=np.array([1, 0, 1, 1, 1]),\n",
    "    initial_key2=np.array([1, 1, 1, 0, 1]),\n",
    ")\n",
    "X_train, Y_train = X[: 500 - ln], Y[: 500 - ln]\n",
    "X_test, Y_test = X[500 - ln :], Y[500 - ln :]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1000)              11000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,001\n",
      "Trainable params: 12,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 07:51:05.764585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:05.764869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:05.765115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:05.765343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:05.816344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/TensorRT-8.4.0.6//lib:/usr/local/cuda-11.6/lib64:/usr/local/apps/python-3.10.2/lib:/usr/local/apps/cuDNN/8.4.0-cuda-11.6/lib\n",
      "2024-04-05 07:51:05.816551: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-04-05 07:51:05.817215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(500, activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        # tf.keras.layers.Embedding(2, 5, input_length=5),\n",
    "        # tf.keras.layers.LSTM(5),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 1s - loss: 0.7049 - accuracy: 0.4592 - val_loss: 0.6976 - val_accuracy: 0.4978 - 1s/epoch - 93ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 0s - loss: 0.6935 - accuracy: 0.4918 - val_loss: 0.6934 - val_accuracy: 0.5098 - 387ms/epoch - 24ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 0s - loss: 0.6924 - accuracy: 0.5265 - val_loss: 0.6904 - val_accuracy: 0.5336 - 399ms/epoch - 25ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 0s - loss: 0.6901 - accuracy: 0.5347 - val_loss: 0.6892 - val_accuracy: 0.5539 - 405ms/epoch - 25ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 0s - loss: 0.6873 - accuracy: 0.5510 - val_loss: 0.6877 - val_accuracy: 0.5712 - 412ms/epoch - 26ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 0s - loss: 0.6867 - accuracy: 0.5694 - val_loss: 0.6866 - val_accuracy: 0.5767 - 418ms/epoch - 26ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 0s - loss: 0.6863 - accuracy: 0.5551 - val_loss: 0.6850 - val_accuracy: 0.5802 - 410ms/epoch - 26ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 0s - loss: 0.6813 - accuracy: 0.5857 - val_loss: 0.6831 - val_accuracy: 0.5829 - 383ms/epoch - 24ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 0s - loss: 0.6763 - accuracy: 0.6429 - val_loss: 0.6812 - val_accuracy: 0.5979 - 408ms/epoch - 26ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 0s - loss: 0.6776 - accuracy: 0.6020 - val_loss: 0.6777 - val_accuracy: 0.6143 - 368ms/epoch - 23ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 0s - loss: 0.6693 - accuracy: 0.6755 - val_loss: 0.6741 - val_accuracy: 0.6228 - 382ms/epoch - 24ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 0s - loss: 0.6674 - accuracy: 0.6592 - val_loss: 0.6707 - val_accuracy: 0.6644 - 384ms/epoch - 24ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 0s - loss: 0.6613 - accuracy: 0.7000 - val_loss: 0.6672 - val_accuracy: 0.6436 - 391ms/epoch - 24ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 0s - loss: 0.6557 - accuracy: 0.6939 - val_loss: 0.6612 - val_accuracy: 0.6796 - 405ms/epoch - 25ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 0s - loss: 0.6494 - accuracy: 0.7347 - val_loss: 0.6558 - val_accuracy: 0.6919 - 403ms/epoch - 25ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 0s - loss: 0.6457 - accuracy: 0.7306 - val_loss: 0.6510 - val_accuracy: 0.7033 - 414ms/epoch - 26ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 0s - loss: 0.6375 - accuracy: 0.7633 - val_loss: 0.6441 - val_accuracy: 0.7273 - 404ms/epoch - 25ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 0s - loss: 0.6316 - accuracy: 0.7694 - val_loss: 0.6382 - val_accuracy: 0.7347 - 403ms/epoch - 25ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 0s - loss: 0.6228 - accuracy: 0.7837 - val_loss: 0.6319 - val_accuracy: 0.7254 - 393ms/epoch - 25ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 0s - loss: 0.6141 - accuracy: 0.7755 - val_loss: 0.6246 - val_accuracy: 0.7739 - 399ms/epoch - 25ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 0s - loss: 0.6067 - accuracy: 0.7980 - val_loss: 0.6177 - val_accuracy: 0.7520 - 409ms/epoch - 26ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 0s - loss: 0.5960 - accuracy: 0.8204 - val_loss: 0.6072 - val_accuracy: 0.7935 - 364ms/epoch - 23ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 0s - loss: 0.5893 - accuracy: 0.8469 - val_loss: 0.5995 - val_accuracy: 0.8188 - 411ms/epoch - 26ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 0s - loss: 0.5844 - accuracy: 0.8041 - val_loss: 0.5922 - val_accuracy: 0.8002 - 377ms/epoch - 24ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 0s - loss: 0.5706 - accuracy: 0.8224 - val_loss: 0.5890 - val_accuracy: 0.7878 - 412ms/epoch - 26ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 0s - loss: 0.5679 - accuracy: 0.8286 - val_loss: 0.5761 - val_accuracy: 0.8020 - 416ms/epoch - 26ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 0s - loss: 0.5534 - accuracy: 0.8429 - val_loss: 0.5672 - val_accuracy: 0.8357 - 414ms/epoch - 26ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 0s - loss: 0.5426 - accuracy: 0.8755 - val_loss: 0.5565 - val_accuracy: 0.8387 - 399ms/epoch - 25ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 0s - loss: 0.5330 - accuracy: 0.8694 - val_loss: 0.5469 - val_accuracy: 0.8383 - 385ms/epoch - 24ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 0s - loss: 0.5216 - accuracy: 0.8857 - val_loss: 0.5392 - val_accuracy: 0.8444 - 414ms/epoch - 26ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 0s - loss: 0.5122 - accuracy: 0.9020 - val_loss: 0.5275 - val_accuracy: 0.8635 - 396ms/epoch - 25ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 0s - loss: 0.4998 - accuracy: 0.9000 - val_loss: 0.5175 - val_accuracy: 0.8678 - 406ms/epoch - 25ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 0s - loss: 0.4890 - accuracy: 0.9122 - val_loss: 0.5070 - val_accuracy: 0.8771 - 415ms/epoch - 26ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 0s - loss: 0.4834 - accuracy: 0.8959 - val_loss: 0.5032 - val_accuracy: 0.8571 - 399ms/epoch - 25ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 0s - loss: 0.4704 - accuracy: 0.9122 - val_loss: 0.4900 - val_accuracy: 0.8848 - 392ms/epoch - 25ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 0s - loss: 0.4594 - accuracy: 0.9265 - val_loss: 0.4790 - val_accuracy: 0.8939 - 404ms/epoch - 25ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 0s - loss: 0.4514 - accuracy: 0.9347 - val_loss: 0.4708 - val_accuracy: 0.9036 - 423ms/epoch - 26ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 0s - loss: 0.4461 - accuracy: 0.9306 - val_loss: 0.4651 - val_accuracy: 0.8984 - 404ms/epoch - 25ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 0s - loss: 0.4323 - accuracy: 0.9245 - val_loss: 0.4630 - val_accuracy: 0.8881 - 387ms/epoch - 24ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 0s - loss: 0.4265 - accuracy: 0.9020 - val_loss: 0.4431 - val_accuracy: 0.9125 - 386ms/epoch - 24ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 0s - loss: 0.4148 - accuracy: 0.9449 - val_loss: 0.4430 - val_accuracy: 0.8959 - 399ms/epoch - 25ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 0s - loss: 0.4055 - accuracy: 0.9388 - val_loss: 0.4237 - val_accuracy: 0.9263 - 422ms/epoch - 26ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 0s - loss: 0.3928 - accuracy: 0.9449 - val_loss: 0.4179 - val_accuracy: 0.9203 - 394ms/epoch - 25ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 0s - loss: 0.3868 - accuracy: 0.9306 - val_loss: 0.4068 - val_accuracy: 0.9314 - 396ms/epoch - 25ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 0s - loss: 0.3795 - accuracy: 0.9449 - val_loss: 0.3942 - val_accuracy: 0.9373 - 399ms/epoch - 25ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 0s - loss: 0.3655 - accuracy: 0.9551 - val_loss: 0.3865 - val_accuracy: 0.9373 - 379ms/epoch - 24ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 0s - loss: 0.3549 - accuracy: 0.9653 - val_loss: 0.3757 - val_accuracy: 0.9465 - 394ms/epoch - 25ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 0s - loss: 0.3444 - accuracy: 0.9612 - val_loss: 0.3669 - val_accuracy: 0.9623 - 393ms/epoch - 25ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 0s - loss: 0.3354 - accuracy: 0.9755 - val_loss: 0.3567 - val_accuracy: 0.9560 - 401ms/epoch - 25ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 0s - loss: 0.3264 - accuracy: 0.9735 - val_loss: 0.3495 - val_accuracy: 0.9544 - 379ms/epoch - 24ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 0s - loss: 0.3226 - accuracy: 0.9714 - val_loss: 0.3410 - val_accuracy: 0.9592 - 418ms/epoch - 26ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 0s - loss: 0.3075 - accuracy: 0.9837 - val_loss: 0.3311 - val_accuracy: 0.9686 - 413ms/epoch - 26ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 0s - loss: 0.3021 - accuracy: 0.9857 - val_loss: 0.3281 - val_accuracy: 0.9546 - 395ms/epoch - 25ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 0s - loss: 0.2948 - accuracy: 0.9816 - val_loss: 0.3203 - val_accuracy: 0.9593 - 406ms/epoch - 25ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 0s - loss: 0.2862 - accuracy: 0.9939 - val_loss: 0.3084 - val_accuracy: 0.9780 - 406ms/epoch - 25ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 0s - loss: 0.2808 - accuracy: 0.9878 - val_loss: 0.3002 - val_accuracy: 0.9749 - 400ms/epoch - 25ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 0s - loss: 0.2712 - accuracy: 0.9898 - val_loss: 0.2915 - val_accuracy: 0.9781 - 384ms/epoch - 24ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 0s - loss: 0.2620 - accuracy: 0.9939 - val_loss: 0.2868 - val_accuracy: 0.9781 - 411ms/epoch - 26ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 0s - loss: 0.2564 - accuracy: 0.9918 - val_loss: 0.2771 - val_accuracy: 0.9812 - 389ms/epoch - 24ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 0s - loss: 0.2513 - accuracy: 0.9959 - val_loss: 0.2747 - val_accuracy: 0.9797 - 404ms/epoch - 25ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 0s - loss: 0.2454 - accuracy: 0.9939 - val_loss: 0.2659 - val_accuracy: 0.9827 - 401ms/epoch - 25ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 0s - loss: 0.2393 - accuracy: 0.9918 - val_loss: 0.2582 - val_accuracy: 0.9843 - 388ms/epoch - 24ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 0s - loss: 0.2279 - accuracy: 0.9959 - val_loss: 0.2495 - val_accuracy: 0.9875 - 380ms/epoch - 24ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 0s - loss: 0.2194 - accuracy: 0.9980 - val_loss: 0.2430 - val_accuracy: 0.9889 - 405ms/epoch - 25ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 0s - loss: 0.2150 - accuracy: 0.9980 - val_loss: 0.2363 - val_accuracy: 0.9921 - 389ms/epoch - 24ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 0s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9889 - 388ms/epoch - 24ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 0s - loss: 0.2017 - accuracy: 0.9980 - val_loss: 0.2233 - val_accuracy: 0.9937 - 381ms/epoch - 24ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 0s - loss: 0.1970 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9859 - 412ms/epoch - 26ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 0s - loss: 0.1999 - accuracy: 0.9939 - val_loss: 0.2154 - val_accuracy: 0.9953 - 402ms/epoch - 25ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 0s - loss: 0.1894 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9953 - 382ms/epoch - 24ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 0s - loss: 0.1826 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9937 - 370ms/epoch - 23ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 0s - loss: 0.1785 - accuracy: 0.9980 - val_loss: 0.1970 - val_accuracy: 0.9968 - 395ms/epoch - 25ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 0s - loss: 0.1727 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9968 - 393ms/epoch - 25ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 0s - loss: 0.1688 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9937 - 403ms/epoch - 25ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 0s - loss: 0.1654 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9968 - 424ms/epoch - 26ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 0s - loss: 0.1576 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9968 - 385ms/epoch - 24ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 0s - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9968 - 406ms/epoch - 25ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 0s - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9968 - 381ms/epoch - 24ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 0s - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9968 - 383ms/epoch - 24ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 0s - loss: 0.1416 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9968 - 403ms/epoch - 25ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 0s - loss: 0.1361 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9968 - 398ms/epoch - 25ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 0s - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9984 - 369ms/epoch - 23ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 0s - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9968 - 396ms/epoch - 25ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 0s - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9984 - 399ms/epoch - 25ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 0s - loss: 0.1231 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9984 - 430ms/epoch - 27ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 0s - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9984 - 390ms/epoch - 24ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 0s - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9968 - 384ms/epoch - 24ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 0s - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9984 - 407ms/epoch - 25ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 0s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9984 - 395ms/epoch - 25ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 0s - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9984 - 370ms/epoch - 23ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 0s - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9984 - 414ms/epoch - 26ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 0s - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9968 - 386ms/epoch - 24ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 0s - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9984 - 398ms/epoch - 25ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 0s - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9968 - 404ms/epoch - 25ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 0s - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9984 - 425ms/epoch - 27ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 0s - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9984 - 398ms/epoch - 25ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 0s - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9984 - 378ms/epoch - 24ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 0s - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9984 - 372ms/epoch - 23ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 0s - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9984 - 392ms/epoch - 25ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 0s - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9984 - 395ms/epoch - 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x149a9552ad40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, validation_data=(X_test, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6974 - accuracy: 0.5019 - val_loss: 0.6946 - val_accuracy: 0.5025 - 2s/epoch - 66ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6943 - accuracy: 0.5195 - val_loss: 0.6938 - val_accuracy: 0.5045 - 815ms/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6953 - accuracy: 0.4906 - val_loss: 0.6938 - val_accuracy: 0.5063 - 820ms/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6936 - accuracy: 0.5145 - val_loss: 0.6932 - val_accuracy: 0.5080 - 817ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6939 - accuracy: 0.5069 - val_loss: 0.6942 - val_accuracy: 0.5051 - 792ms/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6937 - accuracy: 0.5145 - val_loss: 0.6931 - val_accuracy: 0.5096 - 830ms/epoch - 33ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6930 - accuracy: 0.5170 - val_loss: 0.6940 - val_accuracy: 0.5089 - 773ms/epoch - 31ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6934 - accuracy: 0.5069 - val_loss: 0.6930 - val_accuracy: 0.5096 - 818ms/epoch - 33ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6945 - accuracy: 0.4994 - val_loss: 0.6929 - val_accuracy: 0.5111 - 796ms/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6949 - accuracy: 0.5069 - val_loss: 0.6938 - val_accuracy: 0.5126 - 835ms/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5245 - val_loss: 0.6935 - val_accuracy: 0.5085 - 799ms/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6960 - accuracy: 0.4918 - val_loss: 0.6932 - val_accuracy: 0.5108 - 807ms/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6936 - accuracy: 0.5069 - val_loss: 0.6931 - val_accuracy: 0.5112 - 796ms/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6925 - accuracy: 0.5233 - val_loss: 0.6930 - val_accuracy: 0.5159 - 801ms/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6933 - accuracy: 0.5145 - val_loss: 0.6933 - val_accuracy: 0.5110 - 813ms/epoch - 33ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5346 - val_loss: 0.6928 - val_accuracy: 0.5127 - 776ms/epoch - 31ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5308 - val_loss: 0.6930 - val_accuracy: 0.5157 - 793ms/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5283 - val_loss: 0.6924 - val_accuracy: 0.5142 - 780ms/epoch - 31ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6929 - val_accuracy: 0.5127 - 776ms/epoch - 31ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5233 - val_loss: 0.6924 - val_accuracy: 0.5158 - 808ms/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5308 - val_loss: 0.6930 - val_accuracy: 0.5143 - 803ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5308 - val_loss: 0.6925 - val_accuracy: 0.5175 - 830ms/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6924 - accuracy: 0.5082 - val_loss: 0.6927 - val_accuracy: 0.5158 - 798ms/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5270 - val_loss: 0.6931 - val_accuracy: 0.5175 - 800ms/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6931 - val_accuracy: 0.5142 - 809ms/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5270 - val_loss: 0.6927 - val_accuracy: 0.5157 - 783ms/epoch - 31ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5296 - val_loss: 0.6926 - val_accuracy: 0.5142 - 793ms/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5384 - val_loss: 0.6929 - val_accuracy: 0.5146 - 792ms/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5245 - val_loss: 0.6934 - val_accuracy: 0.5157 - 811ms/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5308 - val_loss: 0.6935 - val_accuracy: 0.5172 - 791ms/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5129 - 769ms/epoch - 31ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5321 - val_loss: 0.6927 - val_accuracy: 0.5157 - 791ms/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5157 - 798ms/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5233 - val_loss: 0.6930 - val_accuracy: 0.5175 - 811ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6925 - accuracy: 0.5283 - val_loss: 0.6926 - val_accuracy: 0.5175 - 791ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6931 - val_accuracy: 0.5126 - 796ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5308 - val_loss: 0.6928 - val_accuracy: 0.5160 - 798ms/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5333 - val_loss: 0.6927 - val_accuracy: 0.5172 - 791ms/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5283 - val_loss: 0.6930 - val_accuracy: 0.5127 - 790ms/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5296 - val_loss: 0.6927 - val_accuracy: 0.5173 - 793ms/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5119 - val_loss: 0.6927 - val_accuracy: 0.5175 - 799ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5296 - val_loss: 0.6930 - val_accuracy: 0.5143 - 811ms/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5358 - val_loss: 0.6928 - val_accuracy: 0.5159 - 794ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5296 - val_loss: 0.6929 - val_accuracy: 0.5177 - 841ms/epoch - 34ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5245 - val_loss: 0.6927 - val_accuracy: 0.5188 - 848ms/epoch - 34ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5346 - val_loss: 0.6929 - val_accuracy: 0.5157 - 789ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5270 - val_loss: 0.6929 - val_accuracy: 0.5160 - 803ms/epoch - 32ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5270 - val_loss: 0.6928 - val_accuracy: 0.5146 - 804ms/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6938 - accuracy: 0.5082 - val_loss: 0.6926 - val_accuracy: 0.5161 - 799ms/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5409 - val_loss: 0.6939 - val_accuracy: 0.5159 - 793ms/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5107 - val_loss: 0.6927 - val_accuracy: 0.5146 - 790ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6928 - accuracy: 0.5283 - val_loss: 0.6929 - val_accuracy: 0.5172 - 763ms/epoch - 31ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5258 - val_loss: 0.6933 - val_accuracy: 0.5146 - 795ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6928 - val_accuracy: 0.5172 - 807ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6927 - val_accuracy: 0.5172 - 776ms/epoch - 31ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5358 - val_loss: 0.6927 - val_accuracy: 0.5175 - 781ms/epoch - 31ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6917 - accuracy: 0.5258 - val_loss: 0.6927 - val_accuracy: 0.5174 - 819ms/epoch - 33ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6927 - val_accuracy: 0.5146 - 788ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5308 - val_loss: 0.6928 - val_accuracy: 0.5145 - 816ms/epoch - 33ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5145 - val_loss: 0.6930 - val_accuracy: 0.5146 - 793ms/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5371 - val_loss: 0.6930 - val_accuracy: 0.5172 - 791ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5270 - val_loss: 0.6930 - val_accuracy: 0.5146 - 797ms/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5245 - val_loss: 0.6928 - val_accuracy: 0.5176 - 794ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5371 - val_loss: 0.6927 - val_accuracy: 0.5176 - 797ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6926 - accuracy: 0.5270 - val_loss: 0.6934 - val_accuracy: 0.5174 - 800ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5396 - val_loss: 0.6930 - val_accuracy: 0.5146 - 779ms/epoch - 31ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5258 - val_loss: 0.6928 - val_accuracy: 0.5176 - 789ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5321 - val_loss: 0.6927 - val_accuracy: 0.5175 - 775ms/epoch - 31ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5371 - val_loss: 0.6931 - val_accuracy: 0.5172 - 806ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5308 - val_loss: 0.6929 - val_accuracy: 0.5146 - 796ms/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5308 - val_loss: 0.6927 - val_accuracy: 0.5176 - 794ms/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5283 - val_loss: 0.6929 - val_accuracy: 0.5174 - 799ms/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5258 - val_loss: 0.6930 - val_accuracy: 0.5146 - 781ms/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5283 - val_loss: 0.6932 - val_accuracy: 0.5172 - 788ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5296 - val_loss: 0.6926 - val_accuracy: 0.5190 - 820ms/epoch - 33ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5258 - val_loss: 0.6930 - val_accuracy: 0.5146 - 809ms/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5358 - val_loss: 0.6928 - val_accuracy: 0.5146 - 790ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5258 - val_loss: 0.6931 - val_accuracy: 0.5172 - 797ms/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5283 - val_loss: 0.6929 - val_accuracy: 0.5146 - 806ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5296 - val_loss: 0.6929 - val_accuracy: 0.5129 - 781ms/epoch - 31ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5233 - val_loss: 0.6928 - val_accuracy: 0.5174 - 795ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5358 - val_loss: 0.6928 - val_accuracy: 0.5146 - 806ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5308 - val_loss: 0.6928 - val_accuracy: 0.5176 - 815ms/epoch - 33ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5296 - val_loss: 0.6927 - val_accuracy: 0.5176 - 798ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5245 - val_loss: 0.6931 - val_accuracy: 0.5174 - 798ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5176 - 806ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5358 - val_loss: 0.6929 - val_accuracy: 0.5176 - 789ms/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5308 - val_loss: 0.6928 - val_accuracy: 0.5145 - 777ms/epoch - 31ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5258 - val_loss: 0.6931 - val_accuracy: 0.5146 - 803ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5358 - val_loss: 0.6928 - val_accuracy: 0.5174 - 798ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5321 - val_loss: 0.6927 - val_accuracy: 0.5191 - 823ms/epoch - 33ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5358 - val_loss: 0.6929 - val_accuracy: 0.5160 - 774ms/epoch - 31ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5283 - val_loss: 0.6929 - val_accuracy: 0.5146 - 796ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5333 - val_loss: 0.6932 - val_accuracy: 0.5172 - 792ms/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5346 - val_loss: 0.6931 - val_accuracy: 0.5146 - 800ms/epoch - 32ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6931 - val_accuracy: 0.5159 - 790ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5308 - val_loss: 0.6927 - val_accuracy: 0.5161 - 807ms/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5321 - val_loss: 0.6929 - val_accuracy: 0.5175 - 800ms/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5258 - val_loss: 0.6930 - val_accuracy: 0.5160 - 792ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5270 - val_loss: 0.6928 - val_accuracy: 0.5129 - 800ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5191\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6988 - accuracy: 0.5013 - val_loss: 0.6955 - val_accuracy: 0.5025 - 2s/epoch - 72ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6960 - accuracy: 0.5176 - val_loss: 0.6961 - val_accuracy: 0.5016 - 794ms/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6947 - accuracy: 0.5076 - val_loss: 0.6947 - val_accuracy: 0.5023 - 799ms/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6943 - accuracy: 0.5063 - val_loss: 0.6936 - val_accuracy: 0.5060 - 825ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6941 - accuracy: 0.5050 - val_loss: 0.6925 - val_accuracy: 0.5146 - 805ms/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6931 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5074 - 788ms/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5050 - val_loss: 0.6937 - val_accuracy: 0.5154 - 812ms/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6938 - accuracy: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5123 - 765ms/epoch - 31ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6927 - val_accuracy: 0.5135 - 791ms/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6935 - accuracy: 0.5126 - val_loss: 0.6934 - val_accuracy: 0.5097 - 787ms/epoch - 31ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5264 - val_loss: 0.6934 - val_accuracy: 0.5152 - 784ms/epoch - 31ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5416 - val_loss: 0.6938 - val_accuracy: 0.5116 - 778ms/epoch - 31ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5302 - val_loss: 0.6924 - val_accuracy: 0.5135 - 801ms/epoch - 32ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6925 - accuracy: 0.5202 - val_loss: 0.6934 - val_accuracy: 0.5164 - 825ms/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5428 - val_loss: 0.6936 - val_accuracy: 0.5162 - 780ms/epoch - 31ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5340 - val_loss: 0.6942 - val_accuracy: 0.5168 - 838ms/epoch - 34ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5139 - 806ms/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5239 - val_loss: 0.6921 - val_accuracy: 0.5220 - 805ms/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5302 - val_loss: 0.6928 - val_accuracy: 0.5158 - 803ms/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5166 - 796ms/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5403 - val_loss: 0.6922 - val_accuracy: 0.5185 - 803ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5353 - val_loss: 0.6923 - val_accuracy: 0.5182 - 804ms/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5076 - val_loss: 0.6926 - val_accuracy: 0.5166 - 781ms/epoch - 31ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5290 - val_loss: 0.6923 - val_accuracy: 0.5198 - 779ms/epoch - 31ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5378 - val_loss: 0.6923 - val_accuracy: 0.5215 - 764ms/epoch - 31ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6912 - accuracy: 0.5340 - val_loss: 0.6924 - val_accuracy: 0.5180 - 799ms/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6906 - accuracy: 0.5403 - val_loss: 0.6930 - val_accuracy: 0.5177 - 802ms/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6897 - accuracy: 0.5466 - val_loss: 0.6921 - val_accuracy: 0.5196 - 769ms/epoch - 31ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5340 - val_loss: 0.6924 - val_accuracy: 0.5220 - 799ms/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5151 - val_loss: 0.6921 - val_accuracy: 0.5215 - 780ms/epoch - 31ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5441 - val_loss: 0.6925 - val_accuracy: 0.5196 - 809ms/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6901 - accuracy: 0.5353 - val_loss: 0.6925 - val_accuracy: 0.5182 - 825ms/epoch - 33ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6900 - accuracy: 0.5252 - val_loss: 0.6918 - val_accuracy: 0.5249 - 814ms/epoch - 33ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5579 - val_loss: 0.6923 - val_accuracy: 0.5198 - 790ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5327 - val_loss: 0.6921 - val_accuracy: 0.5230 - 791ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5390 - val_loss: 0.6926 - val_accuracy: 0.5218 - 787ms/epoch - 31ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5126 - val_loss: 0.6918 - val_accuracy: 0.5235 - 764ms/epoch - 31ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5315 - val_loss: 0.6926 - val_accuracy: 0.5199 - 786ms/epoch - 31ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5365 - val_loss: 0.6924 - val_accuracy: 0.5184 - 804ms/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5365 - val_loss: 0.6923 - val_accuracy: 0.5233 - 781ms/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5088 - val_loss: 0.6921 - val_accuracy: 0.5229 - 796ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6915 - accuracy: 0.5327 - val_loss: 0.6916 - val_accuracy: 0.5246 - 821ms/epoch - 33ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5416 - val_loss: 0.6922 - val_accuracy: 0.5186 - 786ms/epoch - 31ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6895 - accuracy: 0.5315 - val_loss: 0.6921 - val_accuracy: 0.5247 - 786ms/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5340 - val_loss: 0.6924 - val_accuracy: 0.5172 - 793ms/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5239 - val_loss: 0.6923 - val_accuracy: 0.5249 - 796ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6913 - accuracy: 0.5327 - val_loss: 0.6923 - val_accuracy: 0.5198 - 800ms/epoch - 32ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6907 - accuracy: 0.5365 - val_loss: 0.6925 - val_accuracy: 0.5215 - 788ms/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5378 - val_loss: 0.6916 - val_accuracy: 0.5233 - 789ms/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5327 - val_loss: 0.6917 - val_accuracy: 0.5250 - 832ms/epoch - 33ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5290 - val_loss: 0.6927 - val_accuracy: 0.5185 - 792ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5139 - val_loss: 0.6919 - val_accuracy: 0.5232 - 804ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5378 - val_loss: 0.6921 - val_accuracy: 0.5216 - 764ms/epoch - 31ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5428 - val_loss: 0.6920 - val_accuracy: 0.5199 - 801ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6900 - accuracy: 0.5277 - val_loss: 0.6924 - val_accuracy: 0.5201 - 805ms/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6899 - accuracy: 0.5453 - val_loss: 0.6920 - val_accuracy: 0.5215 - 841ms/epoch - 34ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6890 - accuracy: 0.5390 - val_loss: 0.6920 - val_accuracy: 0.5233 - 809ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6890 - accuracy: 0.5390 - val_loss: 0.6923 - val_accuracy: 0.5200 - 801ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6892 - accuracy: 0.5403 - val_loss: 0.6919 - val_accuracy: 0.5200 - 796ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6898 - accuracy: 0.5416 - val_loss: 0.6930 - val_accuracy: 0.5215 - 785ms/epoch - 31ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6897 - accuracy: 0.5239 - val_loss: 0.6920 - val_accuracy: 0.5249 - 817ms/epoch - 33ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6900 - accuracy: 0.5365 - val_loss: 0.6924 - val_accuracy: 0.5201 - 811ms/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6908 - accuracy: 0.5453 - val_loss: 0.6922 - val_accuracy: 0.5200 - 808ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6900 - accuracy: 0.5466 - val_loss: 0.6918 - val_accuracy: 0.5250 - 800ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6890 - accuracy: 0.5302 - val_loss: 0.6921 - val_accuracy: 0.5233 - 810ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6892 - accuracy: 0.5479 - val_loss: 0.6922 - val_accuracy: 0.5184 - 791ms/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6890 - accuracy: 0.5378 - val_loss: 0.6920 - val_accuracy: 0.5233 - 797ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5479 - val_loss: 0.6925 - val_accuracy: 0.5201 - 782ms/epoch - 31ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6886 - accuracy: 0.5466 - val_loss: 0.6921 - val_accuracy: 0.5250 - 796ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5428 - val_loss: 0.6921 - val_accuracy: 0.5232 - 797ms/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6901 - accuracy: 0.5390 - val_loss: 0.6924 - val_accuracy: 0.5199 - 803ms/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6895 - accuracy: 0.5441 - val_loss: 0.6922 - val_accuracy: 0.5201 - 795ms/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6878 - accuracy: 0.5504 - val_loss: 0.6927 - val_accuracy: 0.5213 - 786ms/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6888 - accuracy: 0.5441 - val_loss: 0.6924 - val_accuracy: 0.5250 - 799ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5390 - val_loss: 0.6920 - val_accuracy: 0.5252 - 835ms/epoch - 33ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6895 - accuracy: 0.5365 - val_loss: 0.6924 - val_accuracy: 0.5232 - 813ms/epoch - 33ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6892 - accuracy: 0.5403 - val_loss: 0.6918 - val_accuracy: 0.5232 - 814ms/epoch - 33ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5353 - val_loss: 0.6921 - val_accuracy: 0.5233 - 786ms/epoch - 31ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5466 - val_loss: 0.6922 - val_accuracy: 0.5200 - 796ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6887 - accuracy: 0.5441 - val_loss: 0.6920 - val_accuracy: 0.5232 - 777ms/epoch - 31ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5416 - val_loss: 0.6927 - val_accuracy: 0.5170 - 792ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6902 - accuracy: 0.5340 - val_loss: 0.6923 - val_accuracy: 0.5249 - 811ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5416 - val_loss: 0.6921 - val_accuracy: 0.5249 - 769ms/epoch - 31ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6896 - accuracy: 0.5365 - val_loss: 0.6927 - val_accuracy: 0.5215 - 796ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5353 - val_loss: 0.6922 - val_accuracy: 0.5218 - 806ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6879 - accuracy: 0.5441 - val_loss: 0.6922 - val_accuracy: 0.5265 - 821ms/epoch - 33ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6885 - accuracy: 0.5479 - val_loss: 0.6921 - val_accuracy: 0.5250 - 789ms/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6887 - accuracy: 0.5453 - val_loss: 0.6922 - val_accuracy: 0.5218 - 794ms/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6888 - accuracy: 0.5466 - val_loss: 0.6922 - val_accuracy: 0.5200 - 798ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6888 - accuracy: 0.5504 - val_loss: 0.6928 - val_accuracy: 0.5250 - 815ms/epoch - 33ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5466 - val_loss: 0.6923 - val_accuracy: 0.5252 - 800ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5327 - val_loss: 0.6920 - val_accuracy: 0.5232 - 795ms/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6896 - accuracy: 0.5403 - val_loss: 0.6925 - val_accuracy: 0.5184 - 797ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6897 - accuracy: 0.5302 - val_loss: 0.6923 - val_accuracy: 0.5232 - 788ms/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5416 - val_loss: 0.6925 - val_accuracy: 0.5216 - 771ms/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6882 - accuracy: 0.5479 - val_loss: 0.6925 - val_accuracy: 0.5250 - 811ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6881 - accuracy: 0.5479 - val_loss: 0.6922 - val_accuracy: 0.5233 - 817ms/epoch - 33ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6880 - accuracy: 0.5504 - val_loss: 0.6923 - val_accuracy: 0.5249 - 814ms/epoch - 33ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6885 - accuracy: 0.5554 - val_loss: 0.6922 - val_accuracy: 0.5248 - 792ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6895 - accuracy: 0.5428 - val_loss: 0.6921 - val_accuracy: 0.5250 - 805ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6922 - accuracy: 0.5265\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6987 - accuracy: 0.4754 - val_loss: 0.6935 - val_accuracy: 0.5068 - 2s/epoch - 67ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6963 - accuracy: 0.4905 - val_loss: 0.6935 - val_accuracy: 0.5074 - 829ms/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6975 - accuracy: 0.4994 - val_loss: 0.6928 - val_accuracy: 0.5141 - 823ms/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6977 - accuracy: 0.5032 - val_loss: 0.6936 - val_accuracy: 0.5097 - 818ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6924 - accuracy: 0.5145 - val_loss: 0.6928 - val_accuracy: 0.5153 - 821ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6937 - val_accuracy: 0.5096 - 808ms/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6921 - accuracy: 0.5069 - val_loss: 0.6923 - val_accuracy: 0.5136 - 776ms/epoch - 31ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6916 - accuracy: 0.5246 - val_loss: 0.6924 - val_accuracy: 0.5153 - 801ms/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6924 - val_accuracy: 0.5110 - 801ms/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5200 - 813ms/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6920 - accuracy: 0.5271 - val_loss: 0.6939 - val_accuracy: 0.5168 - 799ms/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6914 - accuracy: 0.5359 - val_loss: 0.6918 - val_accuracy: 0.5186 - 789ms/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6927 - accuracy: 0.5284 - val_loss: 0.6913 - val_accuracy: 0.5136 - 761ms/epoch - 30ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6903 - accuracy: 0.5259 - val_loss: 0.6914 - val_accuracy: 0.5229 - 824ms/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6904 - accuracy: 0.5132 - val_loss: 0.6924 - val_accuracy: 0.5200 - 783ms/epoch - 31ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6910 - accuracy: 0.5397 - val_loss: 0.6913 - val_accuracy: 0.5213 - 815ms/epoch - 33ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6901 - accuracy: 0.5397 - val_loss: 0.6913 - val_accuracy: 0.5247 - 828ms/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6892 - accuracy: 0.5334 - val_loss: 0.6908 - val_accuracy: 0.5323 - 819ms/epoch - 33ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6900 - accuracy: 0.5322 - val_loss: 0.6910 - val_accuracy: 0.5246 - 795ms/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.5158 - val_loss: 0.6911 - val_accuracy: 0.5295 - 783ms/epoch - 31ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6887 - accuracy: 0.5410 - val_loss: 0.6903 - val_accuracy: 0.5280 - 794ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6922 - accuracy: 0.5132 - val_loss: 0.6916 - val_accuracy: 0.5298 - 807ms/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6886 - accuracy: 0.5372 - val_loss: 0.6904 - val_accuracy: 0.5215 - 796ms/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6883 - accuracy: 0.5385 - val_loss: 0.6904 - val_accuracy: 0.5309 - 798ms/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6882 - accuracy: 0.5359 - val_loss: 0.6899 - val_accuracy: 0.5354 - 803ms/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6893 - accuracy: 0.5309 - val_loss: 0.6898 - val_accuracy: 0.5292 - 783ms/epoch - 31ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6890 - accuracy: 0.5233 - val_loss: 0.6899 - val_accuracy: 0.5293 - 780ms/epoch - 31ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6869 - accuracy: 0.5498 - val_loss: 0.6900 - val_accuracy: 0.5292 - 805ms/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6871 - accuracy: 0.5448 - val_loss: 0.6897 - val_accuracy: 0.5309 - 798ms/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6885 - accuracy: 0.5322 - val_loss: 0.6900 - val_accuracy: 0.5304 - 778ms/epoch - 31ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6870 - accuracy: 0.5536 - val_loss: 0.6893 - val_accuracy: 0.5385 - 826ms/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6871 - accuracy: 0.5485 - val_loss: 0.6888 - val_accuracy: 0.5325 - 786ms/epoch - 31ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6874 - accuracy: 0.5233 - val_loss: 0.6890 - val_accuracy: 0.5368 - 801ms/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6862 - accuracy: 0.5485 - val_loss: 0.6888 - val_accuracy: 0.5358 - 785ms/epoch - 31ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6861 - accuracy: 0.5574 - val_loss: 0.6885 - val_accuracy: 0.5382 - 802ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6864 - accuracy: 0.5523 - val_loss: 0.6887 - val_accuracy: 0.5403 - 811ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6858 - accuracy: 0.5586 - val_loss: 0.6882 - val_accuracy: 0.5434 - 817ms/epoch - 33ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6856 - accuracy: 0.5549 - val_loss: 0.6885 - val_accuracy: 0.5400 - 785ms/epoch - 31ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6858 - accuracy: 0.5334 - val_loss: 0.6883 - val_accuracy: 0.5387 - 792ms/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5410 - val_loss: 0.6882 - val_accuracy: 0.5398 - 786ms/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6859 - accuracy: 0.5460 - val_loss: 0.6881 - val_accuracy: 0.5416 - 794ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6858 - accuracy: 0.5485 - val_loss: 0.6873 - val_accuracy: 0.5464 - 806ms/epoch - 32ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6863 - accuracy: 0.5473 - val_loss: 0.6880 - val_accuracy: 0.5402 - 806ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6839 - accuracy: 0.5561 - val_loss: 0.6873 - val_accuracy: 0.5447 - 775ms/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6849 - accuracy: 0.5523 - val_loss: 0.6873 - val_accuracy: 0.5434 - 771ms/epoch - 31ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5296 - val_loss: 0.6871 - val_accuracy: 0.5438 - 780ms/epoch - 31ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6846 - accuracy: 0.5448 - val_loss: 0.6872 - val_accuracy: 0.5466 - 838ms/epoch - 34ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6846 - accuracy: 0.5511 - val_loss: 0.6867 - val_accuracy: 0.5432 - 811ms/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6826 - accuracy: 0.5586 - val_loss: 0.6865 - val_accuracy: 0.5483 - 816ms/epoch - 33ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6841 - accuracy: 0.5624 - val_loss: 0.6865 - val_accuracy: 0.5448 - 795ms/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6857 - accuracy: 0.5511 - val_loss: 0.6879 - val_accuracy: 0.5439 - 787ms/epoch - 31ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6853 - accuracy: 0.5586 - val_loss: 0.6878 - val_accuracy: 0.5416 - 792ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6830 - accuracy: 0.5649 - val_loss: 0.6861 - val_accuracy: 0.5466 - 791ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6833 - accuracy: 0.5624 - val_loss: 0.6859 - val_accuracy: 0.5511 - 824ms/epoch - 33ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6825 - accuracy: 0.5586 - val_loss: 0.6867 - val_accuracy: 0.5449 - 793ms/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6835 - accuracy: 0.5549 - val_loss: 0.6857 - val_accuracy: 0.5545 - 824ms/epoch - 33ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6827 - accuracy: 0.5435 - val_loss: 0.6864 - val_accuracy: 0.5476 - 797ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6829 - accuracy: 0.5662 - val_loss: 0.6869 - val_accuracy: 0.5486 - 796ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6815 - accuracy: 0.5586 - val_loss: 0.6851 - val_accuracy: 0.5496 - 802ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6821 - accuracy: 0.5624 - val_loss: 0.6855 - val_accuracy: 0.5500 - 783ms/epoch - 31ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6825 - accuracy: 0.5599 - val_loss: 0.6856 - val_accuracy: 0.5511 - 786ms/epoch - 31ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6827 - accuracy: 0.5536 - val_loss: 0.6853 - val_accuracy: 0.5492 - 796ms/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6810 - accuracy: 0.5574 - val_loss: 0.6851 - val_accuracy: 0.5543 - 792ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6812 - accuracy: 0.5448 - val_loss: 0.6853 - val_accuracy: 0.5518 - 810ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6831 - accuracy: 0.5662 - val_loss: 0.6850 - val_accuracy: 0.5545 - 794ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6813 - accuracy: 0.5612 - val_loss: 0.6855 - val_accuracy: 0.5482 - 775ms/epoch - 31ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6810 - accuracy: 0.5662 - val_loss: 0.6839 - val_accuracy: 0.5574 - 843ms/epoch - 34ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6799 - accuracy: 0.5675 - val_loss: 0.6844 - val_accuracy: 0.5541 - 813ms/epoch - 33ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6825 - accuracy: 0.5649 - val_loss: 0.6852 - val_accuracy: 0.5526 - 806ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6807 - accuracy: 0.5649 - val_loss: 0.6837 - val_accuracy: 0.5558 - 818ms/epoch - 33ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6798 - accuracy: 0.5700 - val_loss: 0.6843 - val_accuracy: 0.5588 - 835ms/epoch - 33ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6805 - accuracy: 0.5712 - val_loss: 0.6843 - val_accuracy: 0.5540 - 799ms/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6796 - accuracy: 0.5700 - val_loss: 0.6845 - val_accuracy: 0.5575 - 791ms/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6791 - accuracy: 0.5649 - val_loss: 0.6839 - val_accuracy: 0.5574 - 799ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6798 - accuracy: 0.5624 - val_loss: 0.6839 - val_accuracy: 0.5589 - 834ms/epoch - 33ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6803 - accuracy: 0.5687 - val_loss: 0.6838 - val_accuracy: 0.5573 - 783ms/epoch - 31ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6792 - accuracy: 0.5624 - val_loss: 0.6836 - val_accuracy: 0.5589 - 810ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6801 - accuracy: 0.5700 - val_loss: 0.6837 - val_accuracy: 0.5559 - 802ms/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6798 - accuracy: 0.5712 - val_loss: 0.6841 - val_accuracy: 0.5543 - 798ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6810 - accuracy: 0.5612 - val_loss: 0.6838 - val_accuracy: 0.5575 - 819ms/epoch - 33ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6794 - accuracy: 0.5612 - val_loss: 0.6839 - val_accuracy: 0.5557 - 807ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6776 - accuracy: 0.5675 - val_loss: 0.6841 - val_accuracy: 0.5577 - 800ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6798 - accuracy: 0.5763 - val_loss: 0.6835 - val_accuracy: 0.5591 - 828ms/epoch - 33ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6784 - accuracy: 0.5687 - val_loss: 0.6839 - val_accuracy: 0.5559 - 807ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6783 - accuracy: 0.5725 - val_loss: 0.6837 - val_accuracy: 0.5621 - 806ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6792 - accuracy: 0.5485 - val_loss: 0.6835 - val_accuracy: 0.5596 - 802ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6789 - accuracy: 0.5599 - val_loss: 0.6830 - val_accuracy: 0.5590 - 810ms/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6778 - accuracy: 0.5738 - val_loss: 0.6836 - val_accuracy: 0.5593 - 793ms/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6795 - accuracy: 0.5675 - val_loss: 0.6837 - val_accuracy: 0.5574 - 780ms/epoch - 31ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6778 - accuracy: 0.5612 - val_loss: 0.6829 - val_accuracy: 0.5621 - 784ms/epoch - 31ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6774 - accuracy: 0.5763 - val_loss: 0.6832 - val_accuracy: 0.5607 - 791ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6777 - accuracy: 0.5813 - val_loss: 0.6829 - val_accuracy: 0.5575 - 810ms/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6771 - accuracy: 0.5725 - val_loss: 0.6830 - val_accuracy: 0.5609 - 790ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6773 - accuracy: 0.5586 - val_loss: 0.6832 - val_accuracy: 0.5605 - 799ms/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6773 - accuracy: 0.5813 - val_loss: 0.6824 - val_accuracy: 0.5622 - 815ms/epoch - 33ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6792 - accuracy: 0.5460 - val_loss: 0.6827 - val_accuracy: 0.5588 - 792ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6777 - accuracy: 0.5750 - val_loss: 0.6827 - val_accuracy: 0.5609 - 796ms/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6770 - accuracy: 0.5700 - val_loss: 0.6825 - val_accuracy: 0.5590 - 799ms/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6786 - accuracy: 0.5612 - val_loss: 0.6841 - val_accuracy: 0.5605 - 790ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6783 - accuracy: 0.5763 - val_loss: 0.6826 - val_accuracy: 0.5607 - 782ms/epoch - 31ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6824 - accuracy: 0.5622\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.7010 - accuracy: 0.4899 - val_loss: 0.6950 - val_accuracy: 0.5092 - 2s/epoch - 76ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6945 - accuracy: 0.4912 - val_loss: 0.6922 - val_accuracy: 0.5110 - 812ms/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6918 - accuracy: 0.4962 - val_loss: 0.6919 - val_accuracy: 0.5092 - 787ms/epoch - 31ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6911 - val_accuracy: 0.5171 - 813ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5328 - val_loss: 0.6904 - val_accuracy: 0.5202 - 821ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5391 - val_loss: 0.6901 - val_accuracy: 0.5366 - 801ms/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6885 - accuracy: 0.5429 - val_loss: 0.6879 - val_accuracy: 0.5465 - 818ms/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6897 - accuracy: 0.5492 - val_loss: 0.6920 - val_accuracy: 0.5202 - 809ms/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6850 - accuracy: 0.5202 - val_loss: 0.6852 - val_accuracy: 0.5691 - 807ms/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6827 - accuracy: 0.5745 - val_loss: 0.6832 - val_accuracy: 0.5673 - 804ms/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6804 - accuracy: 0.5808 - val_loss: 0.6804 - val_accuracy: 0.5854 - 815ms/epoch - 33ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6794 - accuracy: 0.5657 - val_loss: 0.6796 - val_accuracy: 0.5828 - 790ms/epoch - 32ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6768 - accuracy: 0.5859 - val_loss: 0.6771 - val_accuracy: 0.5792 - 785ms/epoch - 31ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6743 - accuracy: 0.5833 - val_loss: 0.6745 - val_accuracy: 0.5982 - 818ms/epoch - 33ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6725 - accuracy: 0.5922 - val_loss: 0.6748 - val_accuracy: 0.5955 - 802ms/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6698 - accuracy: 0.6136 - val_loss: 0.6710 - val_accuracy: 0.6040 - 829ms/epoch - 33ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6682 - accuracy: 0.5985 - val_loss: 0.6684 - val_accuracy: 0.6117 - 817ms/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6644 - accuracy: 0.5884 - val_loss: 0.6664 - val_accuracy: 0.6103 - 807ms/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.6623 - accuracy: 0.6187 - val_loss: 0.6634 - val_accuracy: 0.6272 - 811ms/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6603 - accuracy: 0.6199 - val_loss: 0.6632 - val_accuracy: 0.6136 - 779ms/epoch - 31ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6595 - accuracy: 0.6225 - val_loss: 0.6587 - val_accuracy: 0.6332 - 808ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6609 - accuracy: 0.6162 - val_loss: 0.6626 - val_accuracy: 0.6001 - 775ms/epoch - 31ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6525 - accuracy: 0.6301 - val_loss: 0.6575 - val_accuracy: 0.6245 - 785ms/epoch - 31ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6532 - accuracy: 0.6275 - val_loss: 0.6552 - val_accuracy: 0.6338 - 830ms/epoch - 33ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6513 - accuracy: 0.6326 - val_loss: 0.6523 - val_accuracy: 0.6393 - 830ms/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6473 - accuracy: 0.6452 - val_loss: 0.6505 - val_accuracy: 0.6429 - 828ms/epoch - 33ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6440 - accuracy: 0.6503 - val_loss: 0.6483 - val_accuracy: 0.6428 - 797ms/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6475 - accuracy: 0.6288 - val_loss: 0.6470 - val_accuracy: 0.6442 - 830ms/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6441 - accuracy: 0.6326 - val_loss: 0.6470 - val_accuracy: 0.6377 - 770ms/epoch - 31ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6434 - accuracy: 0.6452 - val_loss: 0.6442 - val_accuracy: 0.6505 - 838ms/epoch - 34ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6392 - accuracy: 0.6578 - val_loss: 0.6425 - val_accuracy: 0.6526 - 824ms/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6365 - accuracy: 0.6452 - val_loss: 0.6418 - val_accuracy: 0.6508 - 792ms/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6380 - accuracy: 0.6439 - val_loss: 0.6401 - val_accuracy: 0.6541 - 793ms/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6354 - accuracy: 0.6566 - val_loss: 0.6381 - val_accuracy: 0.6508 - 803ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6346 - accuracy: 0.6528 - val_loss: 0.6393 - val_accuracy: 0.6557 - 825ms/epoch - 33ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.6325 - accuracy: 0.6578 - val_loss: 0.6359 - val_accuracy: 0.6509 - 792ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.6335 - accuracy: 0.6477 - val_loss: 0.6352 - val_accuracy: 0.6539 - 798ms/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.6333 - accuracy: 0.6604 - val_loss: 0.6410 - val_accuracy: 0.6398 - 798ms/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.6320 - accuracy: 0.6528 - val_loss: 0.6381 - val_accuracy: 0.6558 - 825ms/epoch - 33ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.6327 - accuracy: 0.6591 - val_loss: 0.6350 - val_accuracy: 0.6604 - 811ms/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.6307 - accuracy: 0.6490 - val_loss: 0.6327 - val_accuracy: 0.6586 - 804ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.6297 - accuracy: 0.6528 - val_loss: 0.6316 - val_accuracy: 0.6635 - 822ms/epoch - 33ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.6266 - accuracy: 0.6553 - val_loss: 0.6362 - val_accuracy: 0.6543 - 812ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.6262 - accuracy: 0.6616 - val_loss: 0.6317 - val_accuracy: 0.6508 - 783ms/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.6245 - accuracy: 0.6654 - val_loss: 0.6299 - val_accuracy: 0.6665 - 808ms/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.6261 - accuracy: 0.6641 - val_loss: 0.6299 - val_accuracy: 0.6665 - 801ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.6243 - accuracy: 0.6604 - val_loss: 0.6292 - val_accuracy: 0.6664 - 813ms/epoch - 33ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.6273 - accuracy: 0.6591 - val_loss: 0.6293 - val_accuracy: 0.6603 - 790ms/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.6227 - accuracy: 0.6616 - val_loss: 0.6292 - val_accuracy: 0.6572 - 801ms/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.6227 - accuracy: 0.6616 - val_loss: 0.6272 - val_accuracy: 0.6633 - 797ms/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.6233 - accuracy: 0.6629 - val_loss: 0.6290 - val_accuracy: 0.6634 - 807ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.6253 - accuracy: 0.6604 - val_loss: 0.6356 - val_accuracy: 0.6511 - 793ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.6241 - accuracy: 0.6591 - val_loss: 0.6280 - val_accuracy: 0.6603 - 792ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.6241 - accuracy: 0.6616 - val_loss: 0.6268 - val_accuracy: 0.6651 - 786ms/epoch - 31ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.6285 - val_accuracy: 0.6648 - 782ms/epoch - 31ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.6224 - accuracy: 0.6641 - val_loss: 0.6276 - val_accuracy: 0.6588 - 793ms/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.6187 - accuracy: 0.6755 - val_loss: 0.6285 - val_accuracy: 0.6510 - 819ms/epoch - 33ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.6186 - accuracy: 0.6705 - val_loss: 0.6294 - val_accuracy: 0.6604 - 793ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.6175 - accuracy: 0.6578 - val_loss: 0.6246 - val_accuracy: 0.6618 - 796ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.6175 - accuracy: 0.6566 - val_loss: 0.6246 - val_accuracy: 0.6634 - 802ms/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.6162 - accuracy: 0.6692 - val_loss: 0.6233 - val_accuracy: 0.6651 - 800ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.6164 - accuracy: 0.6742 - val_loss: 0.6236 - val_accuracy: 0.6648 - 810ms/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.6193 - accuracy: 0.6604 - val_loss: 0.6245 - val_accuracy: 0.6650 - 798ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.6153 - accuracy: 0.6679 - val_loss: 0.6229 - val_accuracy: 0.6664 - 784ms/epoch - 31ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.6159 - accuracy: 0.6679 - val_loss: 0.6226 - val_accuracy: 0.6665 - 818ms/epoch - 33ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.6162 - accuracy: 0.6654 - val_loss: 0.6245 - val_accuracy: 0.6557 - 807ms/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.6144 - accuracy: 0.6717 - val_loss: 0.6220 - val_accuracy: 0.6664 - 817ms/epoch - 33ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.6123 - accuracy: 0.6730 - val_loss: 0.6222 - val_accuracy: 0.6633 - 805ms/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.6170 - accuracy: 0.6616 - val_loss: 0.6216 - val_accuracy: 0.6648 - 802ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.6152 - accuracy: 0.6604 - val_loss: 0.6221 - val_accuracy: 0.6665 - 800ms/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.6137 - accuracy: 0.6755 - val_loss: 0.6211 - val_accuracy: 0.6649 - 801ms/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.6138 - accuracy: 0.6591 - val_loss: 0.6285 - val_accuracy: 0.6526 - 796ms/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.6164 - accuracy: 0.6667 - val_loss: 0.6222 - val_accuracy: 0.6618 - 770ms/epoch - 31ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.6167 - accuracy: 0.6629 - val_loss: 0.6217 - val_accuracy: 0.6634 - 797ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.6144 - accuracy: 0.6793 - val_loss: 0.6206 - val_accuracy: 0.6649 - 798ms/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.6126 - accuracy: 0.6730 - val_loss: 0.6205 - val_accuracy: 0.6649 - 829ms/epoch - 33ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.6103 - accuracy: 0.6730 - val_loss: 0.6194 - val_accuracy: 0.6664 - 808ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.6099 - accuracy: 0.6730 - val_loss: 0.6197 - val_accuracy: 0.6650 - 802ms/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.6115 - accuracy: 0.6629 - val_loss: 0.6272 - val_accuracy: 0.6588 - 804ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.6125 - accuracy: 0.6604 - val_loss: 0.6208 - val_accuracy: 0.6650 - 791ms/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.6111 - accuracy: 0.6629 - val_loss: 0.6190 - val_accuracy: 0.6650 - 796ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.6091 - accuracy: 0.6705 - val_loss: 0.6182 - val_accuracy: 0.6650 - 796ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.6154 - accuracy: 0.6717 - val_loss: 0.6222 - val_accuracy: 0.6541 - 795ms/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.6133 - accuracy: 0.6641 - val_loss: 0.6192 - val_accuracy: 0.6601 - 798ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.6106 - accuracy: 0.6679 - val_loss: 0.6178 - val_accuracy: 0.6682 - 805ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.6086 - accuracy: 0.6667 - val_loss: 0.6204 - val_accuracy: 0.6649 - 811ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.6069 - accuracy: 0.6742 - val_loss: 0.6170 - val_accuracy: 0.6650 - 813ms/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.6072 - accuracy: 0.6768 - val_loss: 0.6197 - val_accuracy: 0.6649 - 817ms/epoch - 33ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.6093 - accuracy: 0.6717 - val_loss: 0.6172 - val_accuracy: 0.6651 - 803ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.6095 - accuracy: 0.6629 - val_loss: 0.6229 - val_accuracy: 0.6557 - 798ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.6106 - accuracy: 0.6667 - val_loss: 0.6165 - val_accuracy: 0.6666 - 798ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.6067 - accuracy: 0.6692 - val_loss: 0.6192 - val_accuracy: 0.6634 - 758ms/epoch - 30ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.6080 - accuracy: 0.6755 - val_loss: 0.6166 - val_accuracy: 0.6664 - 794ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.6068 - accuracy: 0.6768 - val_loss: 0.6183 - val_accuracy: 0.6635 - 767ms/epoch - 31ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.6078 - accuracy: 0.6717 - val_loss: 0.6166 - val_accuracy: 0.6649 - 782ms/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.6042 - accuracy: 0.6730 - val_loss: 0.6156 - val_accuracy: 0.6648 - 801ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.6073 - accuracy: 0.6768 - val_loss: 0.6158 - val_accuracy: 0.6682 - 812ms/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.6073 - accuracy: 0.6742 - val_loss: 0.6235 - val_accuracy: 0.6587 - 816ms/epoch - 33ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.6094 - accuracy: 0.6755 - val_loss: 0.6151 - val_accuracy: 0.6648 - 816ms/epoch - 33ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.6063 - accuracy: 0.6730 - val_loss: 0.6175 - val_accuracy: 0.6634 - 785ms/epoch - 31ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.6178 - accuracy: 0.6682\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.7001 - accuracy: 0.4905 - val_loss: 0.6998 - val_accuracy: 0.5028 - 2s/epoch - 68ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6927 - accuracy: 0.5006 - val_loss: 0.6942 - val_accuracy: 0.5140 - 806ms/epoch - 32ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6905 - accuracy: 0.5386 - val_loss: 0.6975 - val_accuracy: 0.5088 - 797ms/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6945 - accuracy: 0.5044 - val_loss: 0.6904 - val_accuracy: 0.5318 - 821ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6895 - accuracy: 0.5335 - val_loss: 0.6894 - val_accuracy: 0.5332 - 824ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6885 - accuracy: 0.5386 - val_loss: 0.6884 - val_accuracy: 0.5383 - 818ms/epoch - 33ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6891 - accuracy: 0.5183 - val_loss: 0.6889 - val_accuracy: 0.5387 - 820ms/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6853 - accuracy: 0.5348 - val_loss: 0.6881 - val_accuracy: 0.5449 - 811ms/epoch - 32ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6843 - accuracy: 0.5651 - val_loss: 0.6862 - val_accuracy: 0.5525 - 823ms/epoch - 33ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6836 - accuracy: 0.5727 - val_loss: 0.6825 - val_accuracy: 0.5718 - 800ms/epoch - 32ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6794 - accuracy: 0.5777 - val_loss: 0.6809 - val_accuracy: 0.5692 - 773ms/epoch - 31ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6777 - accuracy: 0.5853 - val_loss: 0.6784 - val_accuracy: 0.5792 - 820ms/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6749 - accuracy: 0.5954 - val_loss: 0.6770 - val_accuracy: 0.5718 - 777ms/epoch - 31ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6729 - accuracy: 0.5992 - val_loss: 0.6730 - val_accuracy: 0.6092 - 810ms/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.6699 - accuracy: 0.5967 - val_loss: 0.6712 - val_accuracy: 0.6027 - 800ms/epoch - 32ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.6661 - accuracy: 0.6144 - val_loss: 0.6683 - val_accuracy: 0.6180 - 805ms/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.6673 - accuracy: 0.5917 - val_loss: 0.6662 - val_accuracy: 0.6163 - 795ms/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.6609 - accuracy: 0.6169 - val_loss: 0.6625 - val_accuracy: 0.6240 - 808ms/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 3s - loss: 0.6579 - accuracy: 0.6271 - val_loss: 0.6594 - val_accuracy: 0.6316 - 3s/epoch - 107ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.6547 - accuracy: 0.6359 - val_loss: 0.6582 - val_accuracy: 0.6336 - 810ms/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.6514 - accuracy: 0.6561 - val_loss: 0.6529 - val_accuracy: 0.6417 - 834ms/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.6491 - accuracy: 0.6422 - val_loss: 0.6543 - val_accuracy: 0.6118 - 802ms/epoch - 32ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.6447 - accuracy: 0.6612 - val_loss: 0.6467 - val_accuracy: 0.6504 - 820ms/epoch - 33ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.6405 - accuracy: 0.6650 - val_loss: 0.6427 - val_accuracy: 0.6553 - 808ms/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.6390 - accuracy: 0.6523 - val_loss: 0.6394 - val_accuracy: 0.6599 - 819ms/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.6341 - accuracy: 0.6713 - val_loss: 0.6361 - val_accuracy: 0.6632 - 826ms/epoch - 33ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.6300 - accuracy: 0.6637 - val_loss: 0.6317 - val_accuracy: 0.6660 - 820ms/epoch - 33ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.6310 - accuracy: 0.6612 - val_loss: 0.6290 - val_accuracy: 0.6674 - 805ms/epoch - 32ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.6236 - accuracy: 0.6802 - val_loss: 0.6257 - val_accuracy: 0.6641 - 790ms/epoch - 32ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.6184 - accuracy: 0.6953 - val_loss: 0.6227 - val_accuracy: 0.6752 - 821ms/epoch - 33ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.6148 - accuracy: 0.6713 - val_loss: 0.6175 - val_accuracy: 0.6814 - 821ms/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.6112 - accuracy: 0.6865 - val_loss: 0.6145 - val_accuracy: 0.6785 - 784ms/epoch - 31ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.6102 - accuracy: 0.6713 - val_loss: 0.6239 - val_accuracy: 0.6464 - 801ms/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.6090 - accuracy: 0.6738 - val_loss: 0.6079 - val_accuracy: 0.6777 - 785ms/epoch - 31ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.6027 - accuracy: 0.6827 - val_loss: 0.6049 - val_accuracy: 0.6765 - 803ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.5967 - accuracy: 0.6789 - val_loss: 0.6035 - val_accuracy: 0.6861 - 811ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.5954 - accuracy: 0.6877 - val_loss: 0.5983 - val_accuracy: 0.6796 - 790ms/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.5915 - accuracy: 0.6966 - val_loss: 0.5946 - val_accuracy: 0.6875 - 822ms/epoch - 33ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.5889 - accuracy: 0.6877 - val_loss: 0.5990 - val_accuracy: 0.6708 - 796ms/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.5853 - accuracy: 0.6941 - val_loss: 0.5899 - val_accuracy: 0.6955 - 807ms/epoch - 32ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.5810 - accuracy: 0.6979 - val_loss: 0.5840 - val_accuracy: 0.6953 - 802ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.5775 - accuracy: 0.7054 - val_loss: 0.5803 - val_accuracy: 0.6984 - 827ms/epoch - 33ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.5730 - accuracy: 0.7054 - val_loss: 0.5800 - val_accuracy: 0.6968 - 800ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.5751 - accuracy: 0.6979 - val_loss: 0.5849 - val_accuracy: 0.6830 - 801ms/epoch - 32ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.5769 - accuracy: 0.6915 - val_loss: 0.5807 - val_accuracy: 0.6889 - 802ms/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.5758 - accuracy: 0.6865 - val_loss: 0.5699 - val_accuracy: 0.6952 - 802ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.5643 - accuracy: 0.6941 - val_loss: 0.5657 - val_accuracy: 0.7015 - 829ms/epoch - 33ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.5649 - accuracy: 0.7206 - val_loss: 0.5692 - val_accuracy: 0.6861 - 779ms/epoch - 31ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.5550 - accuracy: 0.7092 - val_loss: 0.5618 - val_accuracy: 0.6995 - 784ms/epoch - 31ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.5514 - accuracy: 0.7295 - val_loss: 0.5620 - val_accuracy: 0.6984 - 781ms/epoch - 31ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.5518 - accuracy: 0.7042 - val_loss: 0.5561 - val_accuracy: 0.7033 - 815ms/epoch - 33ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.5495 - accuracy: 0.7168 - val_loss: 0.5572 - val_accuracy: 0.7012 - 800ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.5455 - accuracy: 0.7168 - val_loss: 0.5516 - val_accuracy: 0.7045 - 809ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.5439 - accuracy: 0.7054 - val_loss: 0.5477 - val_accuracy: 0.7045 - 794ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.5407 - accuracy: 0.7219 - val_loss: 0.5458 - val_accuracy: 0.7049 - 817ms/epoch - 33ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.5432 - accuracy: 0.6979 - val_loss: 0.5442 - val_accuracy: 0.7061 - 829ms/epoch - 33ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.5381 - accuracy: 0.7168 - val_loss: 0.5407 - val_accuracy: 0.7047 - 791ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.5357 - accuracy: 0.7042 - val_loss: 0.5419 - val_accuracy: 0.7011 - 783ms/epoch - 31ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.5299 - accuracy: 0.7155 - val_loss: 0.5364 - val_accuracy: 0.7059 - 787ms/epoch - 31ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.5305 - accuracy: 0.7155 - val_loss: 0.5344 - val_accuracy: 0.7042 - 798ms/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.5288 - accuracy: 0.7143 - val_loss: 0.5316 - val_accuracy: 0.7042 - 812ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.5270 - accuracy: 0.7244 - val_loss: 0.5321 - val_accuracy: 0.7064 - 832ms/epoch - 33ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.5313 - accuracy: 0.7092 - val_loss: 0.5310 - val_accuracy: 0.7088 - 826ms/epoch - 33ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.5223 - accuracy: 0.7143 - val_loss: 0.5304 - val_accuracy: 0.7076 - 809ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.5220 - accuracy: 0.7168 - val_loss: 0.5303 - val_accuracy: 0.7078 - 803ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.5217 - accuracy: 0.7067 - val_loss: 0.5347 - val_accuracy: 0.7015 - 808ms/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.5197 - accuracy: 0.7130 - val_loss: 0.5236 - val_accuracy: 0.7077 - 799ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.5205 - accuracy: 0.7231 - val_loss: 0.5209 - val_accuracy: 0.7093 - 808ms/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.5190 - accuracy: 0.7130 - val_loss: 0.5226 - val_accuracy: 0.7092 - 787ms/epoch - 31ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.5158 - accuracy: 0.7206 - val_loss: 0.5246 - val_accuracy: 0.7064 - 795ms/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.5155 - accuracy: 0.7206 - val_loss: 0.5183 - val_accuracy: 0.7095 - 794ms/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.5096 - accuracy: 0.7168 - val_loss: 0.5140 - val_accuracy: 0.7165 - 832ms/epoch - 33ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.5066 - accuracy: 0.7396 - val_loss: 0.5176 - val_accuracy: 0.7091 - 796ms/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.5119 - accuracy: 0.7181 - val_loss: 0.5155 - val_accuracy: 0.7125 - 769ms/epoch - 31ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.5033 - accuracy: 0.7320 - val_loss: 0.5090 - val_accuracy: 0.7154 - 807ms/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.5042 - accuracy: 0.7155 - val_loss: 0.5081 - val_accuracy: 0.7123 - 790ms/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.5029 - accuracy: 0.7244 - val_loss: 0.5100 - val_accuracy: 0.7152 - 800ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.5045 - accuracy: 0.7155 - val_loss: 0.5069 - val_accuracy: 0.7123 - 797ms/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.5046 - accuracy: 0.7231 - val_loss: 0.5068 - val_accuracy: 0.7153 - 798ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.4982 - accuracy: 0.7269 - val_loss: 0.5063 - val_accuracy: 0.7157 - 801ms/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.4997 - accuracy: 0.7421 - val_loss: 0.5130 - val_accuracy: 0.7076 - 803ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.4978 - accuracy: 0.7193 - val_loss: 0.5033 - val_accuracy: 0.7123 - 785ms/epoch - 31ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.4973 - accuracy: 0.7282 - val_loss: 0.5337 - val_accuracy: 0.6945 - 796ms/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.5037 - accuracy: 0.7269 - val_loss: 0.4998 - val_accuracy: 0.7149 - 796ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.4895 - accuracy: 0.7320 - val_loss: 0.4958 - val_accuracy: 0.7171 - 823ms/epoch - 33ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.4897 - accuracy: 0.7269 - val_loss: 0.4971 - val_accuracy: 0.7139 - 803ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.4911 - accuracy: 0.7257 - val_loss: 0.5030 - val_accuracy: 0.7082 - 815ms/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.4873 - accuracy: 0.7370 - val_loss: 0.4988 - val_accuracy: 0.7166 - 814ms/epoch - 33ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.4881 - accuracy: 0.7295 - val_loss: 0.5027 - val_accuracy: 0.7079 - 807ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.4935 - accuracy: 0.7244 - val_loss: 0.4960 - val_accuracy: 0.7142 - 807ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.4853 - accuracy: 0.7269 - val_loss: 0.4906 - val_accuracy: 0.7183 - 829ms/epoch - 33ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.4909 - accuracy: 0.7219 - val_loss: 0.4971 - val_accuracy: 0.7154 - 819ms/epoch - 33ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.4864 - accuracy: 0.7332 - val_loss: 0.4954 - val_accuracy: 0.7152 - 804ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.4800 - accuracy: 0.7282 - val_loss: 0.4873 - val_accuracy: 0.7182 - 787ms/epoch - 31ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.4778 - accuracy: 0.7459 - val_loss: 0.4968 - val_accuracy: 0.7097 - 783ms/epoch - 31ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.4905 - accuracy: 0.7320 - val_loss: 0.4909 - val_accuracy: 0.7143 - 788ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.4863 - accuracy: 0.7282 - val_loss: 0.4907 - val_accuracy: 0.7127 - 801ms/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.4780 - accuracy: 0.7446 - val_loss: 0.4873 - val_accuracy: 0.7196 - 814ms/epoch - 33ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.4793 - accuracy: 0.7269 - val_loss: 0.4837 - val_accuracy: 0.7186 - 792ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.4742 - accuracy: 0.7446 - val_loss: 0.4827 - val_accuracy: 0.7186 - 794ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 2ms/step - loss: 0.4873 - accuracy: 0.7196\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.6997 - accuracy: 0.4747 - val_loss: 0.6923 - val_accuracy: 0.5247 - 2s/epoch - 71ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6923 - accuracy: 0.5051 - val_loss: 0.6897 - val_accuracy: 0.5436 - 841ms/epoch - 34ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6894 - accuracy: 0.5443 - val_loss: 0.6914 - val_accuracy: 0.5230 - 787ms/epoch - 31ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5519 - val_loss: 0.6853 - val_accuracy: 0.5665 - 820ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6830 - accuracy: 0.5810 - val_loss: 0.6816 - val_accuracy: 0.5786 - 828ms/epoch - 33ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6810 - accuracy: 0.5886 - val_loss: 0.6779 - val_accuracy: 0.5936 - 807ms/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6751 - accuracy: 0.5937 - val_loss: 0.6737 - val_accuracy: 0.6002 - 830ms/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6697 - accuracy: 0.6114 - val_loss: 0.6686 - val_accuracy: 0.6211 - 818ms/epoch - 33ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6657 - accuracy: 0.6367 - val_loss: 0.6619 - val_accuracy: 0.6659 - 815ms/epoch - 33ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6554 - accuracy: 0.7051 - val_loss: 0.6509 - val_accuracy: 0.7385 - 824ms/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6453 - accuracy: 0.7494 - val_loss: 0.6411 - val_accuracy: 0.7676 - 833ms/epoch - 33ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6342 - accuracy: 0.7797 - val_loss: 0.6300 - val_accuracy: 0.7882 - 813ms/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6241 - accuracy: 0.7797 - val_loss: 0.6210 - val_accuracy: 0.7951 - 814ms/epoch - 33ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.6108 - accuracy: 0.8127 - val_loss: 0.6076 - val_accuracy: 0.7904 - 796ms/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.5988 - accuracy: 0.8506 - val_loss: 0.5914 - val_accuracy: 0.8757 - 815ms/epoch - 33ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.5822 - accuracy: 0.8848 - val_loss: 0.5771 - val_accuracy: 0.8908 - 819ms/epoch - 33ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.5710 - accuracy: 0.8899 - val_loss: 0.5657 - val_accuracy: 0.8909 - 815ms/epoch - 33ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.5582 - accuracy: 0.8975 - val_loss: 0.5476 - val_accuracy: 0.9262 - 838ms/epoch - 34ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.5430 - accuracy: 0.9063 - val_loss: 0.5423 - val_accuracy: 0.8386 - 797ms/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.5291 - accuracy: 0.8848 - val_loss: 0.5253 - val_accuracy: 0.8940 - 796ms/epoch - 32ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.5087 - accuracy: 0.9405 - val_loss: 0.4977 - val_accuracy: 0.9630 - 815ms/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.4870 - accuracy: 0.9544 - val_loss: 0.4800 - val_accuracy: 0.9663 - 828ms/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.4701 - accuracy: 0.9633 - val_loss: 0.4609 - val_accuracy: 0.9709 - 836ms/epoch - 33ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.4505 - accuracy: 0.9709 - val_loss: 0.4449 - val_accuracy: 0.9662 - 801ms/epoch - 32ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.4337 - accuracy: 0.9785 - val_loss: 0.4351 - val_accuracy: 0.9493 - 807ms/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.4193 - accuracy: 0.9658 - val_loss: 0.4102 - val_accuracy: 0.9893 - 822ms/epoch - 33ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.3994 - accuracy: 0.9810 - val_loss: 0.3916 - val_accuracy: 0.9909 - 825ms/epoch - 33ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.3819 - accuracy: 0.9797 - val_loss: 0.3773 - val_accuracy: 0.9876 - 824ms/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.3683 - accuracy: 0.9848 - val_loss: 0.3581 - val_accuracy: 0.9923 - 823ms/epoch - 33ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.3469 - accuracy: 0.9911 - val_loss: 0.3419 - val_accuracy: 0.9937 - 812ms/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.3344 - accuracy: 0.9924 - val_loss: 0.3273 - val_accuracy: 0.9953 - 815ms/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.3171 - accuracy: 0.9937 - val_loss: 0.3102 - val_accuracy: 0.9985 - 820ms/epoch - 33ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.2999 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 1.0000 - 849ms/epoch - 34ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.2860 - accuracy: 0.9962 - val_loss: 0.2823 - val_accuracy: 0.9985 - 809ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.2728 - accuracy: 0.9987 - val_loss: 0.2690 - val_accuracy: 1.0000 - 808ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.2626 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 1.0000 - 817ms/epoch - 33ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.2451 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 1.0000 - 820ms/epoch - 33ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 1.0000 - 785ms/epoch - 31ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.2134 - accuracy: 0.9987 - val_loss: 0.2100 - val_accuracy: 1.0000 - 816ms/epoch - 33ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.2022 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 1.0000 - 800ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.1923 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 1.0000 - 826ms/epoch - 33ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.1835 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 1.0000 - 785ms/epoch - 31ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.1778 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000 - 780ms/epoch - 31ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.1661 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 1.0000 - 793ms/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.1560 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 1.0000 - 807ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.1501 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 1.0000 - 755ms/epoch - 30ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 2s - loss: 0.1410 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 1.0000 - 2s/epoch - 99ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.1349 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 1.0000 - 805ms/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 1.0000 - 790ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.1159 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 1.0000 - 794ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.1126 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 1.0000 - 810ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 1.0000 - 810ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.1035 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 1.0000 - 791ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 1.0000 - 808ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 1.0000 - 788ms/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000 - 771ms/epoch - 31ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 1.0000 - 814ms/epoch - 33ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000 - 794ms/epoch - 32ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000 - 804ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 1.0000 - 810ms/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000 - 793ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 1.0000 - 817ms/epoch - 33ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000 - 828ms/epoch - 33ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000 - 819ms/epoch - 33ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000 - 800ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000 - 819ms/epoch - 33ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000 - 788ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000 - 804ms/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000 - 791ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000 - 808ms/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000 - 794ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 1.0000 - 809ms/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000 - 805ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000 - 804ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000 - 806ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000 - 820ms/epoch - 33ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000 - 808ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000 - 793ms/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000 - 788ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000 - 800ms/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000 - 816ms/epoch - 33ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000 - 807ms/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000 - 799ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.2951 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.7032 - accuracy: 0.4575 - val_loss: 0.6914 - val_accuracy: 0.5053 - 2s/epoch - 72ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6919 - accuracy: 0.5234 - val_loss: 0.6902 - val_accuracy: 0.5371 - 831ms/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6924 - accuracy: 0.5082 - val_loss: 0.6882 - val_accuracy: 0.5497 - 800ms/epoch - 32ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6888 - accuracy: 0.5311 - val_loss: 0.6850 - val_accuracy: 0.5568 - 826ms/epoch - 33ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6820 - accuracy: 0.5703 - val_loss: 0.6793 - val_accuracy: 0.5740 - 784ms/epoch - 31ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6771 - accuracy: 0.5830 - val_loss: 0.6731 - val_accuracy: 0.6074 - 801ms/epoch - 32ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6696 - accuracy: 0.6248 - val_loss: 0.6684 - val_accuracy: 0.5942 - 807ms/epoch - 32ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6615 - accuracy: 0.6527 - val_loss: 0.6560 - val_accuracy: 0.6725 - 819ms/epoch - 33ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6489 - accuracy: 0.7009 - val_loss: 0.6430 - val_accuracy: 0.7308 - 802ms/epoch - 32ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6342 - accuracy: 0.7503 - val_loss: 0.6279 - val_accuracy: 0.7600 - 827ms/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6193 - accuracy: 0.7719 - val_loss: 0.6156 - val_accuracy: 0.7460 - 807ms/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6016 - accuracy: 0.8150 - val_loss: 0.5937 - val_accuracy: 0.8199 - 816ms/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.5814 - accuracy: 0.8517 - val_loss: 0.5716 - val_accuracy: 0.8647 - 822ms/epoch - 33ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.5622 - accuracy: 0.8593 - val_loss: 0.5539 - val_accuracy: 0.8509 - 793ms/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.5407 - accuracy: 0.8707 - val_loss: 0.5307 - val_accuracy: 0.8876 - 820ms/epoch - 33ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.5250 - accuracy: 0.8859 - val_loss: 0.5115 - val_accuracy: 0.8849 - 806ms/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.4978 - accuracy: 0.9049 - val_loss: 0.4872 - val_accuracy: 0.9138 - 806ms/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.4767 - accuracy: 0.9037 - val_loss: 0.4652 - val_accuracy: 0.9214 - 808ms/epoch - 32ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.4519 - accuracy: 0.9328 - val_loss: 0.4410 - val_accuracy: 0.9339 - 810ms/epoch - 32ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.4282 - accuracy: 0.9430 - val_loss: 0.4172 - val_accuracy: 0.9587 - 833ms/epoch - 33ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.4062 - accuracy: 0.9544 - val_loss: 0.3953 - val_accuracy: 0.9633 - 820ms/epoch - 33ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.3830 - accuracy: 0.9683 - val_loss: 0.3742 - val_accuracy: 0.9710 - 820ms/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.3620 - accuracy: 0.9759 - val_loss: 0.3527 - val_accuracy: 0.9710 - 802ms/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.3438 - accuracy: 0.9759 - val_loss: 0.3324 - val_accuracy: 0.9786 - 826ms/epoch - 33ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.3215 - accuracy: 0.9835 - val_loss: 0.3137 - val_accuracy: 0.9848 - 804ms/epoch - 32ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.3028 - accuracy: 0.9886 - val_loss: 0.2952 - val_accuracy: 0.9847 - 802ms/epoch - 32ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.2851 - accuracy: 0.9911 - val_loss: 0.2768 - val_accuracy: 0.9893 - 815ms/epoch - 33ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.2658 - accuracy: 0.9911 - val_loss: 0.2620 - val_accuracy: 0.9909 - 819ms/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.2482 - accuracy: 0.9949 - val_loss: 0.2419 - val_accuracy: 1.0000 - 814ms/epoch - 33ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.2344 - accuracy: 0.9975 - val_loss: 0.2281 - val_accuracy: 1.0000 - 806ms/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 1.0000 - 806ms/epoch - 32ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.2055 - accuracy: 0.9987 - val_loss: 0.1994 - val_accuracy: 1.0000 - 807ms/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.1915 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 1.0000 - 804ms/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.1801 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 1.0000 - 783ms/epoch - 31ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.1655 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.1549 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 1.0000 - 827ms/epoch - 33ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.1382 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 3s - loss: 0.1301 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 1.0000 - 3s/epoch - 111ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 1.0000 - 768ms/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 1.0000 - 774ms/epoch - 31ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 1.0000 - 786ms/epoch - 31ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 1.0000 - 799ms/epoch - 32ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 1.0000 - 799ms/epoch - 32ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000 - 790ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 1.0000 - 794ms/epoch - 32ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000 - 800ms/epoch - 32ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000 - 820ms/epoch - 33ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000 - 820ms/epoch - 33ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 1.0000 - 790ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000 - 788ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000 - 817ms/epoch - 33ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000 - 777ms/epoch - 31ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 1.0000 - 804ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000 - 815ms/epoch - 33ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000 - 799ms/epoch - 32ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 1s - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000 - 802ms/epoch - 32ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000 - 790ms/epoch - 32ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000 - 807ms/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000 - 795ms/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000 - 785ms/epoch - 31ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000 - 825ms/epoch - 33ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000 - 816ms/epoch - 33ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000 - 800ms/epoch - 32ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000 - 802ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000 - 818ms/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000 - 802ms/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000 - 805ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000 - 802ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000 - 805ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000 - 781ms/epoch - 31ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000 - 824ms/epoch - 33ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000 - 791ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "25/25 - 2s - loss: 0.7053 - accuracy: 0.4937 - val_loss: 0.6914 - val_accuracy: 0.5220 - 2s/epoch - 71ms/step\n",
      "Epoch 2/100\n",
      "25/25 - 1s - loss: 0.6934 - accuracy: 0.5190 - val_loss: 0.6894 - val_accuracy: 0.5455 - 827ms/epoch - 33ms/step\n",
      "Epoch 3/100\n",
      "25/25 - 1s - loss: 0.6882 - accuracy: 0.5647 - val_loss: 0.6867 - val_accuracy: 0.5539 - 814ms/epoch - 33ms/step\n",
      "Epoch 4/100\n",
      "25/25 - 1s - loss: 0.6872 - accuracy: 0.5343 - val_loss: 0.6857 - val_accuracy: 0.5449 - 803ms/epoch - 32ms/step\n",
      "Epoch 5/100\n",
      "25/25 - 1s - loss: 0.6855 - accuracy: 0.5266 - val_loss: 0.6874 - val_accuracy: 0.5211 - 802ms/epoch - 32ms/step\n",
      "Epoch 6/100\n",
      "25/25 - 1s - loss: 0.6798 - accuracy: 0.5863 - val_loss: 0.6749 - val_accuracy: 0.6248 - 823ms/epoch - 33ms/step\n",
      "Epoch 7/100\n",
      "25/25 - 1s - loss: 0.6714 - accuracy: 0.6485 - val_loss: 0.6683 - val_accuracy: 0.6522 - 818ms/epoch - 33ms/step\n",
      "Epoch 8/100\n",
      "25/25 - 1s - loss: 0.6662 - accuracy: 0.6409 - val_loss: 0.6635 - val_accuracy: 0.6599 - 841ms/epoch - 34ms/step\n",
      "Epoch 9/100\n",
      "25/25 - 1s - loss: 0.6570 - accuracy: 0.6764 - val_loss: 0.6516 - val_accuracy: 0.7239 - 827ms/epoch - 33ms/step\n",
      "Epoch 10/100\n",
      "25/25 - 1s - loss: 0.6446 - accuracy: 0.7386 - val_loss: 0.6395 - val_accuracy: 0.7801 - 834ms/epoch - 33ms/step\n",
      "Epoch 11/100\n",
      "25/25 - 1s - loss: 0.6364 - accuracy: 0.7437 - val_loss: 0.6314 - val_accuracy: 0.7211 - 811ms/epoch - 32ms/step\n",
      "Epoch 12/100\n",
      "25/25 - 1s - loss: 0.6205 - accuracy: 0.7551 - val_loss: 0.6134 - val_accuracy: 0.7953 - 825ms/epoch - 33ms/step\n",
      "Epoch 13/100\n",
      "25/25 - 1s - loss: 0.6067 - accuracy: 0.7982 - val_loss: 0.5980 - val_accuracy: 0.8335 - 839ms/epoch - 34ms/step\n",
      "Epoch 14/100\n",
      "25/25 - 1s - loss: 0.5916 - accuracy: 0.7678 - val_loss: 0.5946 - val_accuracy: 0.7258 - 810ms/epoch - 32ms/step\n",
      "Epoch 15/100\n",
      "25/25 - 1s - loss: 0.5787 - accuracy: 0.8096 - val_loss: 0.5667 - val_accuracy: 0.8536 - 824ms/epoch - 33ms/step\n",
      "Epoch 16/100\n",
      "25/25 - 1s - loss: 0.5505 - accuracy: 0.8782 - val_loss: 0.5467 - val_accuracy: 0.8601 - 799ms/epoch - 32ms/step\n",
      "Epoch 17/100\n",
      "25/25 - 1s - loss: 0.5318 - accuracy: 0.8896 - val_loss: 0.5238 - val_accuracy: 0.8953 - 801ms/epoch - 32ms/step\n",
      "Epoch 18/100\n",
      "25/25 - 1s - loss: 0.5102 - accuracy: 0.9150 - val_loss: 0.5014 - val_accuracy: 0.9186 - 839ms/epoch - 34ms/step\n",
      "Epoch 19/100\n",
      "25/25 - 1s - loss: 0.4908 - accuracy: 0.9277 - val_loss: 0.4792 - val_accuracy: 0.9308 - 825ms/epoch - 33ms/step\n",
      "Epoch 20/100\n",
      "25/25 - 1s - loss: 0.4686 - accuracy: 0.9340 - val_loss: 0.4568 - val_accuracy: 0.9490 - 813ms/epoch - 33ms/step\n",
      "Epoch 21/100\n",
      "25/25 - 1s - loss: 0.4454 - accuracy: 0.9607 - val_loss: 0.4413 - val_accuracy: 0.9309 - 800ms/epoch - 32ms/step\n",
      "Epoch 22/100\n",
      "25/25 - 1s - loss: 0.4257 - accuracy: 0.9556 - val_loss: 0.4130 - val_accuracy: 0.9799 - 833ms/epoch - 33ms/step\n",
      "Epoch 23/100\n",
      "25/25 - 1s - loss: 0.4024 - accuracy: 0.9708 - val_loss: 0.3934 - val_accuracy: 0.9724 - 797ms/epoch - 32ms/step\n",
      "Epoch 24/100\n",
      "25/25 - 1s - loss: 0.3822 - accuracy: 0.9784 - val_loss: 0.3754 - val_accuracy: 0.9784 - 713ms/epoch - 29ms/step\n",
      "Epoch 25/100\n",
      "25/25 - 1s - loss: 0.3636 - accuracy: 0.9746 - val_loss: 0.3521 - val_accuracy: 0.9939 - 830ms/epoch - 33ms/step\n",
      "Epoch 26/100\n",
      "25/25 - 1s - loss: 0.3455 - accuracy: 0.9835 - val_loss: 0.3355 - val_accuracy: 0.9954 - 779ms/epoch - 31ms/step\n",
      "Epoch 27/100\n",
      "25/25 - 1s - loss: 0.3244 - accuracy: 0.9911 - val_loss: 0.3170 - val_accuracy: 0.9954 - 795ms/epoch - 32ms/step\n",
      "Epoch 28/100\n",
      "25/25 - 1s - loss: 0.3074 - accuracy: 0.9937 - val_loss: 0.3007 - val_accuracy: 0.9954 - 824ms/epoch - 33ms/step\n",
      "Epoch 29/100\n",
      "25/25 - 1s - loss: 0.2897 - accuracy: 0.9924 - val_loss: 0.2807 - val_accuracy: 0.9985 - 822ms/epoch - 33ms/step\n",
      "Epoch 30/100\n",
      "25/25 - 1s - loss: 0.2741 - accuracy: 0.9937 - val_loss: 0.2676 - val_accuracy: 0.9970 - 808ms/epoch - 32ms/step\n",
      "Epoch 31/100\n",
      "25/25 - 1s - loss: 0.2576 - accuracy: 0.9962 - val_loss: 0.2514 - val_accuracy: 1.0000 - 837ms/epoch - 33ms/step\n",
      "Epoch 32/100\n",
      "25/25 - 1s - loss: 0.2426 - accuracy: 0.9962 - val_loss: 0.2365 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 33/100\n",
      "25/25 - 1s - loss: 0.2268 - accuracy: 0.9987 - val_loss: 0.2237 - val_accuracy: 1.0000 - 809ms/epoch - 32ms/step\n",
      "Epoch 34/100\n",
      "25/25 - 1s - loss: 0.2182 - accuracy: 0.9987 - val_loss: 0.2129 - val_accuracy: 1.0000 - 807ms/epoch - 32ms/step\n",
      "Epoch 35/100\n",
      "25/25 - 1s - loss: 0.2041 - accuracy: 0.9987 - val_loss: 0.1995 - val_accuracy: 0.9985 - 818ms/epoch - 33ms/step\n",
      "Epoch 36/100\n",
      "25/25 - 1s - loss: 0.1913 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 1.0000 - 810ms/epoch - 32ms/step\n",
      "Epoch 37/100\n",
      "25/25 - 1s - loss: 0.1822 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "Epoch 38/100\n",
      "25/25 - 1s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 39/100\n",
      "25/25 - 1s - loss: 0.1622 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 40/100\n",
      "25/25 - 1s - loss: 0.1528 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 1.0000 - 784ms/epoch - 31ms/step\n",
      "Epoch 41/100\n",
      "25/25 - 1s - loss: 0.1449 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 42/100\n",
      "25/25 - 1s - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 1.0000 - 777ms/epoch - 31ms/step\n",
      "Epoch 43/100\n",
      "25/25 - 1s - loss: 0.1295 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 1.0000 - 800ms/epoch - 32ms/step\n",
      "Epoch 44/100\n",
      "25/25 - 1s - loss: 0.1221 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 1.0000 - 814ms/epoch - 33ms/step\n",
      "Epoch 45/100\n",
      "25/25 - 1s - loss: 0.1236 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 1.0000 - 814ms/epoch - 33ms/step\n",
      "Epoch 46/100\n",
      "25/25 - 1s - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 1.0000 - 794ms/epoch - 32ms/step\n",
      "Epoch 47/100\n",
      "25/25 - 1s - loss: 0.1039 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 1.0000 - 783ms/epoch - 31ms/step\n",
      "Epoch 48/100\n",
      "25/25 - 1s - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000 - 815ms/epoch - 33ms/step\n",
      "Epoch 49/100\n",
      "25/25 - 1s - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 50/100\n",
      "25/25 - 1s - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "Epoch 51/100\n",
      "25/25 - 1s - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000 - 808ms/epoch - 32ms/step\n",
      "Epoch 52/100\n",
      "25/25 - 1s - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 1.0000 - 810ms/epoch - 32ms/step\n",
      "Epoch 53/100\n",
      "25/25 - 1s - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000 - 799ms/epoch - 32ms/step\n",
      "Epoch 54/100\n",
      "25/25 - 1s - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 1.0000 - 805ms/epoch - 32ms/step\n",
      "Epoch 55/100\n",
      "25/25 - 1s - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 56/100\n",
      "25/25 - 1s - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000 - 809ms/epoch - 32ms/step\n",
      "Epoch 57/100\n",
      "25/25 - 1s - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000 - 789ms/epoch - 32ms/step\n",
      "Epoch 58/100\n",
      "25/25 - 1s - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000 - 783ms/epoch - 31ms/step\n",
      "Epoch 59/100\n",
      "25/25 - 1s - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "Epoch 60/100\n",
      "25/25 - 1s - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 61/100\n",
      "25/25 - 1s - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 1.0000 - 795ms/epoch - 32ms/step\n",
      "Epoch 62/100\n",
      "25/25 - 1s - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000 - 802ms/epoch - 32ms/step\n",
      "Epoch 63/100\n",
      "25/25 - 1s - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 64/100\n",
      "25/25 - 1s - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000 - 820ms/epoch - 33ms/step\n",
      "Epoch 65/100\n",
      "25/25 - 1s - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 1.0000 - 818ms/epoch - 33ms/step\n",
      "Epoch 66/100\n",
      "25/25 - 1s - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000 - 781ms/epoch - 31ms/step\n",
      "Epoch 67/100\n",
      "25/25 - 1s - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000 - 813ms/epoch - 33ms/step\n",
      "Epoch 68/100\n",
      "25/25 - 1s - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000 - 742ms/epoch - 30ms/step\n",
      "Epoch 69/100\n",
      "25/25 - 2s - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000 - 2s/epoch - 94ms/step\n",
      "Epoch 70/100\n",
      "25/25 - 1s - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 1.0000 - 783ms/epoch - 31ms/step\n",
      "Epoch 71/100\n",
      "25/25 - 1s - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 1.0000 - 814ms/epoch - 33ms/step\n",
      "Epoch 72/100\n",
      "25/25 - 1s - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 73/100\n",
      "25/25 - 1s - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000 - 790ms/epoch - 32ms/step\n",
      "Epoch 74/100\n",
      "25/25 - 1s - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000 - 808ms/epoch - 32ms/step\n",
      "Epoch 75/100\n",
      "25/25 - 1s - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 76/100\n",
      "25/25 - 1s - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000 - 795ms/epoch - 32ms/step\n",
      "Epoch 77/100\n",
      "25/25 - 1s - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000 - 811ms/epoch - 32ms/step\n",
      "Epoch 78/100\n",
      "25/25 - 1s - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000 - 803ms/epoch - 32ms/step\n",
      "Epoch 79/100\n",
      "25/25 - 1s - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000 - 783ms/epoch - 31ms/step\n",
      "Epoch 80/100\n",
      "25/25 - 1s - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000 - 802ms/epoch - 32ms/step\n",
      "Epoch 81/100\n",
      "25/25 - 1s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000 - 805ms/epoch - 32ms/step\n",
      "Epoch 82/100\n",
      "25/25 - 1s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 83/100\n",
      "25/25 - 1s - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - 819ms/epoch - 33ms/step\n",
      "Epoch 84/100\n",
      "25/25 - 1s - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000 - 807ms/epoch - 32ms/step\n",
      "Epoch 85/100\n",
      "25/25 - 1s - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 86/100\n",
      "25/25 - 1s - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 87/100\n",
      "25/25 - 1s - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000 - 830ms/epoch - 33ms/step\n",
      "Epoch 88/100\n",
      "25/25 - 1s - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000 - 796ms/epoch - 32ms/step\n",
      "Epoch 89/100\n",
      "25/25 - 1s - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000 - 809ms/epoch - 32ms/step\n",
      "Epoch 90/100\n",
      "25/25 - 1s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000 - 791ms/epoch - 32ms/step\n",
      "Epoch 91/100\n",
      "25/25 - 1s - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000 - 801ms/epoch - 32ms/step\n",
      "Epoch 92/100\n",
      "25/25 - 1s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000 - 806ms/epoch - 32ms/step\n",
      "Epoch 93/100\n",
      "25/25 - 1s - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000 - 792ms/epoch - 32ms/step\n",
      "Epoch 94/100\n",
      "25/25 - 1s - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000 - 806ms/epoch - 32ms/step\n",
      "Epoch 95/100\n",
      "25/25 - 1s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000 - 798ms/epoch - 32ms/step\n",
      "Epoch 96/100\n",
      "25/25 - 1s - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000 - 809ms/epoch - 32ms/step\n",
      "Epoch 97/100\n",
      "25/25 - 1s - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000 - 767ms/epoch - 31ms/step\n",
      "Epoch 98/100\n",
      "25/25 - 1s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000 - 797ms/epoch - 32ms/step\n",
      "Epoch 99/100\n",
      "25/25 - 1s - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000 - 809ms/epoch - 32ms/step\n",
      "Epoch 100/100\n",
      "25/25 - 1s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000 - 812ms/epoch - 32ms/step\n",
      "288/288 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "tf.keras.utils.enable_interactive_logging()\n",
    "for ln in range(5, 13):\n",
    "    print(f\"{ln - 5}/8\", end=\"\\r\")\n",
    "    X, Y = create_data(\n",
    "        10000,\n",
    "        ln=ln,\n",
    "        initial_key1=np.array([1, 0, 1, 1, 1]),\n",
    "        initial_key2=np.array([1, 1, 1, 0, 1]),\n",
    "    )\n",
    "    X_train, Y_train = X[: 800 - ln], Y[: 800 - ln]\n",
    "    X_test, Y_test = X[800 - ln :], Y[800 - ln :]\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "            # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "            # tf.keras.layers.LSTM(5),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # model.summary()\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[callback],\n",
    "        verbose=2\n",
    "    )\n",
    "    model = tf.keras.models.load_model(\"model.h5\")\n",
    "    l, ac = model.evaluate(X_test, Y_test)\n",
    "    lengths.append(ln)\n",
    "    accuracies.append(ac)\n",
    "    losses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lengths, accuracies)\n",
    "plt.plot(lengths, losses)\n",
    "plt.legend([\"Accuracy\", \"Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: 500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# tf.keras.utils.enable_interactive_logging()\n",
    "for sq_ln in range(150, 501, 50):\n",
    "\n",
    "    ln = 10\n",
    "\n",
    "    X, Y = create_data(\n",
    "        10000,\n",
    "        ln=ln,\n",
    "        initial_key1=np.array([1, 0, 1, 1, 1]),\n",
    "        initial_key2=np.array([1, 1, 1, 0, 1]),\n",
    "    )\n",
    "    X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "    X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "            # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "            # tf.keras.layers.LSTM(5),\n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # model.summary()\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\"\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[callback],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model = tf.keras.models.load_model(\"model.h5\")\n",
    "    l, ac = model.evaluate(X_test, Y_test)\n",
    "    lengths.append(sq_ln)\n",
    "    accuracies.append(ac)\n",
    "    losses.append(l)\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(lengths, accuracies)\n",
    "    plt.plot(lengths, losses)\n",
    "    plt.legend([\"Accuracy\", \"Loss\"])\n",
    "    print(f\"Sequence length: {sq_ln}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lengths, accuracies)\n",
    "plt.plot(lengths, losses)\n",
    "plt.legend([\"Accuracy\", \"Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1364639699459076, 0.9952631592750549]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial key 1:  [0 0 1 1 0]\n",
      "Initial key 2:  [0 1 1 1 1]\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1361 - accuracy: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13614453375339508, 0.995195209980011]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = create_data(10000, ln=10)\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001627977762836963 1.0\n",
      "0.027096500620245934 1.0\n",
      "0.027099456638097763 1.0\n",
      "0.02709682285785675 1.0\n",
      "0.02710133045911789 1.0\n",
      "0.02709275484085083 1.0\n",
      "0.027095673605799675 1.0\n",
      "0.02709517441689968 1.0\n",
      "0.027095001190900803 1.0\n",
      "0.027100099250674248 1.0\n",
      "0.027091754600405693 1.0\n",
      "0.027095170691609383 1.0\n",
      "0.02709691971540451 1.0\n",
      "0.027092278003692627 1.0\n",
      "0.02709146775305271 1.0\n",
      "0.027095044031739235 1.0\n",
      "0.027096008881926537 1.0\n",
      "0.027098780497908592 1.0\n",
      "0.027094535529613495 1.0\n",
      "0.027093661949038506 1.0\n",
      "0.027092503383755684 1.0\n",
      "0.027091510593891144 1.0\n",
      "0.027097944170236588 1.0\n",
      "0.027090352028608322 1.0\n",
      "0.027108965441584587 1.0\n",
      "0.027095798403024673 1.0\n",
      "0.027092641219496727 1.0\n",
      "0.02709127776324749 1.0\n",
      "0.027111951261758804 1.0\n",
      "0.027092285454273224 1.0\n",
      "0.027110831812024117 1.0\n",
      "0.027099519968032837 1.0\n",
      "0.028543516993522644 1.0\n",
      "0.010601012967526913 1.0\n",
      "0.010621019639074802 1.0\n",
      "0.010682213120162487 1.0\n",
      "0.01063036173582077 1.0\n",
      "0.010549264028668404 1.0\n",
      "0.010678859427571297 1.0\n",
      "0.010609365068376064 1.0\n",
      "0.010685519315302372 1.0\n",
      "0.01061057485640049 1.0\n",
      "0.010623199865221977 1.0\n",
      "0.010583294555544853 1.0\n",
      "0.010677031241357327 1.0\n",
      "0.01066623255610466 1.0\n",
      "0.010624941438436508 1.0\n",
      "0.010638220235705376 1.0\n",
      "0.010681558400392532 1.0\n",
      "0.010678955353796482 1.0\n",
      "0.010600997135043144 1.0\n",
      "0.010614440776407719 1.0\n",
      "0.010664792731404305 1.0\n",
      "0.010575342923402786 1.0\n",
      "0.010665463283658028 1.0\n",
      "0.010652104392647743 1.0\n",
      "0.010581143200397491 1.0\n",
      "0.010675525292754173 1.0\n",
      "0.010589607059955597 1.0\n",
      "0.010596519336104393 1.0\n",
      "0.01056677382439375 1.0\n",
      "0.010614385828375816 1.0\n",
      "0.01061499584466219 1.0\n",
      "0.01062215305864811 1.0\n",
      "0.02854158543050289 1.0\n",
      "0.010681862942874432 1.0\n",
      "0.010601351037621498 1.0\n",
      "0.010677102021872997 1.0\n",
      "0.010620631277561188 1.0\n",
      "0.01059794146567583 1.0\n",
      "0.010681945830583572 1.0\n",
      "0.010604364797472954 1.0\n",
      "0.010664565488696098 1.0\n",
      "0.010628998279571533 1.0\n",
      "0.010575230233371258 1.0\n",
      "0.010549137368798256 1.0\n",
      "0.01066503208130598 1.0\n",
      "0.010676580481231213 1.0\n",
      "0.010652038268744946 1.0\n",
      "0.01060546562075615 1.0\n",
      "0.01068499218672514 1.0\n",
      "0.010580764152109623 1.0\n",
      "0.010609320364892483 1.0\n",
      "0.01067481841892004 1.0\n",
      "0.010624571703374386 1.0\n",
      "0.010588877834379673 1.0\n",
      "0.010582515969872475 1.0\n",
      "0.010597201995551586 1.0\n",
      "0.010561607778072357 1.0\n",
      "0.010676227509975433 1.0\n",
      "0.010613473132252693 1.0\n",
      "0.010661475360393524 1.0\n",
      "0.01061552856117487 1.0\n",
      "0.010625011287629604 1.0\n",
      "0.010620837099850178 1.0\n",
      "0.010637899860739708 1.0\n",
      "0.02853498049080372 1.0\n",
      "0.010578508488833904 1.0\n",
      "0.010643907822668552 1.0\n",
      "0.010619500651955605 1.0\n",
      "0.01066812314093113 1.0\n",
      "0.010604684241116047 1.0\n",
      "0.010615695267915726 1.0\n",
      "0.010588075965642929 1.0\n",
      "0.010617847554385662 1.0\n",
      "0.010689135640859604 1.0\n",
      "0.010650964453816414 1.0\n",
      "0.01062473002821207 1.0\n",
      "0.010608389973640442 1.0\n",
      "0.010553416796028614 1.0\n",
      "0.01068128738552332 1.0\n",
      "0.01067177951335907 1.0\n",
      "0.010587048716843128 1.0\n",
      "0.010637897998094559 1.0\n",
      "0.01068347878754139 1.0\n",
      "0.010554293170571327 1.0\n",
      "0.01062378566712141 1.0\n",
      "0.010605603456497192 1.0\n",
      "0.010628814809024334 1.0\n",
      "0.010675809346139431 1.0\n",
      "0.010607069358229637 1.0\n",
      "0.01059769932180643 1.0\n",
      "0.01065748929977417 1.0\n",
      "0.010580579750239849 1.0\n",
      "0.010599174536764622 1.0\n",
      "0.010675749741494656 1.0\n",
      "0.010679689235985279 1.0\n",
      "0.010679290629923344 1.0\n",
      "0.028545839712023735 1.0\n",
      "0.010686933062970638 1.0\n",
      "0.010684004984796047 1.0\n",
      "0.01058103609830141 1.0\n",
      "0.01060082670301199 1.0\n",
      "0.010609034448862076 1.0\n",
      "0.010676711797714233 1.0\n",
      "0.010677176527678967 1.0\n",
      "0.010626248084008694 1.0\n",
      "0.01062227226793766 1.0\n",
      "0.010588651522994041 1.0\n",
      "0.010598158463835716 1.0\n",
      "0.010585012845695019 1.0\n",
      "0.010682141408324242 1.0\n",
      "0.010599600151181221 1.0\n",
      "0.010604769922792912 1.0\n",
      "0.01066491287201643 1.0\n",
      "0.010560572147369385 1.0\n",
      "0.010629122145473957 1.0\n",
      "0.010676673613488674 1.0\n",
      "0.010576584376394749 1.0\n",
      "0.010614552535116673 1.0\n",
      "0.010550291277468204 1.0\n",
      "0.010660853236913681 1.0\n",
      "0.010616736486554146 1.0\n",
      "0.010667402297258377 1.0\n",
      "0.010625415481626987 1.0\n",
      "0.010677982121706009 1.0\n",
      "0.010622210800647736 1.0\n",
      "0.010652978904545307 1.0\n",
      "0.010638314299285412 1.0\n",
      "0.010606275871396065 1.0\n",
      "0.028523515909910202 1.0\n",
      "0.010612180456519127 1.0\n",
      "0.010648246854543686 1.0\n",
      "0.010681914165616035 1.0\n",
      "0.010621785186231136 1.0\n",
      "0.010578286834061146 1.0\n",
      "0.010679040104150772 1.0\n",
      "0.010632414370775223 1.0\n",
      "0.010675154626369476 1.0\n",
      "0.010621258988976479 1.0\n",
      "0.01066726166754961 1.0\n",
      "0.01065978966653347 1.0\n",
      "0.010690631344914436 1.0\n",
      "0.010601557791233063 1.0\n",
      "0.010616689920425415 1.0\n",
      "0.01062946580350399 1.0\n",
      "0.010647201910614967 1.0\n",
      "0.010671118274331093 1.0\n",
      "0.010587338358163834 1.0\n",
      "0.010603654198348522 1.0\n",
      "0.010679898783564568 1.0\n",
      "0.010579721070826054 1.0\n",
      "0.010673686861991882 1.0\n",
      "0.010635728016495705 1.0\n",
      "0.010601240210235119 1.0\n",
      "0.010680042207241058 1.0\n",
      "0.010549025610089302 1.0\n",
      "0.010612927377223969 1.0\n",
      "0.010564751923084259 1.0\n",
      "0.010619071312248707 1.0\n",
      "0.010598384775221348 1.0\n",
      "0.010606834664940834 1.0\n",
      "0.028534816578030586 1.0\n",
      "0.010588248260319233 1.0\n",
      "0.01057929266244173 1.0\n",
      "0.010637554340064526 1.0\n",
      "0.010649845004081726 1.0\n",
      "0.01068268995732069 1.0\n",
      "0.010618316009640694 1.0\n",
      "0.010555639863014221 1.0\n",
      "0.01062371488660574 1.0\n",
      "0.010668376460671425 1.0\n",
      "0.01060688216239214 1.0\n",
      "0.010604379698634148 1.0\n",
      "0.010628693737089634 1.0\n",
      "0.010615956969559193 1.0\n",
      "0.010673719458281994 1.0\n",
      "0.010587980970740318 1.0\n",
      "0.010617953725159168 1.0\n",
      "0.010608264245092869 1.0\n",
      "0.010690252296626568 1.0\n",
      "0.01059823390096426 1.0\n",
      "0.010651064105331898 1.0\n",
      "0.010656741447746754 1.0\n",
      "0.010624896734952927 1.0\n",
      "0.010580806992948055 1.0\n",
      "0.010599728673696518 1.0\n",
      "0.010608641430735588 1.0\n",
      "0.010676213540136814 1.0\n",
      "0.010552620515227318 1.0\n",
      "0.010680284351110458 1.0\n",
      "0.010680971667170525 1.0\n",
      "0.010679780505597591 1.0\n",
      "0.010672654956579208 1.0\n",
      "0.031325116753578186 1.0\n",
      "0.030318081378936768 1.0\n",
      "0.03031669370830059 1.0\n",
      "0.030318111181259155 1.0\n",
      "0.030325736850500107 1.0\n",
      "0.030315810814499855 1.0\n",
      "0.030313212424516678 1.0\n",
      "0.030325720086693764 1.0\n",
      "0.030324868857860565 1.0\n",
      "0.030321676284074783 1.0\n",
      "0.030317170545458794 1.0\n",
      "0.030323809012770653 1.0\n",
      "0.030312051996588707 1.0\n",
      "0.030324786901474 1.0\n",
      "0.030317766591906548 1.0\n",
      "0.0303114652633667 1.0\n",
      "0.030319778248667717 1.0\n",
      "0.03031962551176548 1.0\n",
      "0.030314862728118896 1.0\n",
      "0.030327782034873962 1.0\n",
      "0.03031495399773121 1.0\n",
      "0.030321024358272552 1.0\n",
      "0.030318085104227066 1.0\n",
      "0.030312424525618553 1.0\n",
      "0.030321309342980385 1.0\n",
      "0.03032025136053562 1.0\n",
      "0.03031575307250023 1.0\n",
      "0.03031989373266697 1.0\n",
      "0.030316360294818878 1.0\n",
      "0.030314847826957703 1.0\n",
      "0.030324777588248253 1.0\n",
      "0.030316874384880066 1.0\n",
      "0.028542982414364815 1.0\n",
      "0.01066543161869049 1.0\n",
      "0.01068784762173891 1.0\n",
      "0.010557161644101143 1.0\n",
      "0.010684196837246418 1.0\n",
      "0.010629105381667614 1.0\n",
      "0.010581644251942635 1.0\n",
      "0.010677838698029518 1.0\n",
      "0.01057728286832571 1.0\n",
      "0.010601907968521118 1.0\n",
      "0.01061504427343607 1.0\n",
      "0.01060937624424696 1.0\n",
      "0.010550640523433685 1.0\n",
      "0.010676193982362747 1.0\n",
      "0.010659608989953995 1.0\n",
      "0.010677752085030079 1.0\n",
      "0.010626697912812233 1.0\n",
      "0.01061681006103754 1.0\n",
      "0.010623261332511902 1.0\n",
      "0.010669487528502941 1.0\n",
      "0.010588135570287704 1.0\n",
      "0.010624808259308338 1.0\n",
      "0.010597643442451954 1.0\n",
      "0.010678142309188843 1.0\n",
      "0.01062189880758524 1.0\n",
      "0.0105863306671381 1.0\n",
      "0.010653506964445114 1.0\n",
      "0.01068160030990839 1.0\n",
      "0.01063874363899231 1.0\n",
      "0.010600975714623928 1.0\n",
      "0.010606169700622559 1.0\n",
      "0.010603375732898712 1.0\n",
      "0.03132972866296768 1.0\n",
      "0.030329274013638496 1.0\n",
      "0.030312759801745415 1.0\n",
      "0.030327556654810905 1.0\n",
      "0.03030998259782791 1.0\n",
      "0.03031427413225174 1.0\n",
      "0.03031769022345543 1.0\n",
      "0.030312027782201767 1.0\n",
      "0.030311714857816696 1.0\n",
      "0.030319498851895332 1.0\n",
      "0.030312439426779747 1.0\n",
      "0.030315658077597618 1.0\n",
      "0.030318867415189743 1.0\n",
      "0.030314791947603226 1.0\n",
      "0.030316269025206566 1.0\n",
      "0.030320661142468452 1.0\n",
      "0.030314447358250618 1.0\n",
      "0.030312106013298035 1.0\n",
      "0.030317042022943497 1.0\n",
      "0.030312715098261833 1.0\n",
      "0.03031839057803154 1.0\n",
      "0.030319545418024063 1.0\n",
      "0.03031451813876629 1.0\n",
      "0.030310936272144318 1.0\n",
      "0.030316749587655067 1.0\n",
      "0.03031238354742527 1.0\n",
      "0.030314121395349503 1.0\n",
      "0.030316269025206566 1.0\n",
      "0.030313072726130486 1.0\n",
      "0.03031734749674797 1.0\n",
      "0.030321229249238968 1.0\n",
      "0.03031057119369507 1.0\n",
      "0.028525423258543015 1.0\n",
      "0.010647373273968697 1.0\n",
      "0.010615034028887749 1.0\n",
      "0.010672048665583134 1.0\n",
      "0.010648485273122787 1.0\n",
      "0.010587906464934349 1.0\n",
      "0.010683084838092327 1.0\n",
      "0.010603677481412888 1.0\n",
      "0.010680202394723892 1.0\n",
      "0.010621106252074242 1.0\n",
      "0.010580241680145264 1.0\n",
      "0.010579343885183334 1.0\n",
      "0.010676720179617405 1.0\n",
      "0.010679425671696663 1.0\n",
      "0.010635585524141788 1.0\n",
      "0.01063814852386713 1.0\n",
      "0.010677912272512913 1.0\n",
      "0.010602538473904133 1.0\n",
      "0.010621524415910244 1.0\n",
      "0.010680533945560455 1.0\n",
      "0.010668287053704262 1.0\n",
      "0.010548993945121765 1.0\n",
      "0.01066075824201107 1.0\n",
      "0.010613941587507725 1.0\n",
      "0.01056697778403759 1.0\n",
      "0.010692885145545006 1.0\n",
      "0.010619128122925758 1.0\n",
      "0.01060166023671627 1.0\n",
      "0.010598714463412762 1.0\n",
      "0.01061695534735918 1.0\n",
      "0.010606667026877403 1.0\n",
      "0.010630798526108265 1.0\n",
      "0.028521617874503136 1.0\n",
      "0.010679208673536777 1.0\n",
      "0.01067778468132019 1.0\n",
      "0.010568538680672646 1.0\n",
      "0.010646031238138676 1.0\n",
      "0.010619796812534332 1.0\n",
      "0.010606487281620502 1.0\n",
      "0.010691743344068527 1.0\n",
      "0.010580453090369701 1.0\n",
      "0.010617143474519253 1.0\n",
      "0.010615098290145397 1.0\n",
      "0.010619458742439747 1.0\n",
      "0.010578912682831287 1.0\n",
      "0.010670777410268784 1.0\n",
      "0.010602219961583614 1.0\n",
      "0.010677418671548367 1.0\n",
      "0.010668283328413963 1.0\n",
      "0.01059654075652361 1.0\n",
      "0.010645645670592785 1.0\n",
      "0.010681835003197193 1.0\n",
      "0.010548392310738564 1.0\n",
      "0.010617466643452644 1.0\n",
      "0.010585866868495941 1.0\n",
      "0.01067870482802391 1.0\n",
      "0.010607732459902763 1.0\n",
      "0.010671408846974373 1.0\n",
      "0.010633046738803387 1.0\n",
      "0.01068317424505949 1.0\n",
      "0.010627281852066517 1.0\n",
      "0.010614645667374134 1.0\n",
      "0.01064248289912939 1.0\n",
      "0.010599316097795963 1.0\n",
      "0.028524812310934067 1.0\n",
      "0.010617815889418125 1.0\n",
      "0.010588006116449833 1.0\n",
      "0.01060790941119194 1.0\n",
      "0.010579300113022327 1.0\n",
      "0.010689881630241871 1.0\n",
      "0.010637271218001842 1.0\n",
      "0.010598516091704369 1.0\n",
      "0.01064989436417818 1.0\n",
      "0.01064981147646904 1.0\n",
      "0.010652138851583004 1.0\n",
      "0.010682303458452225 1.0\n",
      "0.0106266550719738 1.0\n",
      "0.010617565363645554 1.0\n",
      "0.010579888708889484 1.0\n",
      "0.010556875728070736 1.0\n",
      "0.010623544454574585 1.0\n",
      "0.010598951950669289 1.0\n",
      "0.010668618604540825 1.0\n",
      "0.010608257725834846 1.0\n",
      "0.01060696691274643 1.0\n",
      "0.010675718076527119 1.0\n",
      "0.010603992268443108 1.0\n",
      "0.010551366955041885 1.0\n",
      "0.010680407285690308 1.0\n",
      "0.010628731921315193 1.0\n",
      "0.010681218467652798 1.0\n",
      "0.010615464299917221 1.0\n",
      "0.010680511593818665 1.0\n",
      "0.010670099407434464 1.0\n",
      "0.010672003962099552 1.0\n",
      "0.01058803591877222 1.0\n",
      "0.024028360843658447 1.0\n",
      "0.01998225972056389 1.0\n",
      "0.01998881809413433 1.0\n",
      "0.01998332142829895 1.0\n",
      "0.020004162564873695 1.0\n",
      "0.02000425010919571 1.0\n",
      "0.019993968307971954 1.0\n",
      "0.02001013234257698 1.0\n",
      "0.01999976485967636 1.0\n",
      "0.01998540200293064 1.0\n",
      "0.01998881809413433 1.0\n",
      "0.019987456500530243 1.0\n",
      "0.020008472725749016 1.0\n",
      "0.020006908103823662 1.0\n",
      "0.020003052428364754 1.0\n",
      "0.01998784765601158 1.0\n",
      "0.02000029943883419 1.0\n",
      "0.020008785650134087 1.0\n",
      "0.01998080685734749 1.0\n",
      "0.01997644640505314 1.0\n",
      "0.01998591609299183 1.0\n",
      "0.02000540681183338 1.0\n",
      "0.019979896023869514 1.0\n",
      "0.019995585083961487 1.0\n",
      "0.01999211683869362 1.0\n",
      "0.019986353814601898 1.0\n",
      "0.019993377849459648 1.0\n",
      "0.019977673888206482 1.0\n",
      "0.019992975518107414 1.0\n",
      "0.019978754222393036 1.0\n",
      "0.020008429884910583 1.0\n",
      "0.01998528465628624 1.0\n",
      "0.03132404759526253 1.0\n",
      "0.03032069094479084 1.0\n",
      "0.03031914122402668 1.0\n",
      "0.030324013903737068 1.0\n",
      "0.030315300449728966 1.0\n",
      "0.030318448320031166 1.0\n",
      "0.030322382226586342 1.0\n",
      "0.030328825116157532 1.0\n",
      "0.030316555872559547 1.0\n",
      "0.030333107337355614 1.0\n",
      "0.030324066057801247 1.0\n",
      "0.030311107635498047 1.0\n",
      "0.030325034633278847 1.0\n",
      "0.030313674360513687 1.0\n",
      "0.03032149001955986 1.0\n",
      "0.030325211584568024 1.0\n",
      "0.03032551147043705 1.0\n",
      "0.030323423445224762 1.0\n",
      "0.03032100386917591 1.0\n",
      "0.030324768275022507 1.0\n",
      "0.030316917225718498 1.0\n",
      "0.030314505100250244 1.0\n",
      "0.030320003628730774 1.0\n",
      "0.030321048572659492 1.0\n",
      "0.030316855758428574 1.0\n",
      "0.030312418937683105 1.0\n",
      "0.030318524688482285 1.0\n",
      "0.03031875751912594 1.0\n",
      "0.030331021174788475 1.0\n",
      "0.0303170308470726 1.0\n",
      "0.03032056614756584 1.0\n",
      "0.030315877869725227 1.0\n",
      "0.028533410280942917 1.0\n",
      "0.010580452159047127 1.0\n",
      "0.010665779002010822 1.0\n",
      "0.010608842596411705 1.0\n",
      "0.010678154416382313 1.0\n",
      "0.010615551844239235 1.0\n",
      "0.010595953091979027 1.0\n",
      "0.010674863122403622 1.0\n",
      "0.010610189288854599 1.0\n",
      "0.010676288977265358 1.0\n",
      "0.010632505640387535 1.0\n",
      "0.010643730871379375 1.0\n",
      "0.010616723448038101 1.0\n",
      "0.010570892132818699 1.0\n",
      "0.01068301685154438 1.0\n",
      "0.010682064108550549 1.0\n",
      "0.010548572987318039 1.0\n",
      "0.01062630396336317 1.0\n",
      "0.010630449280142784 1.0\n",
      "0.010579895228147507 1.0\n",
      "0.01061633788049221 1.0\n",
      "0.010616663843393326 1.0\n",
      "0.010620196349918842 1.0\n",
      "0.010670402087271214 1.0\n",
      "0.010646834038197994 1.0\n",
      "0.01058454904705286 1.0\n",
      "0.010601679794490337 1.0\n",
      "0.010608607903122902 1.0\n",
      "0.010598228313028812 1.0\n",
      "0.010679767467081547 1.0\n",
      "0.010675422847270966 1.0\n",
      "0.010689022950828075 1.0\n",
      "0.028545523062348366 1.0\n",
      "0.01062006875872612 1.0\n",
      "0.010631917975842953 1.0\n",
      "0.010680392384529114 1.0\n",
      "0.01061306893825531 1.0\n",
      "0.010582290589809418 1.0\n",
      "0.010666515678167343 1.0\n",
      "0.010640030726790428 1.0\n",
      "0.010680011473596096 1.0\n",
      "0.010603810660541058 1.0\n",
      "0.010665449313819408 1.0\n",
      "0.010664824396371841 1.0\n",
      "0.010676424019038677 1.0\n",
      "0.010597984306514263 1.0\n",
      "0.010612971149384975 1.0\n",
      "0.010621897876262665 1.0\n",
      "0.01060163788497448 1.0\n",
      "0.010682268999516964 1.0\n",
      "0.010549172759056091 1.0\n",
      "0.010612227953970432 1.0\n",
      "0.010685134679079056 1.0\n",
      "0.010620903223752975 1.0\n",
      "0.010677427984774113 1.0\n",
      "0.010624054819345474 1.0\n",
      "0.010679054073989391 1.0\n",
      "0.01061446126550436 1.0\n",
      "0.010574683547019958 1.0\n",
      "0.010652423836290836 1.0\n",
      "0.010580193251371384 1.0\n",
      "0.01059031207114458 1.0\n",
      "0.01057218573987484 1.0\n",
      "0.01061395276337862 1.0\n",
      "0.028532758355140686 1.0\n",
      "0.010633422061800957 1.0\n",
      "0.01066703349351883 1.0\n",
      "0.010615099221467972 1.0\n",
      "0.010688147507607937 1.0\n",
      "0.010623953305184841 1.0\n",
      "0.010556546971201897 1.0\n",
      "0.01066973339766264 1.0\n",
      "0.010586857795715332 1.0\n",
      "0.010684123262763023 1.0\n",
      "0.010623645968735218 1.0\n",
      "0.010628816671669483 1.0\n",
      "0.010597397573292255 1.0\n",
      "0.01058046706020832 1.0\n",
      "0.010676736012101173 1.0\n",
      "0.010678773745894432 1.0\n",
      "0.01057733129709959 1.0\n",
      "0.010621374472975731 1.0\n",
      "0.010603389702737331 1.0\n",
      "0.010586624965071678 1.0\n",
      "0.010615951381623745 1.0\n",
      "0.010651561431586742 1.0\n",
      "0.010608652606606483 1.0\n",
      "0.010680558159947395 1.0\n",
      "0.010638142004609108 1.0\n",
      "0.010550842620432377 1.0\n",
      "0.010603310540318489 1.0\n",
      "0.010675697587430477 1.0\n",
      "0.010606605559587479 1.0\n",
      "0.010659288614988327 1.0\n",
      "0.010601552203297615 1.0\n",
      "0.010678276419639587 1.0\n",
      "0.02852003276348114 1.0\n",
      "0.010648504830896854 1.0\n",
      "0.010624011978507042 1.0\n",
      "0.010681064799427986 1.0\n",
      "0.010621685534715652 1.0\n",
      "0.010656546801328659 1.0\n",
      "0.0106016481295228 1.0\n",
      "0.010629531927406788 1.0\n",
      "0.010649414733052254 1.0\n",
      "0.010588572360575199 1.0\n",
      "0.01068014558404684 1.0\n",
      "0.01067240722477436 1.0\n",
      "0.010681366547942162 1.0\n",
      "0.01061057299375534 1.0\n",
      "0.010617955587804317 1.0\n",
      "0.010607698932290077 1.0\n",
      "0.01061100885272026 1.0\n",
      "0.010681450366973877 1.0\n",
      "0.010579363442957401 1.0\n",
      "0.010631599463522434 1.0\n",
      "0.010675068013370037 1.0\n",
      "0.010668788105249405 1.0\n",
      "0.010691402480006218 1.0\n",
      "0.010616595856845379 1.0\n",
      "0.010672276839613914 1.0\n",
      "0.010605095885694027 1.0\n",
      "0.01058049313724041 1.0\n",
      "0.010636573657393456 1.0\n",
      "0.010601687245070934 1.0\n",
      "0.010549517348408699 1.0\n",
      "0.010564458556473255 1.0\n",
      "0.010598341003060341 1.0\n",
      "0.031325556337833405 1.0\n",
      "0.030315149575471878 1.0\n",
      "0.03032328002154827 1.0\n",
      "0.030312759801745415 1.0\n",
      "0.030318334698677063 1.0\n",
      "0.030324267223477364 1.0\n",
      "0.0303212720900774 1.0\n",
      "0.030312610790133476 1.0\n",
      "0.030321791768074036 1.0\n",
      "0.030311670154333115 1.0\n",
      "0.030314989387989044 1.0\n",
      "0.03031545877456665 1.0\n",
      "0.030319038778543472 1.0\n",
      "0.030317161232233047 1.0\n",
      "0.03031117469072342 1.0\n",
      "0.030316082760691643 1.0\n",
      "0.030314145609736443 1.0\n",
      "0.0303153395652771 1.0\n",
      "0.0303178858011961 1.0\n",
      "0.030315153300762177 1.0\n",
      "0.03031313605606556 1.0\n",
      "0.0303131602704525 1.0\n",
      "0.03031346946954727 1.0\n",
      "0.030316263437271118 1.0\n",
      "0.030313173308968544 1.0\n",
      "0.030325116589665413 1.0\n",
      "0.030318209901452065 1.0\n",
      "0.0303106140345335 1.0\n",
      "0.0303218811750412 1.0\n",
      "0.03031538613140583 1.0\n",
      "0.03031315468251705 1.0\n",
      "0.03032318875193596 1.0\n"
     ]
    }
   ],
   "source": [
    "tl, tac = 0, 0\n",
    "for i in range(1024):\n",
    "    keys = np.binary_repr(i, width=10)\n",
    "    keys = np.array([int(k) for k in keys])\n",
    "    key1 = keys[:5]\n",
    "    key2 = keys[5:]\n",
    "    X, Y = create_data(\n",
    "        10000,\n",
    "        ln=15,\n",
    "        initial_key1=key1,\n",
    "        initial_key2=key2,\n",
    "    )\n",
    "    l, ac = model.evaluate(X, Y)\n",
    "    print(l,ac)\n",
    "    tl += l\n",
    "    tac += ac\n",
    "print(\"Total Loss and Accuracy: \", tl/1024, tac/1024)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key1:  [1 1 1 0 0]\n",
      "Key2:  [0 0 1 0 1]\n",
      "Sequence length: 250 with accuracy: 0.7001025676727295 and loss: 0.6093835234642029\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [1 0 0 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7047179341316223 and loss: 0.6492166519165039\n",
      "Key1:  [1 1 0 1 1]\n",
      "Key2:  [0 0 0 0 0]\n",
      "Sequence length: 150 with accuracy: 1.0 and loss: 0.4989528954029083\n",
      "Key1:  [0 0 1 0 1]\n",
      "Key2:  [1 0 0 0 1]\n",
      "Sequence length: 250 with accuracy: 0.7076923251152039 and loss: 0.6359493732452393\n",
      "Key1:  [1 0 1 0 0]\n",
      "Key2:  [1 0 1 1 0]\n",
      "Sequence length: 150 with accuracy: 0.7120811939239502 and loss: 0.6169815063476562\n",
      "Key1:  [1 1 0 0 0]\n",
      "Key2:  [1 1 1 0 0]\n",
      "Sequence length: 250 with accuracy: 0.7001025676727295 and loss: 0.5866572260856628\n",
      "Key1:  [0 0 1 0 0]\n",
      "Key2:  [0 0 0 0 0]\n",
      "Sequence length: 150 with accuracy: 0.7142131924629211 and loss: 0.6509259343147278\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [1 1 1 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7076923251152039 and loss: 0.5833685994148254\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [0 0 0 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7015384435653687 and loss: 0.5906823873519897\n",
      "Key1:  [1 0 0 1 1]\n",
      "Key2:  [0 1 0 0 1]\n",
      "Sequence length: 150 with accuracy: 0.703045666217804 and loss: 0.5921750664710999\n"
     ]
    }
   ],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[\"val_accuracy\"] > self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(10):\n",
    "    key1 = np.random.randint(0, 2, 5)\n",
    "    key2 = np.random.randint(0, 2, 5)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Key1: \", key1)\n",
    "    print(\"Key2: \", key2)\n",
    "    while True\n",
    "    for sq_ln in range(150, 501, 50):\n",
    "        ln = 10\n",
    "        X, Y = create_data(\n",
    "            10000,\n",
    "            ln=ln,\n",
    "            initial_key1=key1,\n",
    "            initial_key2=key2,\n",
    "        )\n",
    "        X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "        X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "                # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "                # tf.keras.layers.LSTM(5),\n",
    "                tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[ThresholdCallback(0.7)],\n",
    "            verbose=0,\n",
    "        )\n",
    "        l, ac = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        if ac > 0.7:\n",
    "            print(f\"Sequence length: {sq_ln} with accuracy: {ac} and loss: {l}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key1:  [1 1 0 0 1]\n",
      "Key2:  [1 0 1 0 1]\n",
      "Sequence length: 250 with accuracy: 0.707897424697876 and loss: 0.6060001850128174\n",
      "Key1:  [0 0 0 0 0]\n",
      "Key2:  [0 1 1 0 1]\n",
      "Sequence length: 50 with accuracy: 0.7420100569725037 and loss: 0.6757830381393433\n",
      "Key1:  [1 0 1 1 0]\n",
      "Key2:  [1 1 1 1 1]\n",
      "Sequence length: 100 with accuracy: 0.7529292702674866 and loss: 0.6520717144012451\n",
      "Key1:  [1 0 1 0 0]\n",
      "Key2:  [1 0 0 1 0]\n",
      "Sequence length: 100 with accuracy: 0.7027272582054138 and loss: 0.638469398021698\n",
      "Key1:  [1 0 0 0 0]\n",
      "Key2:  [1 0 1 1 0]\n",
      "Sequence length: 250 with accuracy: 0.7061538696289062 and loss: 0.6032127141952515\n",
      "Key1:  [1 0 1 1 0]\n",
      "Key2:  [0 1 1 1 1]\n",
      "Sequence length: 100 with accuracy: 0.7093939185142517 and loss: 0.6635072231292725\n",
      "Key1:  [1 0 0 0 1]\n",
      "Key2:  [0 0 0 0 0]\n",
      "Sequence length: 50 with accuracy: 0.7141708731651306 and loss: 0.61024409532547\n",
      "Key1:  [0 0 1 0 1]\n",
      "Key2:  [0 1 0 0 1]\n",
      "Sequence length: 250 with accuracy: 0.7030768990516663 and loss: 0.6300603747367859\n",
      "Key1:  [1 0 0 0 0]\n",
      "Key2:  [0 1 1 1 1]\n",
      "Sequence length: 250 with accuracy: 0.7015384435653687 and loss: 0.6107650995254517\n",
      "Key1:  [1 0 0 1 0]\n",
      "Key2:  [0 1 1 0 0]\n",
      "Sequence length: 250 with accuracy: 0.7015384435653687 and loss: 0.5968985557556152\n"
     ]
    }
   ],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[\"val_accuracy\"] > self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(10):\n",
    "    key1 = np.random.randint(0, 2, 5)\n",
    "    key2 = np.random.randint(0, 2, 5)\n",
    "    print(\"Key1: \", key1)\n",
    "    print(\"Key2: \", key2)\n",
    "    for sq_ln in range(50, 501, 50):\n",
    "        ln = 10\n",
    "        X, Y = create_data(\n",
    "            10000,\n",
    "            ln=ln,\n",
    "            initial_key1=key1,\n",
    "            initial_key2=key2,\n",
    "        )\n",
    "        X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "        X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "                # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "                # tf.keras.layers.LSTM(5),\n",
    "                tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[ThresholdCallback(0.7)],\n",
    "            verbose=0,\n",
    "        )\n",
    "        l, ac = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        if ac > 0.7:\n",
    "            print(f\"Sequence length: {sq_ln} with accuracy: {ac} and loss: {l}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Key1:  [0 1 1 1 1]\n",
      "Key2:  [1 0 1 0 1]\n",
      "Period of first LFSR:  21\n",
      "Period of second LFSR:  31\n",
      "Period of combined:  651\n"
     ]
    }
   ],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs[\"val_accuracy\"] > self.threshold:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "for i in range(10):\n",
    "    key1 = np.random.randint(0, 2, 5)\n",
    "    key2 = np.random.randint(0, 2, 5)\n",
    "    print(\"---------------------\")\n",
    "    print(\"Key1: \", key1)\n",
    "    print(\"Key2: \", key2)\n",
    "    init_key1 = key1\n",
    "    init_key2 = key2\n",
    "    i = 0\n",
    "    while True:\n",
    "        nxt = key1[0] ^ key1[1]\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key1[-1] = nxt\n",
    "        i += 1\n",
    "        if np.array_equal(key1, init_key1):\n",
    "            break\n",
    "    print(\"Period of first LFSR: \", i)\n",
    "    i=0\n",
    "    while True:\n",
    "        nxt = key2[0] ^ key2[2]\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key2[-1] = nxt\n",
    "        i += 1\n",
    "        if np.array_equal(key2, init_key2):\n",
    "            break\n",
    "    print(\"Period of second LFSR: \", i)\n",
    "    i = 0\n",
    "    while True:\n",
    "        nxt1 = key1[0] ^ key1[1]\n",
    "        nxt2 = key2[0] ^ key2[2]\n",
    "        key1 = np.roll(key1, -1)\n",
    "        key2 = np.roll(key2, -1)\n",
    "        key1[-1] = nxt1\n",
    "        key2[-1] = nxt2\n",
    "        i += 1\n",
    "        if np.array_equal(key1, init_key1) and np.array_equal(key2, init_key2):\n",
    "            break\n",
    "    print(\"Period of combined: \", i)      \n",
    "    for sq_ln in range(20, 521, 50):\n",
    "        ln = 10\n",
    "        X, Y = create_data(\n",
    "            10000,\n",
    "            ln=ln,\n",
    "            initial_key1=key1,\n",
    "            initial_key2=key2,\n",
    "        )\n",
    "        X_train, Y_train = X[: sq_ln - ln], Y[: sq_ln - ln]\n",
    "        X_test, Y_test = X[sq_ln - ln :], Y[sq_ln - ln :]\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(1000, input_shape=(ln,), activation=\"relu\"),\n",
    "                # tf.keras.layers.Embedding(2, 5, input_length=ln),\n",
    "                # tf.keras.layers.LSTM(5),\n",
    "                tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            epochs=100,\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[ThresholdCallback(0.7)],\n",
    "            verbose=0,\n",
    "        )\n",
    "        l, ac = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        if ac > 0.7:\n",
    "            print(f\"Sequence length: {sq_ln} with accuracy: {ac} and loss: {l}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
